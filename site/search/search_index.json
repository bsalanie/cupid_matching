{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"cupid_matching \u00b6 A Python package to solve, simulate and estimate separable matching models Free software: MIT license Documentation: https://bsalanie.github.io/cupid_matching See also: An interactive Streamlit app Installation \u00b6 1 pip install [-U] cupid_matching Importing functions from the package \u00b6 For instance: 1 from cupid_matching.min_distance import estimate_semilinear_mde How it works \u00b6 The following only describes the general ideas. The full documentation is here . The cupid_matching package has code to solve for the stable matching using our Iterative Projection Fitting Procedure (IPFP) in variants of the model of bipartite, one-to-one matching with perfectly transferable utility. It has IPFP solvers for variants of the Choo and Siow 2006 model with or without singles, homoskedastic and heteroskedastic; and also for a class of nested logit models to estimate the parameters of separable models with semilinear surplus and entropy using a minimum distance estimator to estimate the parameters of semilinear Choo and Siow models using a Poisson GLM estimator for a Streamlit interactive app that demonstrates solving and estimating the Choo and Siow model using the cupid_matching package. You can try it here . Incidentally, myy ipfp_R Github repository contains R code to solve for equilibrium in ( only ) the basic version of the Choo and Siow model. The package builds on the pioneering work of Choo and Siow JPE 2006 and on my work with Alfred Galichon, especially our REStud 2022 paper and this working paper . At this stage, it only deals with bipartite models. As the heterosexual marriage market is a leading example, I will refer to the two sides as men and women . Each man \\(m\\) (resp. each women \\(w\\) ) has an observed, discrete-valued type \\(x\\) (resp. \\(y\\) ), along with unobserved heterogeneity. The primitives \u00b6 The primitives of this class of matching models are the margins : the numbers \\(n_x\\) of men of type \\(x=1,\\ldots,X\\) and the numbers \\(m_y\\) of women of type \\(y=1,\\ldots,Y\\) the joint surplus created by the match of a man \\(m\\) of type \\(x\\) and a woman \\(w\\) of type \\(y\\) . We assume separability : this joint surplus takes the form $$ \\Phi_{xy}+\\varepsilon_{my} +\\eta_{xw}. $$ A single man has utility \\(\\varepsilon_{m0}\\) and a single woman has utility \\(\\eta_{0w}\\) . The modeler chooses the distributions of the vectors \\((\\varepsilon_{m0},\\varepsilon_{m1},\\ldots, \\varepsilon_{mY})\\) and \\((\\eta_{0w},\\eta_{1w},\\ldots,\\eta_{Xw})\\) . The solution: the stable matching \u00b6 We denote \\(\\mu_{xy}\\) the number of matches between men of type \\(x\\) and women of type \\(y\\) , \\(\\mu_{x0}\\) the number of single men of type \\(x\\) , and \\(\\mu_{0y}\\) the number of single women of type \\(y\\) . The total numbers must add up to the margins: $$ \\sum_{y=1}^Y \\mu_{xy}+\\mu_{x0}=n_x \\; \\text{ and } \\; \\sum_{x=1}^X \\mu_{xy}+\\mu_{0y}=m_y. $$ The total number of individuals is \\(N_i=\\sum_{x=1}^X n_x+ \\sum_{y=1}^Y m_y\\) and the total number of households is \\(N_h = N_i - \\sum_{x=1}^X \\sum_{y=1}^Y \\mu_{xy}\\) . Galichon-Salani\u00e9 ( REStud 2022) shows that in large markets, if the vectors \\(\\varepsilon\\) and \\(\\eta\\) have full support, the stable matching is the unique solution to the strictly convex program $$ \\max_{\\mu} \\left(\\sum_{x=1}^X \\sum_{y=1}^Y \\mu_{xy}\\Phi_{xy} + \\mathcal{E}(\\mu; n, m)\\right) $$ where \\(\\mathcal{E}\\) , the generalized entropy function, depends on the assumed distributions of the \\(\\varepsilon\\) and \\(\\eta\\) random vectors. The files choo_siow.py , choo_siow_gender_heteroskedastic , choo_siow_heteroskedastic , and nested_logit provide EntropyFunctions objects that compute the generalized entropy and at least its first derivative for, respectively, the original Choo and Siow 2006 model, in which the \\(\\varepsilon\\) and \\(\\eta\\) terms are iid draws from a type I extreme value distribution the same model, without singles (to be used when only couples are observed) an extension of 1. that allows for a scale parameter \\(\\tau\\) for the distribution of \\(\\eta\\) an extension of 3. that has type-dependent scale parameters \\(\\sigma_x\\) and \\(\\tau_y\\) (with \\(\\sigma_1=1\\) a two-layer nested logit model in which singles (type 0) are in their own nest and the user chooses the structure of the other nests. Users of the package are welcome to code EntropyFunctions objects for different distributions of the unobserved heterogeneity terms. Solving for the stable matching \u00b6 Given any joint surplus matrix \\(\\Phi\\) ; margins \\(n\\) and \\(m\\) ; and a generalized entropy \\(\\mathcal{E}\\) , one would like to compute the stable matching patterns \\(\\mu\\) . For the five classes of models above, this can be done efficiently using the IPFP algorithm in Galichon-Salani\u00e9 ( REStud 2022) , which is coded in ipfp_solvers.py for the four Choo and Siow variants and in model_classes.py for the nested logit. Here is an example, given a Numpy array \\(\\Phi\\) that is an \\((X,Y)\\) matrix and a number \\(\\tau>0\\) : 1 2 3 4 5 6 7 import numpy as np from cupid_matching.ipfp_solvers import ipfp_gender_homoskedastic solver solution = ipfp_gender_heteroskedastic_solver ( Phi , n , m , tau ) mus , error_x , error_y = solution muxy = mus . muxy The mus above is an instance of a Matching object (defined in matching_utils.py ). mus.muxy has the number of couples by \\((x,y)\\) cell at the stable matching; the vectors mus.mux0 and mus.mu0y contain the numbers of single men and women of each type. The vectors error_x and error_y are estimates of the precision of the solution (see the code in ipfp_solvers.py ). Estimating the joint surplus \u00b6 Given observed matching patterns \\(\\mu\\) ; a class of generalized entropy functions \\((\\mathcal{E}^{\\alpha})\\) ; and a class of joint surplus functions \\((\\Phi^{\\beta})\\) , one would like to estimate the parameter vectors \\(\\alpha\\) and \\(\\beta\\) . The package provides two estimators, which are described extensively in this paper : the minimum distance estimator in min_distance.py the Poisson estimator in poisson_glm.py , which only applies to the Choo and Siow homoskedastic model. At this stage cupid_matching only allows for linear models of the joint surplus: \\[ \\Phi^{\\beta}_{xy} = \\sum_{k=1}^K \\phi_{xy}^k \\beta_k \\] where the basis functions \\((\\phi^1,\\ldots,\\phi^K)\\) are imposed by the analyst. The file example_choosiow.py has a demo of minimum distance and Poisson estimators on the Choo and Siow 2006 model. For other models, the minimum distance estimator works as follows, given an observed matching stored in a Matching object mus an EntropyFunction object entropy_model that allows for p parameters in \\(\\alpha\\) an \\((X,Y,K)\\) Numpy array of basis functions phi_bases : 1 2 3 mde_results = estimate_semilinear_mde ( mus , phi_bases , entropy_model ) mde_results . print_results ( n_alpha = p ) The mde_results object contains the estimated \\(\\alpha\\) and \\(\\beta\\) , their estimated variance-covariance, and a specification test. Examples \u00b6 example_choosiow.py shows how to run minimum distance and Poisson estimators on a Choo and Siow homoskedastic model. example_nestedlogit.py shows how to run minimum distance estimators on a two-layer nested logit model. Warnings \u00b6 many of these models (including all variants of Choo and Siow) rely heavily on logarithms and exponentials. It is easy to generate examples where numeric instability sets in. as a consequence, the numeric versions of the minimum distance estimator (which use numerical derivatives) are not recommended. the bias-corrected minimum distance estimator ( corrected ) may have a larger mean-squared error and/or introduce numerical instabilities. the estimated variance of the estimators assumes that the observed matching was sampled at the household level, and that sampling weights are all equal. Release notes \u00b6 version 1.1.1 \u00b6 improved documentation the package now relies on my utilities package bs_python_utils . The VarianceMatching class in matching_utils,py is new; this should be transparent for the user. version 1.0.8 \u00b6 deleted spurious print statement. version 1.0.7 \u00b6 fixed error in bias-correction term. version 1.0.6 \u00b6 corrected typo. version 1.0.5 \u00b6 simplified the bias-correction for the minimum distance estimator in the Choo and Siow homoskedastic model. version 1.0.4 \u00b6 added an optional bias-correction for the minimum distance estimator in the Choo and Siow homoskedastic model, to help with cases when the matching patterns vary a lot across cells. added two complete examples: example_choosiow.py and example_nestedlogit.py .","title":"Home"},{"location":"#cupid_matching","text":"A Python package to solve, simulate and estimate separable matching models Free software: MIT license Documentation: https://bsalanie.github.io/cupid_matching See also: An interactive Streamlit app","title":"cupid_matching"},{"location":"#installation","text":"1 pip install [-U] cupid_matching","title":"Installation"},{"location":"#importing-functions-from-the-package","text":"For instance: 1 from cupid_matching.min_distance import estimate_semilinear_mde","title":"Importing functions from the package"},{"location":"#how-it-works","text":"The following only describes the general ideas. The full documentation is here . The cupid_matching package has code to solve for the stable matching using our Iterative Projection Fitting Procedure (IPFP) in variants of the model of bipartite, one-to-one matching with perfectly transferable utility. It has IPFP solvers for variants of the Choo and Siow 2006 model with or without singles, homoskedastic and heteroskedastic; and also for a class of nested logit models to estimate the parameters of separable models with semilinear surplus and entropy using a minimum distance estimator to estimate the parameters of semilinear Choo and Siow models using a Poisson GLM estimator for a Streamlit interactive app that demonstrates solving and estimating the Choo and Siow model using the cupid_matching package. You can try it here . Incidentally, myy ipfp_R Github repository contains R code to solve for equilibrium in ( only ) the basic version of the Choo and Siow model. The package builds on the pioneering work of Choo and Siow JPE 2006 and on my work with Alfred Galichon, especially our REStud 2022 paper and this working paper . At this stage, it only deals with bipartite models. As the heterosexual marriage market is a leading example, I will refer to the two sides as men and women . Each man \\(m\\) (resp. each women \\(w\\) ) has an observed, discrete-valued type \\(x\\) (resp. \\(y\\) ), along with unobserved heterogeneity.","title":"How it works"},{"location":"#the-primitives","text":"The primitives of this class of matching models are the margins : the numbers \\(n_x\\) of men of type \\(x=1,\\ldots,X\\) and the numbers \\(m_y\\) of women of type \\(y=1,\\ldots,Y\\) the joint surplus created by the match of a man \\(m\\) of type \\(x\\) and a woman \\(w\\) of type \\(y\\) . We assume separability : this joint surplus takes the form $$ \\Phi_{xy}+\\varepsilon_{my} +\\eta_{xw}. $$ A single man has utility \\(\\varepsilon_{m0}\\) and a single woman has utility \\(\\eta_{0w}\\) . The modeler chooses the distributions of the vectors \\((\\varepsilon_{m0},\\varepsilon_{m1},\\ldots, \\varepsilon_{mY})\\) and \\((\\eta_{0w},\\eta_{1w},\\ldots,\\eta_{Xw})\\) .","title":"The primitives"},{"location":"#the-solution-the-stable-matching","text":"We denote \\(\\mu_{xy}\\) the number of matches between men of type \\(x\\) and women of type \\(y\\) , \\(\\mu_{x0}\\) the number of single men of type \\(x\\) , and \\(\\mu_{0y}\\) the number of single women of type \\(y\\) . The total numbers must add up to the margins: $$ \\sum_{y=1}^Y \\mu_{xy}+\\mu_{x0}=n_x \\; \\text{ and } \\; \\sum_{x=1}^X \\mu_{xy}+\\mu_{0y}=m_y. $$ The total number of individuals is \\(N_i=\\sum_{x=1}^X n_x+ \\sum_{y=1}^Y m_y\\) and the total number of households is \\(N_h = N_i - \\sum_{x=1}^X \\sum_{y=1}^Y \\mu_{xy}\\) . Galichon-Salani\u00e9 ( REStud 2022) shows that in large markets, if the vectors \\(\\varepsilon\\) and \\(\\eta\\) have full support, the stable matching is the unique solution to the strictly convex program $$ \\max_{\\mu} \\left(\\sum_{x=1}^X \\sum_{y=1}^Y \\mu_{xy}\\Phi_{xy} + \\mathcal{E}(\\mu; n, m)\\right) $$ where \\(\\mathcal{E}\\) , the generalized entropy function, depends on the assumed distributions of the \\(\\varepsilon\\) and \\(\\eta\\) random vectors. The files choo_siow.py , choo_siow_gender_heteroskedastic , choo_siow_heteroskedastic , and nested_logit provide EntropyFunctions objects that compute the generalized entropy and at least its first derivative for, respectively, the original Choo and Siow 2006 model, in which the \\(\\varepsilon\\) and \\(\\eta\\) terms are iid draws from a type I extreme value distribution the same model, without singles (to be used when only couples are observed) an extension of 1. that allows for a scale parameter \\(\\tau\\) for the distribution of \\(\\eta\\) an extension of 3. that has type-dependent scale parameters \\(\\sigma_x\\) and \\(\\tau_y\\) (with \\(\\sigma_1=1\\) a two-layer nested logit model in which singles (type 0) are in their own nest and the user chooses the structure of the other nests. Users of the package are welcome to code EntropyFunctions objects for different distributions of the unobserved heterogeneity terms.","title":"The solution: the stable matching"},{"location":"#solving-for-the-stable-matching","text":"Given any joint surplus matrix \\(\\Phi\\) ; margins \\(n\\) and \\(m\\) ; and a generalized entropy \\(\\mathcal{E}\\) , one would like to compute the stable matching patterns \\(\\mu\\) . For the five classes of models above, this can be done efficiently using the IPFP algorithm in Galichon-Salani\u00e9 ( REStud 2022) , which is coded in ipfp_solvers.py for the four Choo and Siow variants and in model_classes.py for the nested logit. Here is an example, given a Numpy array \\(\\Phi\\) that is an \\((X,Y)\\) matrix and a number \\(\\tau>0\\) : 1 2 3 4 5 6 7 import numpy as np from cupid_matching.ipfp_solvers import ipfp_gender_homoskedastic solver solution = ipfp_gender_heteroskedastic_solver ( Phi , n , m , tau ) mus , error_x , error_y = solution muxy = mus . muxy The mus above is an instance of a Matching object (defined in matching_utils.py ). mus.muxy has the number of couples by \\((x,y)\\) cell at the stable matching; the vectors mus.mux0 and mus.mu0y contain the numbers of single men and women of each type. The vectors error_x and error_y are estimates of the precision of the solution (see the code in ipfp_solvers.py ).","title":"Solving for the stable matching"},{"location":"#estimating-the-joint-surplus","text":"Given observed matching patterns \\(\\mu\\) ; a class of generalized entropy functions \\((\\mathcal{E}^{\\alpha})\\) ; and a class of joint surplus functions \\((\\Phi^{\\beta})\\) , one would like to estimate the parameter vectors \\(\\alpha\\) and \\(\\beta\\) . The package provides two estimators, which are described extensively in this paper : the minimum distance estimator in min_distance.py the Poisson estimator in poisson_glm.py , which only applies to the Choo and Siow homoskedastic model. At this stage cupid_matching only allows for linear models of the joint surplus: \\[ \\Phi^{\\beta}_{xy} = \\sum_{k=1}^K \\phi_{xy}^k \\beta_k \\] where the basis functions \\((\\phi^1,\\ldots,\\phi^K)\\) are imposed by the analyst. The file example_choosiow.py has a demo of minimum distance and Poisson estimators on the Choo and Siow 2006 model. For other models, the minimum distance estimator works as follows, given an observed matching stored in a Matching object mus an EntropyFunction object entropy_model that allows for p parameters in \\(\\alpha\\) an \\((X,Y,K)\\) Numpy array of basis functions phi_bases : 1 2 3 mde_results = estimate_semilinear_mde ( mus , phi_bases , entropy_model ) mde_results . print_results ( n_alpha = p ) The mde_results object contains the estimated \\(\\alpha\\) and \\(\\beta\\) , their estimated variance-covariance, and a specification test.","title":"Estimating the joint surplus"},{"location":"#examples","text":"example_choosiow.py shows how to run minimum distance and Poisson estimators on a Choo and Siow homoskedastic model. example_nestedlogit.py shows how to run minimum distance estimators on a two-layer nested logit model.","title":"Examples"},{"location":"#warnings","text":"many of these models (including all variants of Choo and Siow) rely heavily on logarithms and exponentials. It is easy to generate examples where numeric instability sets in. as a consequence, the numeric versions of the minimum distance estimator (which use numerical derivatives) are not recommended. the bias-corrected minimum distance estimator ( corrected ) may have a larger mean-squared error and/or introduce numerical instabilities. the estimated variance of the estimators assumes that the observed matching was sampled at the household level, and that sampling weights are all equal.","title":"Warnings"},{"location":"#release-notes","text":"","title":"Release notes"},{"location":"#version-111","text":"improved documentation the package now relies on my utilities package bs_python_utils . The VarianceMatching class in matching_utils,py is new; this should be transparent for the user.","title":"version 1.1.1"},{"location":"#version-108","text":"deleted spurious print statement.","title":"version 1.0.8"},{"location":"#version-107","text":"fixed error in bias-correction term.","title":"version 1.0.7"},{"location":"#version-106","text":"corrected typo.","title":"version 1.0.6"},{"location":"#version-105","text":"simplified the bias-correction for the minimum distance estimator in the Choo and Siow homoskedastic model.","title":"version 1.0.5"},{"location":"#version-104","text":"added an optional bias-correction for the minimum distance estimator in the Choo and Siow homoskedastic model, to help with cases when the matching patterns vary a lot across cells. added two complete examples: example_choosiow.py and example_nestedlogit.py .","title":"version 1.0.4"},{"location":"choo_siow/","text":"choo_siow module \u00b6 The components of the derivative of the entropy for the Choo and Siow homoskedastic model. e0_fun_choo_siow ( muhat ) \u00b6 Returns the values of \\(e_0\\) for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the first derivative of the entropy Source code in cupid_matching/choo_siow.py 145 146 147 148 149 150 151 152 153 154 155 def e0_fun_choo_siow ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of $e_0$ for the Choo and Siow model. Args: muhat: a Matching Returns: the (X,Y) matrix of the first derivative of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 1 ) return cast ( np . ndarray , entropy_res [ 1 ]) e0_fun_choo_siow_corrected ( muhat ) \u00b6 Returns the values of \\(e_0\\) for the Choo and Siow model, using the finite-sample correction log(p+(1-p)/(2N)) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the first derivative of the entropy Source code in cupid_matching/choo_siow.py 158 159 160 161 162 163 164 165 166 167 168 169 def e0_fun_choo_siow_corrected ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of $e_0$ for the Choo and Siow model, using the finite-sample correction log(p+(1-p)/(2N)) Args: muhat: a Matching Returns: the (X,Y) matrix of the first derivative of the entropy \"\"\" e0_val_corrected = _der_entropy_choo_siow_corrected ( muhat , hessian = False ) return e0_val_corrected hessian_mumu_choo_siow ( muhat ) \u00b6 Returns the derivatives of \\(e_0\\) in \\(\\mu\\) for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the three components of the hessian wrt \\((\\mu,\\mu)\\) of the entropy Source code in cupid_matching/choo_siow.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def hessian_mumu_choo_siow ( muhat : Matching ) -> ThreeArrays : \"\"\"Returns the derivatives of $e_0$ in $\\\\mu$ for the Choo and Siow model. Args: muhat: a Matching Returns: the three components of the hessian wrt $(\\\\mu,\\\\mu)$ of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 2 ) hessmumu = entropy_res [ 2 ] muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2xy = hessmumu [ x , y , :, :] hess_x [ x , y , :] = d2xy [ x , :] hess_y [ x , y , :] = d2xy [:, y ] hess_xy [ x , y ] = d2xy [ x , y ] return hess_x , hess_y , hess_xy hessian_mumu_choo_siow_corrected ( muhat ) \u00b6 Returns the derivatives of \\(e_0\\) in \\(\\mu\\) for the Choo and Siow model, with the small sample correction Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the three components of the hessian wrt \\((\\mu,\\mu)\\) of the entropy Source code in cupid_matching/choo_siow.py 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 def hessian_mumu_choo_siow_corrected ( muhat : Matching ) -> ThreeArrays : \"\"\"Returns the derivatives of $e_0$ in $\\\\mu$ for the Choo and Siow model, with the small sample correction Args: muhat: a Matching Returns: the three components of the hessian wrt $(\\\\mu,\\\\mu)$ of the entropy \"\"\" _ , hessmumu , _ = _der_entropy_choo_siow_corrected ( muhat , hessian = True ) muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2xy = hessmumu [ x , y , :, :] hess_x [ x , y , :] = d2xy [ x , :] hess_y [ x , y , :] = d2xy [:, y ] hess_xy [ x , y ] = d2xy [ x , y ] return hess_x , hess_y , hess_xy hessian_mur_choo_siow ( muhat ) \u00b6 Returns the derivatives of \\(e_0\\) in \\(r\\) for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the two components of the hessian wrt \\((\\mu,r)\\) of the entropy Source code in cupid_matching/choo_siow.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 def hessian_mur_choo_siow ( muhat : Matching ) -> TwoArrays : \"\"\"Returns the derivatives of $e_0$ in $r$ for the Choo and Siow model. Args: muhat: a Matching Returns: the two components of the hessian wrt $(\\\\mu,r)$ of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 2 ) hessmur = entropy_res [ 3 ] muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_nx = np . zeros (( X , Y )) hess_my = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2r = hessmur [ x , y , :] hess_nx [ x , y ] = d2r [ x ] hess_my [ x , y ] = d2r [ X + y ] return hess_nx , hess_my hessian_mur_choo_siow_corrected ( muhat ) \u00b6 Returns the derivatives of \\(e_0\\) in \\(r\\) for the Choo and Siow model, with the small sample correction Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the two components of the hessian wrt \\((\\mu,r)\\) of the entropy Source code in cupid_matching/choo_siow.py 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 def hessian_mur_choo_siow_corrected ( muhat : Matching ) -> TwoArrays : \"\"\"Returns the derivatives of $e_0$ in $r$ for the Choo and Siow model, with the small sample correction Args: muhat: a Matching Returns: the two components of the hessian wrt $(\\\\mu,r)$ of the entropy \"\"\" _ , _ , hessmur = _der_entropy_choo_siow_corrected ( muhat , hessian = True ) muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_nx = np . zeros (( X , Y )) hess_my = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2r = hessmur [ x , y , :] hess_nx [ x , y ] = d2r [ x ] hess_my [ x , y ] = d2r [ X + y ] return hess_nx , hess_my","title":"Choo-Siow homoskedastic"},{"location":"choo_siow/#choo_siow-module","text":"The components of the derivative of the entropy for the Choo and Siow homoskedastic model.","title":"choo_siow module"},{"location":"choo_siow/#cupid_matching.choo_siow.e0_fun_choo_siow","text":"Returns the values of \\(e_0\\) for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the first derivative of the entropy Source code in cupid_matching/choo_siow.py 145 146 147 148 149 150 151 152 153 154 155 def e0_fun_choo_siow ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of $e_0$ for the Choo and Siow model. Args: muhat: a Matching Returns: the (X,Y) matrix of the first derivative of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 1 ) return cast ( np . ndarray , entropy_res [ 1 ])","title":"e0_fun_choo_siow()"},{"location":"choo_siow/#cupid_matching.choo_siow.e0_fun_choo_siow_corrected","text":"Returns the values of \\(e_0\\) for the Choo and Siow model, using the finite-sample correction log(p+(1-p)/(2N)) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the first derivative of the entropy Source code in cupid_matching/choo_siow.py 158 159 160 161 162 163 164 165 166 167 168 169 def e0_fun_choo_siow_corrected ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of $e_0$ for the Choo and Siow model, using the finite-sample correction log(p+(1-p)/(2N)) Args: muhat: a Matching Returns: the (X,Y) matrix of the first derivative of the entropy \"\"\" e0_val_corrected = _der_entropy_choo_siow_corrected ( muhat , hessian = False ) return e0_val_corrected","title":"e0_fun_choo_siow_corrected()"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mumu_choo_siow","text":"Returns the derivatives of \\(e_0\\) in \\(\\mu\\) for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the three components of the hessian wrt \\((\\mu,\\mu)\\) of the entropy Source code in cupid_matching/choo_siow.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def hessian_mumu_choo_siow ( muhat : Matching ) -> ThreeArrays : \"\"\"Returns the derivatives of $e_0$ in $\\\\mu$ for the Choo and Siow model. Args: muhat: a Matching Returns: the three components of the hessian wrt $(\\\\mu,\\\\mu)$ of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 2 ) hessmumu = entropy_res [ 2 ] muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2xy = hessmumu [ x , y , :, :] hess_x [ x , y , :] = d2xy [ x , :] hess_y [ x , y , :] = d2xy [:, y ] hess_xy [ x , y ] = d2xy [ x , y ] return hess_x , hess_y , hess_xy","title":"hessian_mumu_choo_siow()"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mumu_choo_siow_corrected","text":"Returns the derivatives of \\(e_0\\) in \\(\\mu\\) for the Choo and Siow model, with the small sample correction Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the three components of the hessian wrt \\((\\mu,\\mu)\\) of the entropy Source code in cupid_matching/choo_siow.py 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 def hessian_mumu_choo_siow_corrected ( muhat : Matching ) -> ThreeArrays : \"\"\"Returns the derivatives of $e_0$ in $\\\\mu$ for the Choo and Siow model, with the small sample correction Args: muhat: a Matching Returns: the three components of the hessian wrt $(\\\\mu,\\\\mu)$ of the entropy \"\"\" _ , hessmumu , _ = _der_entropy_choo_siow_corrected ( muhat , hessian = True ) muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2xy = hessmumu [ x , y , :, :] hess_x [ x , y , :] = d2xy [ x , :] hess_y [ x , y , :] = d2xy [:, y ] hess_xy [ x , y ] = d2xy [ x , y ] return hess_x , hess_y , hess_xy","title":"hessian_mumu_choo_siow_corrected()"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mur_choo_siow","text":"Returns the derivatives of \\(e_0\\) in \\(r\\) for the Choo and Siow model. Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the two components of the hessian wrt \\((\\mu,r)\\) of the entropy Source code in cupid_matching/choo_siow.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 def hessian_mur_choo_siow ( muhat : Matching ) -> TwoArrays : \"\"\"Returns the derivatives of $e_0$ in $r$ for the Choo and Siow model. Args: muhat: a Matching Returns: the two components of the hessian wrt $(\\\\mu,r)$ of the entropy \"\"\" entropy_res = _entropy_choo_siow ( muhat , deriv = 2 ) hessmur = entropy_res [ 3 ] muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_nx = np . zeros (( X , Y )) hess_my = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2r = hessmur [ x , y , :] hess_nx [ x , y ] = d2r [ x ] hess_my [ x , y ] = d2r [ X + y ] return hess_nx , hess_my","title":"hessian_mur_choo_siow()"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mur_choo_siow_corrected","text":"Returns the derivatives of \\(e_0\\) in \\(r\\) for the Choo and Siow model, with the small sample correction Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the two components of the hessian wrt \\((\\mu,r)\\) of the entropy Source code in cupid_matching/choo_siow.py 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 def hessian_mur_choo_siow_corrected ( muhat : Matching ) -> TwoArrays : \"\"\"Returns the derivatives of $e_0$ in $r$ for the Choo and Siow model, with the small sample correction Args: muhat: a Matching Returns: the two components of the hessian wrt $(\\\\mu,r)$ of the entropy \"\"\" _ , _ , hessmur = _der_entropy_choo_siow_corrected ( muhat , hessian = True ) muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_nx = np . zeros (( X , Y )) hess_my = np . zeros (( X , Y )) for x in range ( X ): for y in range ( Y ): d2r = hessmur [ x , y , :] hess_nx [ x , y ] = d2r [ x ] hess_my [ x , y ] = d2r [ X + y ] return hess_nx , hess_my","title":"hessian_mur_choo_siow_corrected()"},{"location":"choo_siow_gender_heteroskedastic/","text":"choo_siow_gender_heteroskedastic module \u00b6 The components of the derivative of the entropy for the Choo and Siow gender-heteroskedastic model. We normalize the standard error for the X side at 1, and we estimate the standard error on the Y side. e0_choo_siow_gender_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-independent part \\(e_0\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def e0_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" muxy , mux0 , * _ = muhat . unpack () e0_vals = - np . log ( muxy / mux0 . reshape (( - 1 , 1 ))) return cast ( np . ndarray , e0_vals ) e0_derivative_mu_gender_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-independent part \\(e_0\\) in \\(\\mu\\) . for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt \\((\\mu,\\mu)\\) . Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def e0_derivative_mu_gender_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ in $\\\\mu$. for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$. Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu,\\\\mu)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 for x in range ( X ): dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_x [ x , y , :] = - dlogx0 hess_xy [ x , y ] = - der_logxy [ x , y ] - dlogx0 return hess_x , hess_y , hess_xy e0_derivative_r_gender_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(r\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt \\((\\mu,r)\\) . Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def e0_derivative_r_gender_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$. Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu,r)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 for x in range ( X ): dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_n [ x , y ] = dlogx0 return hess_n , hess_m e_choo_siow_gender_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-dependent part \\(e\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y,1) array of the parameter-dependent part np . ndarray of the first derivative of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def e_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y,1) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 e_vals = np . zeros (( X , Y , n_alpha )) e_vals [:, :, 0 ] = - np . log ( muxy / mu0y ) return e_vals e_derivative_mu_gender_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(\\mu\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma_1=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt \\((\\mu,\\mu)\\) . Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 def e_derivative_mu_gender_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\\\mu$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma_1=1$. Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\\\mu,\\\\mu)$. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_log0y = 1.0 / mu0y for x in range ( X ): for y in range ( Y ): dlog0y = der_log0y [ y ] hess_y [ x , y , :, 0 ] = - dlog0y hess_xy [ x , y , 0 ] = - der_logxy [ x , y ] - dlog0y return hess_x , hess_y , hess_xy e_derivative_r_gender_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(r\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma_1=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt \\((\\mu,r)\\) Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def e_derivative_r_gender_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma_1=1$. Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\\\mu,r)$ \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_log0y = 1.0 / mu0y for x in range ( X ): for y in range ( Y ): dlog0y = der_log0y [ y ] hess_m [ x , y , 0 ] = dlog0y return hess_n , hess_m","title":"Choo-Siow Gender-heteroskedastic"},{"location":"choo_siow_gender_heteroskedastic/#choo_siow_gender_heteroskedastic-module","text":"The components of the derivative of the entropy for the Choo and Siow gender-heteroskedastic model. We normalize the standard error for the X side at 1, and we estimate the standard error on the Y side.","title":"choo_siow_gender_heteroskedastic module"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e0_choo_siow_gender_heteroskedastic","text":"Returns the values of the parameter-independent part \\(e_0\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def e0_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" muxy , mux0 , * _ = muhat . unpack () e0_vals = - np . log ( muxy / mux0 . reshape (( - 1 , 1 ))) return cast ( np . ndarray , e0_vals )","title":"e0_choo_siow_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e0_derivative_mu_gender_heteroskedastic","text":"Returns the derivatives of the parameter-independent part \\(e_0\\) in \\(\\mu\\) . for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt \\((\\mu,\\mu)\\) . Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def e0_derivative_mu_gender_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ in $\\\\mu$. for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$. Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu,\\\\mu)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 for x in range ( X ): dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_x [ x , y , :] = - dlogx0 hess_xy [ x , y ] = - der_logxy [ x , y ] - dlogx0 return hess_x , hess_y , hess_xy","title":"e0_derivative_mu_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e0_derivative_r_gender_heteroskedastic","text":"Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(r\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt \\((\\mu,r)\\) . Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def e0_derivative_r_gender_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$. Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu,r)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 for x in range ( X ): dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_n [ x , y ] = dlogx0 return hess_n , hess_m","title":"e0_derivative_r_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e_choo_siow_gender_heteroskedastic","text":"Returns the values of the parameter-dependent part \\(e\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y,1) array of the parameter-dependent part np . ndarray of the first derivative of the entropy. Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def e_choo_siow_gender_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$. Args: muhat: a Matching Returns: the (X,Y,1) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 e_vals = np . zeros (( X , Y , n_alpha )) e_vals [:, :, 0 ] = - np . log ( muxy / mu0y ) return e_vals","title":"e_choo_siow_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e_derivative_mu_gender_heteroskedastic","text":"Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(\\mu\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma_1=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt \\((\\mu,\\mu)\\) . Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 def e_derivative_mu_gender_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\\\mu$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma_1=1$. Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\\\mu,\\\\mu)$. \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_log0y = 1.0 / mu0y for x in range ( X ): for y in range ( Y ): dlog0y = der_log0y [ y ] hess_y [ x , y , :, 0 ] = - dlog0y hess_xy [ x , y , 0 ] = - der_logxy [ x , y ] - dlog0y return hess_x , hess_y , hess_xy","title":"e_derivative_mu_gender_heteroskedastic()"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e_derivative_r_gender_heteroskedastic","text":"Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(r\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma_1=1\\) . Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt \\((\\mu,r)\\) Source code in cupid_matching/choo_siow_gender_heteroskedastic.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def e_derivative_r_gender_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma_1=1$. Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\\\mu,r)$ \"\"\" muxy , _ , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = 1 hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_log0y = 1.0 / mu0y for x in range ( X ): for y in range ( Y ): dlog0y = der_log0y [ y ] hess_m [ x , y , 0 ] = dlog0y return hess_n , hess_m","title":"e_derivative_r_gender_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/","text":"choo_siow_heteroskedastic module \u00b6 The components of the derivative of the entropy for the Choo and Siow fully heteroskedastic model. We normalize the standard error for X=1 at 1, and we estimate the standard errors for all other types on the X side and for all types on the Y side. e0_choo_siow_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-independent part \\(e_0\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy Source code in cupid_matching/choo_siow_heteroskedastic.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def e0_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy \"\"\" muxy , mux0 , * _ = muhat . unpack () mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] e0_vals = np . zeros_like ( muxy ) e0_vals [ 0 , :] = - np . log ( mu1y / mu10 ) return cast ( np . ndarray , e0_vals ) e0_derivative_mu_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(\\mu\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt \\((\\mu, \\mu)\\) . Source code in cupid_matching/choo_siow_heteroskedastic.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def e0_derivative_mu_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $\\\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu, \\\\mu)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_log1y = 1.0 / mu1y der_log10 = 1.0 / mu10 for y in range ( Y ): hess_x [ 0 , y , :] = - der_log10 hess_xy [ 0 , y ] = - der_log1y [ y ] - der_log10 return hess_x , hess_y , hess_xy e0_derivative_r_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(r\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt \\((\\mu,r)\\) . Source code in cupid_matching/choo_siow_heteroskedastic.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def e0_derivative_r_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu,r)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape mu10 = mux0 [ 0 ] hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_log10 = 1.0 / mu10 for y in range ( Y ): hess_n [ 0 , y ] = der_log10 return hess_n , hess_m e_choo_siow_heteroskedastic ( muhat ) \u00b6 Returns the values of the parameter-dependent part \\(e\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_heteroskedastic.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def e_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 e_vals = np . zeros (( X , Y , n_alpha )) i = 0 for x in range ( 1 , X ): e_vals [ x , :, i ] = - np . log ( muxy [ x , :] / mux0 [ x ]) i += 1 for y in range ( Y ): e_vals [:, y , i ] = - np . log ( muxy [:, y ] / mu0y [ y ]) i += 1 return e_vals e_derivative_mu_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(\\mu\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt \\((\\mu,\\mu)\\) . Source code in cupid_matching/choo_siow_heteroskedastic.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def e_derivative_mu_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\\\mu,\\\\mu)$. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y i = 0 for x in range ( 1 , X ): # derivatives wrt sigma_x dlogx0 = der_logx0 [ x ] dlogxy = der_logxy [ x , :] for y in range ( Y ): hess_x [ x , y , :, i ] = - dlogx0 hess_xy [ x , y , i ] = - dlogxy [ y ] - dlogx0 i += 1 for y in range ( Y ): # derivatives wrt tau_y dlog0y = der_log0y [ y ] dlogxy = der_logxy [:, y ] for x in range ( X ): hess_y [ x , y , :, i ] = - dlog0y hess_xy [ x , y , i ] = - dlogxy [ x ] - dlog0y i += 1 return hess_x , hess_y , hess_xy e_derivative_r_heteroskedastic ( muhat ) \u00b6 Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(r\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt \\(r\\) . Source code in cupid_matching/choo_siow_heteroskedastic.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def e_derivative_r_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $r$. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y i = 0 for x in range ( 1 , X ): # derivatives wrt sigma_x dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_n [ x , y , i ] = dlogx0 i += 1 for y in range ( Y ): # derivatives wrt tau_y dlog0y = der_log0y [ y ] for x in range ( X ): hess_m [ x , y , i ] = dlog0y i += 1 return hess_n , hess_m","title":"Choo-Siow Heteroskedastic"},{"location":"choo_siow_heteroskedastic/#choo_siow_heteroskedastic-module","text":"The components of the derivative of the entropy for the Choo and Siow fully heteroskedastic model. We normalize the standard error for X=1 at 1, and we estimate the standard errors for all other types on the X side and for all types on the Y side.","title":"choo_siow_heteroskedastic module"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e0_choo_siow_heteroskedastic","text":"Returns the values of the parameter-independent part \\(e_0\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy Source code in cupid_matching/choo_siow_heteroskedastic.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def e0_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy \"\"\" muxy , mux0 , * _ = muhat . unpack () mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] e0_vals = np . zeros_like ( muxy ) e0_vals [ 0 , :] = - np . log ( mu1y / mu10 ) return cast ( np . ndarray , e0_vals )","title":"e0_choo_siow_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e0_derivative_mu_heteroskedastic","text":"Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(\\mu\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt \\((\\mu, \\mu)\\) . Source code in cupid_matching/choo_siow_heteroskedastic.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def e0_derivative_mu_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $\\\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu, \\\\mu)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape mu1y = muxy [ 0 , :] mu10 = mux0 [ 0 ] hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_log1y = 1.0 / mu1y der_log10 = 1.0 / mu10 for y in range ( Y ): hess_x [ 0 , y , :] = - der_log10 hess_xy [ 0 , y ] = - der_log1y [ y ] - der_log10 return hess_x , hess_y , hess_xy","title":"e0_derivative_mu_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e0_derivative_r_heteroskedastic","text":"Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(r\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt \\((\\mu,r)\\) . Source code in cupid_matching/choo_siow_heteroskedastic.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def e0_derivative_r_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu,r)$. \"\"\" muxy , mux0 , * _ = muhat . unpack () X , Y = muxy . shape mu10 = mux0 [ 0 ] hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_log10 = 1.0 / mu10 for y in range ( Y ): hess_n [ 0 , y ] = der_log10 return hess_n , hess_m","title":"e0_derivative_r_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e_choo_siow_heteroskedastic","text":"Returns the values of the parameter-dependent part \\(e\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description np . ndarray the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. Source code in cupid_matching/choo_siow_heteroskedastic.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def e_choo_siow_heteroskedastic ( muhat : Matching ) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 e_vals = np . zeros (( X , Y , n_alpha )) i = 0 for x in range ( 1 , X ): e_vals [ x , :, i ] = - np . log ( muxy [ x , :] / mux0 [ x ]) i += 1 for y in range ( Y ): e_vals [:, y , i ] = - np . log ( muxy [:, y ] / mu0y [ y ]) i += 1 return e_vals","title":"e_choo_siow_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e_derivative_mu_heteroskedastic","text":"Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(\\mu\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt \\((\\mu,\\mu)\\) . Source code in cupid_matching/choo_siow_heteroskedastic.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def e_derivative_mu_heteroskedastic ( muhat : Matching , ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\\\mu$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\\\mu,\\\\mu)$. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y i = 0 for x in range ( 1 , X ): # derivatives wrt sigma_x dlogx0 = der_logx0 [ x ] dlogxy = der_logxy [ x , :] for y in range ( Y ): hess_x [ x , y , :, i ] = - dlogx0 hess_xy [ x , y , i ] = - dlogxy [ y ] - dlogx0 i += 1 for y in range ( Y ): # derivatives wrt tau_y dlog0y = der_log0y [ y ] dlogxy = der_logxy [:, y ] for x in range ( X ): hess_y [ x , y , :, i ] = - dlog0y hess_xy [ x , y , i ] = - dlogxy [ x ] - dlog0y i += 1 return hess_x , hess_y , hess_xy","title":"e_derivative_mu_heteroskedastic()"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e_derivative_r_heteroskedastic","text":"Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(r\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\) Parameters: Name Type Description Default muhat Matching a Matching required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt \\(r\\) . Source code in cupid_matching/choo_siow_heteroskedastic.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def e_derivative_r_heteroskedastic ( muhat : Matching , ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the Choo and Siow heteroskedastic model; we normalized $\\\\sigma_1=1$ Args: muhat: a Matching Returns: the parameter-dependent part of the hessian of the entropy wrt $r$. \"\"\" muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape n_alpha = X + Y - 1 hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y i = 0 for x in range ( 1 , X ): # derivatives wrt sigma_x dlogx0 = der_logx0 [ x ] for y in range ( Y ): hess_n [ x , y , i ] = dlogx0 i += 1 for y in range ( Y ): # derivatives wrt tau_y dlog0y = der_log0y [ y ] for x in range ( X ): hess_m [ x , y , i ] = dlog0y i += 1 return hess_n , hess_m","title":"e_derivative_r_heteroskedastic()"},{"location":"cupid_streamlit/","text":"cupid_streamlit module \u00b6 An interactive Streamlit application that solves for the stable matching and estimates the parameters of the joint surplus in a Choo and Siow 2006 homoskedastic model.","title":"Code for a Streamlit app"},{"location":"cupid_streamlit/#cupid_streamlit-module","text":"An interactive Streamlit application that solves for the stable matching and estimates the parameters of the joint surplus in a Choo and Siow 2006 homoskedastic model.","title":"cupid_streamlit module"},{"location":"entropy/","text":"entropy module \u00b6 Entropies and their derivatives. EntropyHessianComponents = tuple [ ThreeArrays , TwoArrays ] module-attribute \u00b6 combines the tuples of the values of the components of the hessians. EntropyHessianMuMu = Callable [[ Matching ], ThreeArrays ] module-attribute \u00b6 The type of a function that takes in a Matching and returns the three components of the hessian of the entropy wrt \\((\\mu,\\mu)\\) . EntropyHessianMuMuParam = Callable [[ Matching , list [ Any ]], ThreeArrays ] module-attribute \u00b6 The type of a function that takes in a Matching and a list of additional parameters and returns the three components of the hessian of the entropy wrt \\((\\mu,\\mu)\\) . EntropyHessianMuR = Callable [[ Matching ], TwoArrays ] module-attribute \u00b6 The type of a function that takes in a Matching and returns the two components of the hessian of the entropy wrt \\((\\mu,n)\\) and \\((\\mu, m))\\) . EntropyHessianMuRParam = Callable [[ Matching , list [ Any ]], TwoArrays ] module-attribute \u00b6 The type of a function that takes in a Matching and a list of additional parameters and returns the two components of the hessian of the entropy wrt \\((\\mu,n)\\) and \\((\\mu, m))\\) . EntropyHessians = tuple [ EntropyHessianMuMu , EntropyHessianMuR ] module-attribute \u00b6 combines the hessian functions EntropyHessiansParam = tuple [ EntropyHessianMuMuParam , EntropyHessianMuRParam ] module-attribute \u00b6 combines the hessian functions when additional parameters are used EntropyFunctions dataclass \u00b6 Defines the entropy used, via the derivative \\(e_0 + e \\cdot \\alpha\\) Attributes: Name Type Description e0_fun MatchingFunction | MatchingFunctionParam required parameter_dependent bool if True , the entropy depends on parameters. Defaults to False e_fun MatchingFunction | MatchingFunctionParam | None only in entropies that depend on parameters. Defaults to None hessian str | None defaults to \"numeric\" * if \"provided\" , we provide the hessian of the entropy. * if \"numerical\" , it is compute_d by central differences. e0_derivative EntropyHessians | EntropyHessiansParam | None the derivative of e0_fun , if available. Defaults to None e_derivative EntropyHessians | EntropyHessiansParam | None the derivative of e_fun , if available. Defaults to None additional_parameters list | None additional parameters that define the distribution of errors. Defaults to None description str | None some text describing the model. Defaults to None Examples: See entropy_choo_siow in choo_siow.py Source code in cupid_matching/entropy.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 @dataclass class EntropyFunctions : \"\"\"Defines the entropy used, via the derivative $e_0 + e \\\\cdot \\\\alpha$ Attributes: e0_fun: required parameter_dependent: if `True`, the entropy depends on parameters. Defaults to `False` e_fun: only in entropies that depend on parameters. Defaults to `None` hessian: defaults to `\"numeric\"` * if `\"provided\"`, we provide the hessian of the entropy. * if `\"numerical\"`, it is compute_d by central differences. e0_derivative: the derivative of `e0_fun`, if available. Defaults to `None` e_derivative: the derivative of `e_fun`, if available. Defaults to `None` additional_parameters: additional parameters that define the distribution of errors. Defaults to `None` description: some text describing the model. Defaults to `None` Examples: See `entropy_choo_siow` in `choo_siow.py` \"\"\" e0_fun : MatchingFunction | MatchingFunctionParam e0_derivative : EntropyHessians | EntropyHessiansParam | None = None additional_parameters : list | None = None description : str | None = None e_fun : MatchingFunction | MatchingFunctionParam | None = None e_derivative : EntropyHessians | EntropyHessiansParam | None = None hessian : str | None = \"numerical\" parameter_dependent : bool = False def __post_init__ ( self ): if ( ( not self . parameter_dependent ) and self . hessian == \"provided\" and self . e0_derivative is None ): bs_error_abort ( \"You claim to provide the hessian \" + \"but you did not provide the e0_derivative.\" ) if self . parameter_dependent : if self . e_fun is None : bs_error_abort ( \"Your entropy is parameter dependent \" + \" but you did not provide the e_fun.\" ) if self . hessian == \"provided\" and self . e_derivative is None : bs_error_abort ( \"Your entropy is parameter dependent, \" + \"you claim to provide the hessian, \\n \" + \" but I do not see the e_derivative.\" ) entropy_gradient ( entropy , muhat , alpha = None , additional_parameters = None ) \u00b6 Computes the derivative of the entropy wrt \\(\\mu\\) at \\((\\mu, n, m, \\alpha, p)\\) Parameters: Name Type Description Default entropy EntropyFunctions the EntropyFunctions object required muhat Matching a Matching required alpha np . ndarray | None a vector of parameters of the derivative of the entropy, if any None additional_parameters list | None a list of additional parameters p , if any None Returns: Type Description np . ndarray the derivative of the entropy wrt \\(\\mu\\) np . ndarray at \\((\\mu, n, m, \\alpha, p)\\) . Source code in cupid_matching/entropy.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def entropy_gradient ( entropy : EntropyFunctions , muhat : Matching , alpha : np . ndarray | None = None , additional_parameters : list | None = None , ) -> np . ndarray : \"\"\"Computes the derivative of the entropy wrt $\\\\mu$ at $(\\\\mu, n, m, \\\\alpha, p)$ Args: entropy: the `EntropyFunctions` object muhat: a Matching alpha: a vector of parameters of the derivative of the entropy, if any additional_parameters: a list of additional parameters `p`, if any Returns: the derivative of the entropy wrt $\\\\mu$ at $(\\\\mu, n, m, \\\\alpha, p)$. \"\"\" e0_fun = entropy . e0_fun if additional_parameters is not None : e0_fun = cast ( MatchingFunctionParam , e0_fun ) e0_vals = e0_fun ( muhat , additional_parameters ) else : e0_fun = cast ( MatchingFunction , e0_fun ) e0_vals = e0_fun ( muhat ) parameter_dependent = entropy . parameter_dependent if parameter_dependent : if alpha is None : bs_error_abort ( \"alpha should be specified for this model\" ) e_fun = entropy . e_fun if e_fun is None : bs_error_abort ( \"we should have an e_fun in this model\" ) else : if additional_parameters is not None : e_fun = cast ( MatchingFunctionParam , e_fun ) e_vals = e_fun ( muhat , additional_parameters ) else : e_fun = cast ( MatchingFunction , e_fun ) e_vals = e_fun ( muhat ) return cast ( np . ndarray , e0_vals + e_vals @ alpha ) else : return e0_vals","title":"Entropy utilities"},{"location":"entropy/#entropy-module","text":"Entropies and their derivatives.","title":"entropy module"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianComponents","text":"combines the tuples of the values of the components of the hessians.","title":"EntropyHessianComponents"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianMuMu","text":"The type of a function that takes in a Matching and returns the three components of the hessian of the entropy wrt \\((\\mu,\\mu)\\) .","title":"EntropyHessianMuMu"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianMuMuParam","text":"The type of a function that takes in a Matching and a list of additional parameters and returns the three components of the hessian of the entropy wrt \\((\\mu,\\mu)\\) .","title":"EntropyHessianMuMuParam"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianMuR","text":"The type of a function that takes in a Matching and returns the two components of the hessian of the entropy wrt \\((\\mu,n)\\) and \\((\\mu, m))\\) .","title":"EntropyHessianMuR"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianMuRParam","text":"The type of a function that takes in a Matching and a list of additional parameters and returns the two components of the hessian of the entropy wrt \\((\\mu,n)\\) and \\((\\mu, m))\\) .","title":"EntropyHessianMuRParam"},{"location":"entropy/#cupid_matching.entropy.EntropyHessians","text":"combines the hessian functions","title":"EntropyHessians"},{"location":"entropy/#cupid_matching.entropy.EntropyHessiansParam","text":"combines the hessian functions when additional parameters are used","title":"EntropyHessiansParam"},{"location":"entropy/#cupid_matching.entropy.EntropyFunctions","text":"Defines the entropy used, via the derivative \\(e_0 + e \\cdot \\alpha\\) Attributes: Name Type Description e0_fun MatchingFunction | MatchingFunctionParam required parameter_dependent bool if True , the entropy depends on parameters. Defaults to False e_fun MatchingFunction | MatchingFunctionParam | None only in entropies that depend on parameters. Defaults to None hessian str | None defaults to \"numeric\" * if \"provided\" , we provide the hessian of the entropy. * if \"numerical\" , it is compute_d by central differences. e0_derivative EntropyHessians | EntropyHessiansParam | None the derivative of e0_fun , if available. Defaults to None e_derivative EntropyHessians | EntropyHessiansParam | None the derivative of e_fun , if available. Defaults to None additional_parameters list | None additional parameters that define the distribution of errors. Defaults to None description str | None some text describing the model. Defaults to None Examples: See entropy_choo_siow in choo_siow.py Source code in cupid_matching/entropy.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 @dataclass class EntropyFunctions : \"\"\"Defines the entropy used, via the derivative $e_0 + e \\\\cdot \\\\alpha$ Attributes: e0_fun: required parameter_dependent: if `True`, the entropy depends on parameters. Defaults to `False` e_fun: only in entropies that depend on parameters. Defaults to `None` hessian: defaults to `\"numeric\"` * if `\"provided\"`, we provide the hessian of the entropy. * if `\"numerical\"`, it is compute_d by central differences. e0_derivative: the derivative of `e0_fun`, if available. Defaults to `None` e_derivative: the derivative of `e_fun`, if available. Defaults to `None` additional_parameters: additional parameters that define the distribution of errors. Defaults to `None` description: some text describing the model. Defaults to `None` Examples: See `entropy_choo_siow` in `choo_siow.py` \"\"\" e0_fun : MatchingFunction | MatchingFunctionParam e0_derivative : EntropyHessians | EntropyHessiansParam | None = None additional_parameters : list | None = None description : str | None = None e_fun : MatchingFunction | MatchingFunctionParam | None = None e_derivative : EntropyHessians | EntropyHessiansParam | None = None hessian : str | None = \"numerical\" parameter_dependent : bool = False def __post_init__ ( self ): if ( ( not self . parameter_dependent ) and self . hessian == \"provided\" and self . e0_derivative is None ): bs_error_abort ( \"You claim to provide the hessian \" + \"but you did not provide the e0_derivative.\" ) if self . parameter_dependent : if self . e_fun is None : bs_error_abort ( \"Your entropy is parameter dependent \" + \" but you did not provide the e_fun.\" ) if self . hessian == \"provided\" and self . e_derivative is None : bs_error_abort ( \"Your entropy is parameter dependent, \" + \"you claim to provide the hessian, \\n \" + \" but I do not see the e_derivative.\" )","title":"EntropyFunctions"},{"location":"entropy/#cupid_matching.entropy.entropy_gradient","text":"Computes the derivative of the entropy wrt \\(\\mu\\) at \\((\\mu, n, m, \\alpha, p)\\) Parameters: Name Type Description Default entropy EntropyFunctions the EntropyFunctions object required muhat Matching a Matching required alpha np . ndarray | None a vector of parameters of the derivative of the entropy, if any None additional_parameters list | None a list of additional parameters p , if any None Returns: Type Description np . ndarray the derivative of the entropy wrt \\(\\mu\\) np . ndarray at \\((\\mu, n, m, \\alpha, p)\\) . Source code in cupid_matching/entropy.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def entropy_gradient ( entropy : EntropyFunctions , muhat : Matching , alpha : np . ndarray | None = None , additional_parameters : list | None = None , ) -> np . ndarray : \"\"\"Computes the derivative of the entropy wrt $\\\\mu$ at $(\\\\mu, n, m, \\\\alpha, p)$ Args: entropy: the `EntropyFunctions` object muhat: a Matching alpha: a vector of parameters of the derivative of the entropy, if any additional_parameters: a list of additional parameters `p`, if any Returns: the derivative of the entropy wrt $\\\\mu$ at $(\\\\mu, n, m, \\\\alpha, p)$. \"\"\" e0_fun = entropy . e0_fun if additional_parameters is not None : e0_fun = cast ( MatchingFunctionParam , e0_fun ) e0_vals = e0_fun ( muhat , additional_parameters ) else : e0_fun = cast ( MatchingFunction , e0_fun ) e0_vals = e0_fun ( muhat ) parameter_dependent = entropy . parameter_dependent if parameter_dependent : if alpha is None : bs_error_abort ( \"alpha should be specified for this model\" ) e_fun = entropy . e_fun if e_fun is None : bs_error_abort ( \"we should have an e_fun in this model\" ) else : if additional_parameters is not None : e_fun = cast ( MatchingFunctionParam , e_fun ) e_vals = e_fun ( muhat , additional_parameters ) else : e_fun = cast ( MatchingFunction , e_fun ) e_vals = e_fun ( muhat ) return cast ( np . ndarray , e0_vals + e_vals @ alpha ) else : return e0_vals","title":"entropy_gradient()"},{"location":"example_choo_siow/","text":"example_choosiow module \u00b6 example using the Choo and Siow homoskedastic model create_choosiow_population ( X , Y , K , std_betas ) \u00b6 we simulate a Choo and Siow population with equal numbers of men and women of each type and random bases dunctions and coefficients 1 2 3 4 5 6 7 8 9 Args: X: number of types of men Y: number of types of women K: random basis functions std_betas: the coefficients are drawn from a centered normal with this standard deviation Returns: a ChooSiowPrimitives instance, the basis functions, and the coefficients Source code in cupid_matching/example_choo_siow.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def create_choosiow_population ( X : int , Y : int , K : int , std_betas : float ) -> tuple [ ChooSiowPrimitives , np . ndarray , np . ndarray ]: \"\"\" we simulate a Choo and Siow population with equal numbers of men and women of each type and random bases dunctions and coefficients Args: X: number of types of men Y: number of types of women K: random basis functions std_betas: the coefficients are drawn from a centered normal with this standard deviation Returns: a ChooSiowPrimitives instance, the basis functions, and the coefficients \"\"\" betas_true = std_betas * np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ betas_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) return choo_siow_instance , phi_bases , betas_true demo_choo_siow ( n_households , X , Y , K , std_betas = 1.0 ) \u00b6 run four MDE estimators and the Poisson estimator on randomly generated data Parameters: Name Type Description Default n_households int number of households required X int number of types of men required Y int number of types of women required K int number of basis functions required std_betas float the standard errors of their coefficients 1.0 Returns: Type Description tuple [ float , float , float , float , float ] the discrepancies of the five estimators Source code in cupid_matching/example_choo_siow.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def demo_choo_siow ( n_households : int , X : int , Y : int , K : int , std_betas : float = 1.0 ) -> tuple [ float , float , float , float , float ]: \"\"\"run four MDE estimators and the Poisson estimator on randomly generated data Args: n_households: number of households X: number of types of men Y: number of types of women K: number of basis functions std_betas: the standard errors of their coefficients Returns: the discrepancies of the five estimators \"\"\" choo_siow_instance , phi_bases , betas_true = create_choosiow_population ( X , Y , K , std_betas ) mus_sim = choo_siow_instance . simulate ( n_households ) # we estimate using four variants of the minimum distance estimator mde_discrepancy = mde_estimate ( mus_sim , phi_bases , betas_true , entropy_choo_siow , \"RESULTS FOR MDE WITH ANALYTICAL GRADIENT\" , ) mde_discrepancy_numeric = mde_estimate ( mus_sim , phi_bases , betas_true , entropy_choo_siow_numeric , \"RESULTS FOR MDE WITH NUMERICAL GRADIENT\" , ) mde_discrepancy_corrected = mde_estimate ( mus_sim , phi_bases , betas_true , entropy_choo_siow_corrected , \"RESULTS FOR THE CORRECTED MDE WITH ANALYTICAL GRADIENT\" , ) mde_discrepancy_corrected_numeric = mde_estimate ( mus_sim , phi_bases , betas_true , entropy_choo_siow_corrected_numeric , \"RESULTS FOR THE CORRECTED MDE WITH NUMERICAL GRADIENT\" , ) # we also estimate using Poisson GLM print_stars ( \" RESULTS FOR POISSON \" ) poisson_results = choo_siow_poisson_glm ( mus_sim , phi_bases ) _ , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () poisson_discrepancy = poisson_results . print_results ( betas_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ), ) return ( mde_discrepancy , mde_discrepancy_numeric , mde_discrepancy_corrected , mde_discrepancy_corrected_numeric , cast ( float , poisson_discrepancy ), ) mde_estimate ( mus_sim , phi_bases , betas_true , entropy , title ) \u00b6 we estimate the parameters using the minimum distance estimator Parameters: Name Type Description Default mus_sim Matching a Choo and Siow Matching required phi_bases np . ndarray the basis functions required betas_true np . ndarray their true coefficients required entropy EntropyFunctions the entropy functions we use required title str the name of the estimator required Returns: Type Description float the largest absolute difference between the true and estimated coefficients Source code in cupid_matching/example_choo_siow.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def mde_estimate ( mus_sim : Matching , phi_bases : np . ndarray , betas_true : np . ndarray , entropy : EntropyFunctions , title : str , ) -> float : \"\"\"we estimate the parameters using the minimum distance estimator Args: mus_sim: a Choo and Siow Matching phi_bases: the basis functions betas_true: their true coefficients entropy: the entropy functions we use title: the name of the estimator Returns: the largest absolute difference between the true and estimated coefficients \"\"\" print_stars ( f \" { title } \" ) mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy ) mde_discrepancy = mde_results . print_results ( true_coeffs = betas_true ) return cast ( float , mde_discrepancy )","title":"Example on the Choo and Siow model"},{"location":"example_choo_siow/#example_choosiow-module","text":"example using the Choo and Siow homoskedastic model","title":"example_choosiow module"},{"location":"example_choo_siow/#cupid_matching.example_choo_siow.create_choosiow_population","text":"we simulate a Choo and Siow population with equal numbers of men and women of each type and random bases dunctions and coefficients 1 2 3 4 5 6 7 8 9 Args: X: number of types of men Y: number of types of women K: random basis functions std_betas: the coefficients are drawn from a centered normal with this standard deviation Returns: a ChooSiowPrimitives instance, the basis functions, and the coefficients Source code in cupid_matching/example_choo_siow.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def create_choosiow_population ( X : int , Y : int , K : int , std_betas : float ) -> tuple [ ChooSiowPrimitives , np . ndarray , np . ndarray ]: \"\"\" we simulate a Choo and Siow population with equal numbers of men and women of each type and random bases dunctions and coefficients Args: X: number of types of men Y: number of types of women K: random basis functions std_betas: the coefficients are drawn from a centered normal with this standard deviation Returns: a ChooSiowPrimitives instance, the basis functions, and the coefficients \"\"\" betas_true = std_betas * np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ betas_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) return choo_siow_instance , phi_bases , betas_true","title":"create_choosiow_population()"},{"location":"example_choo_siow/#cupid_matching.example_choo_siow.demo_choo_siow","text":"run four MDE estimators and the Poisson estimator on randomly generated data Parameters: Name Type Description Default n_households int number of households required X int number of types of men required Y int number of types of women required K int number of basis functions required std_betas float the standard errors of their coefficients 1.0 Returns: Type Description tuple [ float , float , float , float , float ] the discrepancies of the five estimators Source code in cupid_matching/example_choo_siow.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def demo_choo_siow ( n_households : int , X : int , Y : int , K : int , std_betas : float = 1.0 ) -> tuple [ float , float , float , float , float ]: \"\"\"run four MDE estimators and the Poisson estimator on randomly generated data Args: n_households: number of households X: number of types of men Y: number of types of women K: number of basis functions std_betas: the standard errors of their coefficients Returns: the discrepancies of the five estimators \"\"\" choo_siow_instance , phi_bases , betas_true = create_choosiow_population ( X , Y , K , std_betas ) mus_sim = choo_siow_instance . simulate ( n_households ) # we estimate using four variants of the minimum distance estimator mde_discrepancy = mde_estimate ( mus_sim , phi_bases , betas_true , entropy_choo_siow , \"RESULTS FOR MDE WITH ANALYTICAL GRADIENT\" , ) mde_discrepancy_numeric = mde_estimate ( mus_sim , phi_bases , betas_true , entropy_choo_siow_numeric , \"RESULTS FOR MDE WITH NUMERICAL GRADIENT\" , ) mde_discrepancy_corrected = mde_estimate ( mus_sim , phi_bases , betas_true , entropy_choo_siow_corrected , \"RESULTS FOR THE CORRECTED MDE WITH ANALYTICAL GRADIENT\" , ) mde_discrepancy_corrected_numeric = mde_estimate ( mus_sim , phi_bases , betas_true , entropy_choo_siow_corrected_numeric , \"RESULTS FOR THE CORRECTED MDE WITH NUMERICAL GRADIENT\" , ) # we also estimate using Poisson GLM print_stars ( \" RESULTS FOR POISSON \" ) poisson_results = choo_siow_poisson_glm ( mus_sim , phi_bases ) _ , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () poisson_discrepancy = poisson_results . print_results ( betas_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ), ) return ( mde_discrepancy , mde_discrepancy_numeric , mde_discrepancy_corrected , mde_discrepancy_corrected_numeric , cast ( float , poisson_discrepancy ), )","title":"demo_choo_siow()"},{"location":"example_choo_siow/#cupid_matching.example_choo_siow.mde_estimate","text":"we estimate the parameters using the minimum distance estimator Parameters: Name Type Description Default mus_sim Matching a Choo and Siow Matching required phi_bases np . ndarray the basis functions required betas_true np . ndarray their true coefficients required entropy EntropyFunctions the entropy functions we use required title str the name of the estimator required Returns: Type Description float the largest absolute difference between the true and estimated coefficients Source code in cupid_matching/example_choo_siow.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def mde_estimate ( mus_sim : Matching , phi_bases : np . ndarray , betas_true : np . ndarray , entropy : EntropyFunctions , title : str , ) -> float : \"\"\"we estimate the parameters using the minimum distance estimator Args: mus_sim: a Choo and Siow Matching phi_bases: the basis functions betas_true: their true coefficients entropy: the entropy functions we use title: the name of the estimator Returns: the largest absolute difference between the true and estimated coefficients \"\"\" print_stars ( f \" { title } \" ) mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy ) mde_discrepancy = mde_results . print_results ( true_coeffs = betas_true ) return cast ( float , mde_discrepancy )","title":"mde_estimate()"},{"location":"example_nested_logit/","text":"example_nestedlogit module \u00b6 example using a simple two-layer nested logit model One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters. create_nestedlogit_population ( X , Y , K , std_alphas = 0.5 , std_betas = 1.0 ) \u00b6 we simulate a nested logit population with equal numbers of men and women of each type and random bases dunctions and coefficients 1 2 3 4 5 6 7 8 9 10 11 Args: X: number of types of men Y: number of types of women K: random basis functions std_alphas: the nest parameters are drawn from a U[0, std_alphas] distribution std_betas: the coefficients of the bases are drawn from a centered normal with this standard deviation Returns: a NestedLogitPrimitives instance, the basis functions, the true coefficients, and the entropy functions Source code in cupid_matching/example_nested_logit.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def create_nestedlogit_population ( X : int , Y : int , K : int , std_alphas : float = 0.5 , std_betas : float = 1.0 , ) -> tuple [ NestedLogitPrimitives , np . ndarray , np . ndarray , EntropyFunctions , EntropyFunctions , ]: \"\"\" we simulate a nested logit population with equal numbers of men and women of each type and random bases dunctions and coefficients Args: X: number of types of men Y: number of types of women K: random basis functions std_alphas: the nest parameters are drawn from a U[0, std_alphas] distribution std_betas: the coefficients of the bases are drawn from a centered normal with this standard deviation Returns: a NestedLogitPrimitives instance, the basis functions, the true coefficients, and the entropy functions \"\"\" X , Y , K = 10 , 12 , 5 nests_for_each_x = [ list ( range ( 1 , Y // 2 + 1 )), list ( range ( Y // 2 + 1 , Y + 1 )), ] nests_for_each_y = [ list ( range ( 1 , X // 2 + 1 )), list ( range ( X // 2 + 1 , X + 1 )), ] n = np . ones ( X ) m = np . ones ( Y ) phi_bases = np . random . randn ( X , Y , K ) ( entropy_nested_logit , entropy_nested_logit_numeric , ) = setup_standard_nested_logit ( nests_for_each_x , nests_for_each_y ) n_rhos , n_deltas = len ( nests_for_each_x ), len ( nests_for_each_y ) n_alphas = n_rhos + n_deltas betas_true = std_betas * np . random . randn ( K ) alphas_true = std_alphas * np . random . uniform ( size = n_alphas ) Phi = phi_bases @ betas_true nested_logit_instance = NestedLogitPrimitives ( Phi , n , m , nests_for_each_x , nests_for_each_y , alphas_true ) true_coeffs = np . concatenate (( alphas_true , betas_true )) return ( nested_logit_instance , phi_bases , true_coeffs , entropy_nested_logit , entropy_nested_logit_numeric , ) mde_estimate ( mus_sim , phi_bases , true_coeffs , entropy , title ) \u00b6 we estimate the parameters using the minimum distance estimator Parameters: Name Type Description Default mus_sim Matching a Choo and Siow Matching required phi_bases np . ndarray the basis functions required true_coeffs np . ndarray their true coefficients and the nesting parameters required entropy EntropyFunctions the entropy functions we use required title str the name of the estimator required Returns: Type Description float the largest absolute difference between the true and estimated coefficients Source code in cupid_matching/example_nested_logit.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def mde_estimate ( mus_sim : Matching , phi_bases : np . ndarray , true_coeffs : np . ndarray , entropy : EntropyFunctions , title : str , ) -> float : \"\"\"we estimate the parameters using the minimum distance estimator Args: mus_sim: a Choo and Siow Matching phi_bases: the basis functions true_coeffs: their true coefficients and the nesting parameters entropy: the entropy functions we use title: the name of the estimator Returns: the largest absolute difference between the true and estimated coefficients \"\"\" print_stars ( f \" { title } \" ) mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy , additional_parameters = entropy . additional_parameters , ) mde_discrepancy = mde_results . print_results ( true_coeffs = true_coeffs ) return cast ( float , mde_discrepancy )","title":"Example on a nested logit model"},{"location":"example_nested_logit/#example_nestedlogit-module","text":"example using a simple two-layer nested logit model One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters.","title":"example_nestedlogit module"},{"location":"example_nested_logit/#cupid_matching.example_nested_logit.create_nestedlogit_population","text":"we simulate a nested logit population with equal numbers of men and women of each type and random bases dunctions and coefficients 1 2 3 4 5 6 7 8 9 10 11 Args: X: number of types of men Y: number of types of women K: random basis functions std_alphas: the nest parameters are drawn from a U[0, std_alphas] distribution std_betas: the coefficients of the bases are drawn from a centered normal with this standard deviation Returns: a NestedLogitPrimitives instance, the basis functions, the true coefficients, and the entropy functions Source code in cupid_matching/example_nested_logit.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def create_nestedlogit_population ( X : int , Y : int , K : int , std_alphas : float = 0.5 , std_betas : float = 1.0 , ) -> tuple [ NestedLogitPrimitives , np . ndarray , np . ndarray , EntropyFunctions , EntropyFunctions , ]: \"\"\" we simulate a nested logit population with equal numbers of men and women of each type and random bases dunctions and coefficients Args: X: number of types of men Y: number of types of women K: random basis functions std_alphas: the nest parameters are drawn from a U[0, std_alphas] distribution std_betas: the coefficients of the bases are drawn from a centered normal with this standard deviation Returns: a NestedLogitPrimitives instance, the basis functions, the true coefficients, and the entropy functions \"\"\" X , Y , K = 10 , 12 , 5 nests_for_each_x = [ list ( range ( 1 , Y // 2 + 1 )), list ( range ( Y // 2 + 1 , Y + 1 )), ] nests_for_each_y = [ list ( range ( 1 , X // 2 + 1 )), list ( range ( X // 2 + 1 , X + 1 )), ] n = np . ones ( X ) m = np . ones ( Y ) phi_bases = np . random . randn ( X , Y , K ) ( entropy_nested_logit , entropy_nested_logit_numeric , ) = setup_standard_nested_logit ( nests_for_each_x , nests_for_each_y ) n_rhos , n_deltas = len ( nests_for_each_x ), len ( nests_for_each_y ) n_alphas = n_rhos + n_deltas betas_true = std_betas * np . random . randn ( K ) alphas_true = std_alphas * np . random . uniform ( size = n_alphas ) Phi = phi_bases @ betas_true nested_logit_instance = NestedLogitPrimitives ( Phi , n , m , nests_for_each_x , nests_for_each_y , alphas_true ) true_coeffs = np . concatenate (( alphas_true , betas_true )) return ( nested_logit_instance , phi_bases , true_coeffs , entropy_nested_logit , entropy_nested_logit_numeric , )","title":"create_nestedlogit_population()"},{"location":"example_nested_logit/#cupid_matching.example_nested_logit.mde_estimate","text":"we estimate the parameters using the minimum distance estimator Parameters: Name Type Description Default mus_sim Matching a Choo and Siow Matching required phi_bases np . ndarray the basis functions required true_coeffs np . ndarray their true coefficients and the nesting parameters required entropy EntropyFunctions the entropy functions we use required title str the name of the estimator required Returns: Type Description float the largest absolute difference between the true and estimated coefficients Source code in cupid_matching/example_nested_logit.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def mde_estimate ( mus_sim : Matching , phi_bases : np . ndarray , true_coeffs : np . ndarray , entropy : EntropyFunctions , title : str , ) -> float : \"\"\"we estimate the parameters using the minimum distance estimator Args: mus_sim: a Choo and Siow Matching phi_bases: the basis functions true_coeffs: their true coefficients and the nesting parameters entropy: the entropy functions we use title: the name of the estimator Returns: the largest absolute difference between the true and estimated coefficients \"\"\" print_stars ( f \" { title } \" ) mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy , additional_parameters = entropy . additional_parameters , ) mde_discrepancy = mde_results . print_results ( true_coeffs = true_coeffs ) return cast ( float , mde_discrepancy )","title":"mde_estimate()"},{"location":"ipfp_solvers/","text":"ipfp_solvers module \u00b6 Implementations of the IPFP algorithm to solve for equilibrium and do comparative statics in several variants of the Choo and Siow 2006 <https://www.jstor.org/stable/10.1086/498585?seq=1> _ model: homoskedastic with singles (as in Choo and Siow 2006) homoskedastic without singles gender-heteroskedastic: with a scale parameter on the error term for women gender- and type-heteroskedastic: with a scale parameter on the error term for each gender and type two-level nested logit, with nests and nest parameters that do not depend on the type, and {0} as the first nest Each solver, when fed the joint surplus and margins, returns the equilibrium matching patterns, the adding-up errors on the margins, and if requested (using gr=True ) the derivatives of the matching patterns in all primitives. ipfp_gender_heteroskedastic_solver ( Phi , men_margins , women_margins , tau , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter tau Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tau float the standard error for all women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns IPFPNoGradientResults | IPFPGradientResults wrt (men_margins, women_margins, Phi, tau) if gr is True Source code in cupid_matching/ipfp_solvers.py 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 def ipfp_gender_heteroskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tau : float , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter `tau` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tau: the standard error for all women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, tau) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if tau <= 0 : bs_error_abort ( f \"We need a positive tau, not { tau } \" ) ############################################################################# # we use ipfp_heteroxy_solver with sigma_x = 1 and tau_y = tau ############################################################################# sigma_x = np . ones ( X ) tau_y = np . full ( Y , tau ) if gr : ( mus_hxy , marg_err_x , marg_err_y , dmus_xy , dmus_x0 , dmus_0y , ) = ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = True , maxiter = maxiter , verbose = verbose , ) muxy , _ , _ , _ , _ = mus_hxy . unpack () n_sum_categories = X + Y n_prod_categories = X * Y n_cols = n_sum_categories + n_prod_categories itau_y = n_cols + X dmuxy = np . zeros (( n_prod_categories , n_cols + 1 )) dmuxy [:, : n_cols ] = dmus_xy [:, : n_cols ] dmuxy [:, - 1 ] = np . sum ( dmus_xy [:, itau_y :], 1 ) dmux0 = np . zeros (( X , n_cols + 1 )) dmux0 [:, : n_cols ] = dmus_x0 [:, : n_cols ] dmux0 [:, - 1 ] = np . sum ( dmus_x0 [:, itau_y :], 1 ) dmu0y = np . zeros (( Y , n_cols + 1 )) dmu0y [:, : n_cols ] = dmus_0y [:, : n_cols ] dmu0y [:, - 1 ] = np . sum ( dmus_0y [:, itau_y :], 1 ) return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , ) else : return ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = False , maxiter = maxiter , verbose = verbose , ) ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors sigma_x and tau_y Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required sigma_x np . ndarray the vector of standard errors for the X types of men required sigma_x np . ndarray the vector of standard errors for Y types of women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns IPFPNoGradientResults | IPFPGradientResults wrt (men_margins, women_margins, Phi, sigma_x, tau_y) IPFPNoGradientResults | IPFPGradientResults if gr is True Source code in cupid_matching/ipfp_solvers.py 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 def ipfp_heteroskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , sigma_x : np . ndarray , tau_y : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors `sigma_x` and `tau_y` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) sigma_x: the vector of standard errors for the X types of men sigma_x: the vector of standard errors for Y types of women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, sigma_x, tau_y) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if np . min ( sigma_x ) <= 0.0 : bs_error_abort ( \"All elements of sigma_x must be positive\" ) if np . min ( tau_y ) <= 0.0 : bs_error_abort ( \"All elements of tau_y must be positive\" ) sumxy1 = 1.0 / np . add . outer ( sigma_x , tau_y ) ephi2 , der_ephi2 = npexp ( Phi * sumxy1 , deriv = 1 ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # with tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi2 )) # we find the largest values of sigma_x and tau_y xmax = np . argmax ( sigma_x ) sigma_max = sigma_x [ xmax ] ymax = np . argmax ( tau_y ) tau_max = tau_y [ ymax ] # we use tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) sig_taumax = sigma_x + tau_max txi = np . power ( bigc , sigma_x / sig_taumax ) sigmax_tau = tau_y + sigma_max tyi = np . power ( bigc , tau_y / sigmax_tau ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc txin = txi . copy () mu0y_in = np . power ( np . power ( tyi , sigmax_tau ), 1.0 / tau_y ) while err_newton > tol_newton : txit = np . power ( txin , sig_taumax ) mux0_in = np . power ( txit , 1.0 / sigma_x ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y )) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) errxi = mux0_in + np . sum ( muxy_in , 1 ) - men_margins err_newton = npmaxabs ( errxi ) txin -= errxi / ( sig_taumax * ( mux0_in / sigma_x + np . sum ( sumxy1 * muxy_in , 1 )) / txin ) tx = txin # Newton iterates for women err_newton = bigc tyin = tyi . copy () mux0_in = np . power ( np . power ( tx , sig_taumax ), 1.0 / sigma_x ) while err_newton > tol_newton : tyit = np . power ( tyin , sigmax_tau ) mu0y_in = np . power ( tyit , 1.0 / tau_y ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y )) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) erryi = mu0y_in + np . sum ( muxy_in , 0 ) - women_margins err_newton = npmaxabs ( erryi ) tyin -= erryi / ( sigmax_tau * ( mu0y_in / tau_y + np . sum ( sumxy1 * muxy_in , 0 )) / tyin ) ty = tyin err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = mux0_in mu0y = mu0y_in muxy = muxy_in marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , ) else : # we compute_ the derivatives n_sum_categories = X + Y n_prod_categories = X * Y # we work directly with (mux0, mu0y) sigrat_xy = sumxy1 * sigma_x . reshape (( - 1 , 1 )) taurat_xy = 1.0 - sigrat_xy mux0_mat = nprepeat_col ( mux0 , Y ) mu0y_mat = nprepeat_row ( mu0y , X ) # muxy = axy * bxy * ephi2 axy = nppow ( mux0_mat , sigrat_xy ) bxy = nppow ( mu0y_mat , taurat_xy ) der_axy1 , der_axy2 = nppow ( mux0_mat , sigrat_xy , deriv = 1 ) der_bxy1 , der_bxy2 = nppow ( mu0y_mat , taurat_xy , deriv = 1 ) der_axy1_rat , der_axy2_rat = der_axy1 / axy , der_axy2 / axy der_bxy1_rat , der_bxy2_rat = der_bxy1 / bxy , der_bxy2 / bxy # start with the LHS of the linear system on (dmux0, dmu0y) lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 1.0 + np . sum ( muxy * der_axy1_rat , 1 )) lhs [: X , X :] = muxy * der_bxy1_rat lhs [ X :, X :] = np . diag ( 1.0 + np . sum ( muxy * der_bxy1_rat , 0 )) lhs [ X :, : X ] = ( muxy * der_axy1_rat ) . T # now fill the RHS (derivatives wrt men_margins, then men_margins, # then Phi, then sigma_x and tau_y) n_cols_rhs = n_sum_categories + n_prod_categories + X + Y rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute_ derivatives of (mux0, mu0y) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute_ derivatives of (mux0, mu0y) wrt women_margins rhs [ X :, X : n_sum_categories ] = np . eye ( Y ) # the next line is sumxy1 with safeguards sumxy1_safe = sumxy1 * der_ephi2 / ephi2 big_a = muxy * sumxy1_safe big_b = der_axy2_rat - der_bxy2_rat b_mu_s = big_b * muxy * sumxy1 a_phi = Phi * big_a big_c = sumxy1 * ( a_phi - b_mu_s * tau_y ) big_d = sumxy1 * ( a_phi + b_mu_s * sigma_x . reshape (( - 1 , 1 ))) # to compute_ derivatives of (mux0, mu0y) wrt Phi ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - big_a [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories iend_phi = n_sum_categories + n_prod_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : iend_phi : Y ] = - big_a [:, iwoman ] ivar1 += 1 ivar2 += 1 # to compute_ derivatives of (mux0, mu0y) wrt sigma_x iend_sig = iend_phi + X der_sigx = np . sum ( big_c , 1 ) rhs [: X , iend_phi : iend_sig ] = np . diag ( der_sigx ) rhs [ X :, iend_phi : iend_sig ] = big_c . T # to compute_ derivatives of (mux0, mu0y) wrt tau_y der_tauy = np . sum ( big_d , 0 ) rhs [ X :, iend_sig :] = np . diag ( der_tauy ) rhs [: X , iend_sig :] = big_d # solve for the derivatives of mux0 and mu0y dmu0 = spla . solve ( lhs , rhs ) dmux0 = dmu0 [: X , :] dmu0y = dmu0 [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) der1 = ephi2 * der_axy1 * bxy ivar = 0 for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), :] = np . outer ( der1 [ iman , :], dmux0 [ iman , :]) ivar += Y der2 = ephi2 * der_bxy1 * axy for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( der2 [:, iwoman ], dmu0y [ iwoman , :] ) # add the terms that comes from differentiating ephi2 # on the derivative wrt Phi i = 0 j = n_sum_categories for iman in range ( X ): for iwoman in range ( Y ): dmuxy [ i , j ] += big_a [ iman , iwoman ] i += 1 j += 1 # on the derivative wrt sigma_x ivar = 0 ix = iend_phi for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), ix ] -= big_c [ iman , :] ivar += Y ix += 1 # on the derivative wrt tau_y iy = iend_sig for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , iy ] -= big_d [:, iwoman ] iy += 1 return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , ) ipfp_homoskedastic_nosingles_solver ( Phi , men_margins , women_margins , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of \\((\\mu_{xy})\\) wrt \\(\\Phi\\) False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Name Type Description muxy ThreeArrays | FourArrays the matching patterns, shape (X, Y) ThreeArrays | FourArrays marg_err_x, marg_err_y: the errors on the margins ThreeArrays | FourArrays and the gradients of \\((\\mu_{xy})\\) wrt \\(\\Phi\\) if gr is True Source code in cupid_matching/ipfp_solvers.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 def ipfp_homoskedastic_nosingles_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> ThreeArrays | FourArrays : \"\"\"Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of $(\\\\mu_{xy})$ wrt $\\\\Phi$ verbose: if `True`, prints information maxiter: maximum number of iterations Returns: muxy: the matching patterns, shape (X, Y) marg_err_x, marg_err_y: the errors on the margins and the gradients of $(\\\\mu_{xy})$ wrt $\\\\Phi$ if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) n_couples = np . sum ( men_margins ) # check that there are as many men as women if np . abs ( np . sum ( women_margins ) - n_couples ) > n_couples * tol : bs_error_abort ( \"There should be as many men as women\" ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = 1 ) ephi2T = ephi2 . T ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # starting with a reasonable initial point for tx and ty: : tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# bigc = sqrt ( n_couples / np . sum ( ephi2 )) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * err_diff niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = men_margins / sx sy = ephi2T @ tx ty = women_margins / sy err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi , tyi = tx , ty niter += 1 muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = np . sum ( muxy , 1 ) - men_margins marg_err_y = np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return muxy , marg_err_x , marg_err_y else : sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute_ derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = 0 for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = 0 for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer (( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy += np . diag ( muxy_vec2 ) return muxy , marg_err_x , marg_err_y , dmuxy ipfp_homoskedastic_solver ( Phi , men_margins , women_margins , tol = 1e-09 , gr = False , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) IPFPNoGradientResults | IPFPGradientResults if gr is True Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu , sigma = 0.0 , 1.0 n_bases = 4 bases_surplus = np . zeros (( X , Y , n_bases )) x_men = ( np . arange ( X ) - X / 2.0 ) / X y_women = ( np . arange ( Y ) - Y / 2.0 ) / Y bases_surplus [:, :, 0 ] = 1 for iy in range ( Y ): bases_surplus [:, iy , 1 ] = x_men for ix in range ( X ): bases_surplus [ ix , :, 2 ] = y_women for ix in range ( X ): for iy in range ( Y ): bases_surplus [ ix , iy , 3 ] = ( x_men [ ix ] - y_women [ iy ]) * ( x_men [ ix ] - y_women [ iy ] ) men_margins = np . random . uniform ( 1.0 , 10.0 , size = X ) women_margins = np . random . uniform ( 1.0 , 10.0 , size = Y ) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np . array ([ 3.0 , - 1.0 , - 1.0 , - 2.0 ]) true_surplus_matrix = bases_surplus @ true_surplus_params mus , marg_err_x , marg_err_y = ipfp_homoskedastic_solver ( true_surplus_matrix , men_margins , women_margins , tol = 1e-12 ) Source code in cupid_matching/ipfp_solvers.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 def ipfp_homoskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) if `gr` is `True` Example: ```py # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu, sigma = 0.0, 1.0 n_bases = 4 bases_surplus = np.zeros((X, Y, n_bases)) x_men = (np.arange(X) - X / 2.0) / X y_women = (np.arange(Y) - Y / 2.0) / Y bases_surplus[:, :, 0] = 1 for iy in range(Y): bases_surplus[:, iy, 1] = x_men for ix in range(X): bases_surplus[ix, :, 2] = y_women for ix in range(X): for iy in range(Y): bases_surplus[ix, iy, 3] = (x_men[ix] - y_women[iy]) * ( x_men[ix] - y_women[iy] ) men_margins = np.random.uniform(1.0, 10.0, size=X) women_margins = np.random.uniform(1.0, 10.0, size=Y) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np.array([3.0, -1.0, -1.0, -2.0]) true_surplus_matrix = bases_surplus @ true_surplus_params mus, marg_err_x, marg_err_y = ipfp_homoskedastic_solver( true_surplus_matrix, men_margins, women_margins, tol=1e-12 ) ``` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = 1 ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # where mux0=tx**2 and mu0y=ty**2 # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# ephi2T = ephi2 . T nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = sqrt ( nindivs / ( X + Y + 2.0 * np . sum ( ephi2 ))) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * bigc niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = ( np . sqrt ( sx * sx + 4.0 * men_margins ) - sx ) / 2.0 sy = ephi2T @ tx ty = ( np . sqrt ( sy * sy + 4.0 * women_margins ) - sy ) / 2.0 err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = txi * txi mu0y = tyi * tyi muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , ) else : # we compute_ the derivatives sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 2.0 * txi + sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( 2.0 * tyi + syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_sum_categories + n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute_ derivatives of (txi, tyi) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute_ derivatives of (txi, tyi) wrt women_margins rhs [ X : n_sum_categories , X : n_sum_categories ] = np . eye ( Y ) # to compute_ derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of the mus dmux0 = 2.0 * ( dt * txi . reshape (( - 1 , 1 ))) dmu0y = 2.0 * ( dT * tyi . reshape (( - 1 , 1 ))) dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer (( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy [:, n_sum_categories :] += np . diag ( muxy_vec2 ) return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , )","title":"IPFP solvers"},{"location":"ipfp_solvers/#ipfp_solvers-module","text":"Implementations of the IPFP algorithm to solve for equilibrium and do comparative statics in several variants of the Choo and Siow 2006 <https://www.jstor.org/stable/10.1086/498585?seq=1> _ model: homoskedastic with singles (as in Choo and Siow 2006) homoskedastic without singles gender-heteroskedastic: with a scale parameter on the error term for women gender- and type-heteroskedastic: with a scale parameter on the error term for each gender and type two-level nested logit, with nests and nest parameters that do not depend on the type, and {0} as the first nest Each solver, when fed the joint surplus and margins, returns the equilibrium matching patterns, the adding-up errors on the margins, and if requested (using gr=True ) the derivatives of the matching patterns in all primitives.","title":"ipfp_solvers module"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_gender_heteroskedastic_solver","text":"Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter tau Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tau float the standard error for all women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns IPFPNoGradientResults | IPFPGradientResults wrt (men_margins, women_margins, Phi, tau) if gr is True Source code in cupid_matching/ipfp_solvers.py 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 def ipfp_gender_heteroskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tau : float , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter `tau` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tau: the standard error for all women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, tau) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if tau <= 0 : bs_error_abort ( f \"We need a positive tau, not { tau } \" ) ############################################################################# # we use ipfp_heteroxy_solver with sigma_x = 1 and tau_y = tau ############################################################################# sigma_x = np . ones ( X ) tau_y = np . full ( Y , tau ) if gr : ( mus_hxy , marg_err_x , marg_err_y , dmus_xy , dmus_x0 , dmus_0y , ) = ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = True , maxiter = maxiter , verbose = verbose , ) muxy , _ , _ , _ , _ = mus_hxy . unpack () n_sum_categories = X + Y n_prod_categories = X * Y n_cols = n_sum_categories + n_prod_categories itau_y = n_cols + X dmuxy = np . zeros (( n_prod_categories , n_cols + 1 )) dmuxy [:, : n_cols ] = dmus_xy [:, : n_cols ] dmuxy [:, - 1 ] = np . sum ( dmus_xy [:, itau_y :], 1 ) dmux0 = np . zeros (( X , n_cols + 1 )) dmux0 [:, : n_cols ] = dmus_x0 [:, : n_cols ] dmux0 [:, - 1 ] = np . sum ( dmus_x0 [:, itau_y :], 1 ) dmu0y = np . zeros (( Y , n_cols + 1 )) dmu0y [:, : n_cols ] = dmus_0y [:, : n_cols ] dmu0y [:, - 1 ] = np . sum ( dmus_0y [:, itau_y :], 1 ) return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , ) else : return ipfp_heteroskedastic_solver ( Phi , men_margins , women_margins , sigma_x , tau_y , tol = tol , gr = False , maxiter = maxiter , verbose = verbose , )","title":"ipfp_gender_heteroskedastic_solver()"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_heteroskedastic_solver","text":"Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors sigma_x and tau_y Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required sigma_x np . ndarray the vector of standard errors for the X types of men required sigma_x np . ndarray the vector of standard errors for Y types of women required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns IPFPNoGradientResults | IPFPGradientResults wrt (men_margins, women_margins, Phi, sigma_x, tau_y) IPFPNoGradientResults | IPFPGradientResults if gr is True Source code in cupid_matching/ipfp_solvers.py 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 def ipfp_heteroskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , sigma_x : np . ndarray , tau_y : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors `sigma_x` and `tau_y` Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) sigma_x: the vector of standard errors for the X types of men sigma_x: the vector of standard errors for Y types of women tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi, sigma_x, tau_y) if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) if np . min ( sigma_x ) <= 0.0 : bs_error_abort ( \"All elements of sigma_x must be positive\" ) if np . min ( tau_y ) <= 0.0 : bs_error_abort ( \"All elements of tau_y must be positive\" ) sumxy1 = 1.0 / np . add . outer ( sigma_x , tau_y ) ephi2 , der_ephi2 = npexp ( Phi * sumxy1 , deriv = 1 ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # with tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi2 )) # we find the largest values of sigma_x and tau_y xmax = np . argmax ( sigma_x ) sigma_max = sigma_x [ xmax ] ymax = np . argmax ( tau_y ) tau_max = tau_y [ ymax ] # we use tx = mux0^(sigma_x/(sigma_x + tau_max)) # and ty = mu0y^(tau_y/(sigma_max + tau_y)) sig_taumax = sigma_x + tau_max txi = np . power ( bigc , sigma_x / sig_taumax ) sigmax_tau = tau_y + sigma_max tyi = np . power ( bigc , tau_y / sigmax_tau ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc txin = txi . copy () mu0y_in = np . power ( np . power ( tyi , sigmax_tau ), 1.0 / tau_y ) while err_newton > tol_newton : txit = np . power ( txin , sig_taumax ) mux0_in = np . power ( txit , 1.0 / sigma_x ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y )) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) errxi = mux0_in + np . sum ( muxy_in , 1 ) - men_margins err_newton = npmaxabs ( errxi ) txin -= errxi / ( sig_taumax * ( mux0_in / sigma_x + np . sum ( sumxy1 * muxy_in , 1 )) / txin ) tx = txin # Newton iterates for women err_newton = bigc tyin = tyi . copy () mux0_in = np . power ( np . power ( tx , sig_taumax ), 1.0 / sigma_x ) while err_newton > tol_newton : tyit = np . power ( tyin , sigmax_tau ) mu0y_in = np . power ( tyit , 1.0 / tau_y ) out_xy = np . outer ( np . power ( mux0_in , sigma_x ), np . power ( mu0y_in , tau_y )) muxy_in = ephi2 * np . power ( out_xy , sumxy1 ) erryi = mu0y_in + np . sum ( muxy_in , 0 ) - women_margins err_newton = npmaxabs ( erryi ) tyin -= erryi / ( sigmax_tau * ( mu0y_in / tau_y + np . sum ( sumxy1 * muxy_in , 0 )) / tyin ) ty = tyin err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = mux0_in mu0y = mu0y_in muxy = muxy_in marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , ) else : # we compute_ the derivatives n_sum_categories = X + Y n_prod_categories = X * Y # we work directly with (mux0, mu0y) sigrat_xy = sumxy1 * sigma_x . reshape (( - 1 , 1 )) taurat_xy = 1.0 - sigrat_xy mux0_mat = nprepeat_col ( mux0 , Y ) mu0y_mat = nprepeat_row ( mu0y , X ) # muxy = axy * bxy * ephi2 axy = nppow ( mux0_mat , sigrat_xy ) bxy = nppow ( mu0y_mat , taurat_xy ) der_axy1 , der_axy2 = nppow ( mux0_mat , sigrat_xy , deriv = 1 ) der_bxy1 , der_bxy2 = nppow ( mu0y_mat , taurat_xy , deriv = 1 ) der_axy1_rat , der_axy2_rat = der_axy1 / axy , der_axy2 / axy der_bxy1_rat , der_bxy2_rat = der_bxy1 / bxy , der_bxy2 / bxy # start with the LHS of the linear system on (dmux0, dmu0y) lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 1.0 + np . sum ( muxy * der_axy1_rat , 1 )) lhs [: X , X :] = muxy * der_bxy1_rat lhs [ X :, X :] = np . diag ( 1.0 + np . sum ( muxy * der_bxy1_rat , 0 )) lhs [ X :, : X ] = ( muxy * der_axy1_rat ) . T # now fill the RHS (derivatives wrt men_margins, then men_margins, # then Phi, then sigma_x and tau_y) n_cols_rhs = n_sum_categories + n_prod_categories + X + Y rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute_ derivatives of (mux0, mu0y) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute_ derivatives of (mux0, mu0y) wrt women_margins rhs [ X :, X : n_sum_categories ] = np . eye ( Y ) # the next line is sumxy1 with safeguards sumxy1_safe = sumxy1 * der_ephi2 / ephi2 big_a = muxy * sumxy1_safe big_b = der_axy2_rat - der_bxy2_rat b_mu_s = big_b * muxy * sumxy1 a_phi = Phi * big_a big_c = sumxy1 * ( a_phi - b_mu_s * tau_y ) big_d = sumxy1 * ( a_phi + b_mu_s * sigma_x . reshape (( - 1 , 1 ))) # to compute_ derivatives of (mux0, mu0y) wrt Phi ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - big_a [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories iend_phi = n_sum_categories + n_prod_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : iend_phi : Y ] = - big_a [:, iwoman ] ivar1 += 1 ivar2 += 1 # to compute_ derivatives of (mux0, mu0y) wrt sigma_x iend_sig = iend_phi + X der_sigx = np . sum ( big_c , 1 ) rhs [: X , iend_phi : iend_sig ] = np . diag ( der_sigx ) rhs [ X :, iend_phi : iend_sig ] = big_c . T # to compute_ derivatives of (mux0, mu0y) wrt tau_y der_tauy = np . sum ( big_d , 0 ) rhs [ X :, iend_sig :] = np . diag ( der_tauy ) rhs [: X , iend_sig :] = big_d # solve for the derivatives of mux0 and mu0y dmu0 = spla . solve ( lhs , rhs ) dmux0 = dmu0 [: X , :] dmu0y = dmu0 [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) der1 = ephi2 * der_axy1 * bxy ivar = 0 for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), :] = np . outer ( der1 [ iman , :], dmux0 [ iman , :]) ivar += Y der2 = ephi2 * der_bxy1 * axy for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( der2 [:, iwoman ], dmu0y [ iwoman , :] ) # add the terms that comes from differentiating ephi2 # on the derivative wrt Phi i = 0 j = n_sum_categories for iman in range ( X ): for iwoman in range ( Y ): dmuxy [ i , j ] += big_a [ iman , iwoman ] i += 1 j += 1 # on the derivative wrt sigma_x ivar = 0 ix = iend_phi for iman in range ( X ): dmuxy [ ivar : ( ivar + Y ), ix ] -= big_c [ iman , :] ivar += Y ix += 1 # on the derivative wrt tau_y iy = iend_sig for iwoman in range ( Y ): dmuxy [ iwoman : n_prod_categories : Y , iy ] -= big_d [:, iwoman ] iy += 1 return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , )","title":"ipfp_heteroskedastic_solver()"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_homoskedastic_nosingles_solver","text":"Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of \\((\\mu_{xy})\\) wrt \\(\\Phi\\) False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Name Type Description muxy ThreeArrays | FourArrays the matching patterns, shape (X, Y) ThreeArrays | FourArrays marg_err_x, marg_err_y: the errors on the margins ThreeArrays | FourArrays and the gradients of \\((\\mu_{xy})\\) wrt \\(\\Phi\\) if gr is True Source code in cupid_matching/ipfp_solvers.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 def ipfp_homoskedastic_nosingles_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> ThreeArrays | FourArrays : \"\"\"Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of $(\\\\mu_{xy})$ wrt $\\\\Phi$ verbose: if `True`, prints information maxiter: maximum number of iterations Returns: muxy: the matching patterns, shape (X, Y) marg_err_x, marg_err_y: the errors on the margins and the gradients of $(\\\\mu_{xy})$ wrt $\\\\Phi$ if `gr` is `True` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) n_couples = np . sum ( men_margins ) # check that there are as many men as women if np . abs ( np . sum ( women_margins ) - n_couples ) > n_couples * tol : bs_error_abort ( \"There should be as many men as women\" ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = 1 ) ephi2T = ephi2 . T ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # starting with a reasonable initial point for tx and ty: : tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# bigc = sqrt ( n_couples / np . sum ( ephi2 )) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * err_diff niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = men_margins / sx sy = ephi2T @ tx ty = women_margins / sy err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi , tyi = tx , ty niter += 1 muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = np . sum ( muxy , 1 ) - men_margins marg_err_y = np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return muxy , marg_err_x , marg_err_y else : sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute_ derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = 0 for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = 0 for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of muxy dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer (( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy += np . diag ( muxy_vec2 ) return muxy , marg_err_x , marg_err_y , dmuxy","title":"ipfp_homoskedastic_nosingles_solver()"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_homoskedastic_solver","text":"Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Parameters: Name Type Description Default Phi np . ndarray matrix of systematic surplus, shape (X, Y) required men_margins np . ndarray vector of men margins, shape (X) required women_margins np . ndarray vector of women margins, shape (Y) required tol float tolerance on change in solution 1e-09 gr bool if True , also evaluate derivatives of the matching patterns False verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description muxy , mux0 , mu0y the matching patterns IPFPNoGradientResults | IPFPGradientResults marg_err_x, marg_err_y: the errors on the margins IPFPNoGradientResults | IPFPGradientResults and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) IPFPNoGradientResults | IPFPGradientResults if gr is True Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu , sigma = 0.0 , 1.0 n_bases = 4 bases_surplus = np . zeros (( X , Y , n_bases )) x_men = ( np . arange ( X ) - X / 2.0 ) / X y_women = ( np . arange ( Y ) - Y / 2.0 ) / Y bases_surplus [:, :, 0 ] = 1 for iy in range ( Y ): bases_surplus [:, iy , 1 ] = x_men for ix in range ( X ): bases_surplus [ ix , :, 2 ] = y_women for ix in range ( X ): for iy in range ( Y ): bases_surplus [ ix , iy , 3 ] = ( x_men [ ix ] - y_women [ iy ]) * ( x_men [ ix ] - y_women [ iy ] ) men_margins = np . random . uniform ( 1.0 , 10.0 , size = X ) women_margins = np . random . uniform ( 1.0 , 10.0 , size = Y ) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np . array ([ 3.0 , - 1.0 , - 1.0 , - 2.0 ]) true_surplus_matrix = bases_surplus @ true_surplus_params mus , marg_err_x , marg_err_y = ipfp_homoskedastic_solver ( true_surplus_matrix , men_margins , women_margins , tol = 1e-12 ) Source code in cupid_matching/ipfp_solvers.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 def ipfp_homoskedastic_solver ( Phi : np . ndarray , men_margins : np . ndarray , women_margins : np . ndarray , tol : float = 1e-9 , gr : bool = False , verbose : bool = False , maxiter : int = 1000 , ) -> IPFPNoGradientResults | IPFPGradientResults : \"\"\"Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins Args: Phi: matrix of systematic surplus, shape (X, Y) men_margins: vector of men margins, shape (X) women_margins: vector of women margins, shape (Y) tol: tolerance on change in solution gr: if `True`, also evaluate derivatives of the matching patterns verbose: if `True`, prints information maxiter: maximum number of iterations Returns: (muxy, mux0, mu0y): the matching patterns marg_err_x, marg_err_y: the errors on the margins and the gradients of the matching patterns wrt (men_margins, women_margins, Phi) if `gr` is `True` Example: ```py # we generate a Choo and Siow homoskedastic matching X = Y = 20 n_sum_categories = X + Y n_prod_categories = X * Y mu, sigma = 0.0, 1.0 n_bases = 4 bases_surplus = np.zeros((X, Y, n_bases)) x_men = (np.arange(X) - X / 2.0) / X y_women = (np.arange(Y) - Y / 2.0) / Y bases_surplus[:, :, 0] = 1 for iy in range(Y): bases_surplus[:, iy, 1] = x_men for ix in range(X): bases_surplus[ix, :, 2] = y_women for ix in range(X): for iy in range(Y): bases_surplus[ix, iy, 3] = (x_men[ix] - y_women[iy]) * ( x_men[ix] - y_women[iy] ) men_margins = np.random.uniform(1.0, 10.0, size=X) women_margins = np.random.uniform(1.0, 10.0, size=Y) # np.random.normal(mu, sigma, size=n_bases) true_surplus_params = np.array([3.0, -1.0, -1.0, -2.0]) true_surplus_matrix = bases_surplus @ true_surplus_params mus, marg_err_x, marg_err_y = ipfp_homoskedastic_solver( true_surplus_matrix, men_margins, women_margins, tol=1e-12 ) ``` \"\"\" X , Y = _ipfp_check_sizes ( men_margins , women_margins , Phi ) ephi2 , der_ephi2 = npexp ( Phi / 2.0 , deriv = 1 ) ############################################################################# # we solve the equilibrium equations muxy = ephi2 * tx * ty # where mux0=tx**2 and mu0y=ty**2 # starting with a reasonable initial point for tx and ty: tx = ty = bigc # it is important that it fit the number of individuals ############################################################################# ephi2T = ephi2 . T nindivs = np . sum ( men_margins ) + np . sum ( women_margins ) bigc = sqrt ( nindivs / ( X + Y + 2.0 * np . sum ( ephi2 ))) txi = np . full ( X , bigc ) tyi = np . full ( Y , bigc ) err_diff = bigc tol_diff = tol * bigc niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): sx = ephi2 @ tyi tx = ( np . sqrt ( sx * sx + 4.0 * men_margins ) - sx ) / 2.0 sy = ephi2T @ tx ty = ( np . sqrt ( sy * sy + 4.0 * women_margins ) - sy ) / 2.0 err_x = npmaxabs ( tx - txi ) err_y = npmaxabs ( ty - tyi ) err_diff = err_x + err_y txi = tx tyi = ty niter += 1 mux0 = txi * txi mu0y = tyi * tyi muxy = ephi2 * np . outer ( txi , tyi ) marg_err_x = mux0 + np . sum ( muxy , 1 ) - men_margins marg_err_y = mu0y + np . sum ( muxy , 0 ) - women_margins if verbose : print ( f \"After { niter } iterations:\" ) print ( f \" \\t Margin error on x: { npmaxabs ( marg_err_x ) } \" ) print ( f \" \\t Margin error on y: { npmaxabs ( marg_err_y ) } \" ) if not gr : return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , ) else : # we compute_ the derivatives sxi = ephi2 @ tyi syi = ephi2T @ txi n_sum_categories = X + Y n_prod_categories = X * Y # start with the LHS of the linear system lhs = np . zeros (( n_sum_categories , n_sum_categories )) lhs [: X , : X ] = np . diag ( 2.0 * txi + sxi ) lhs [: X , X :] = ephi2 * txi . reshape (( - 1 , 1 )) lhs [ X :, X :] = np . diag ( 2.0 * tyi + syi ) lhs [ X :, : X ] = ephi2T * tyi . reshape (( - 1 , 1 )) # now fill the RHS n_cols_rhs = n_sum_categories + n_prod_categories rhs = np . zeros (( n_sum_categories , n_cols_rhs )) # to compute_ derivatives of (txi, tyi) wrt men_margins rhs [: X , : X ] = np . eye ( X ) # to compute_ derivatives of (txi, tyi) wrt women_margins rhs [ X : n_sum_categories , X : n_sum_categories ] = np . eye ( Y ) # to compute_ derivatives of (txi, tyi) wrt Phi der_ephi2 /= 2.0 * ephi2 # 1/2 with safeguards ivar = n_sum_categories for iman in range ( X ): rhs [ iman , ivar : ( ivar + Y )] = - muxy [ iman , :] * der_ephi2 [ iman , :] ivar += Y ivar1 = X ivar2 = n_sum_categories for iwoman in range ( Y ): rhs [ ivar1 , ivar2 : n_cols_rhs : Y ] = - muxy [:, iwoman ] * der_ephi2 [:, iwoman ] ivar1 += 1 ivar2 += 1 # solve for the derivatives of txi and tyi dt_dT = spla . solve ( lhs , rhs ) dt = dt_dT [: X , :] dT = dt_dT [ X :, :] # now construct the derivatives of the mus dmux0 = 2.0 * ( dt * txi . reshape (( - 1 , 1 ))) dmu0y = 2.0 * ( dT * tyi . reshape (( - 1 , 1 ))) dmuxy = np . zeros (( n_prod_categories , n_cols_rhs )) ivar = 0 for iman in range ( X ): dt_man = dt [ iman , :] dmuxy [ ivar : ( ivar + Y ), :] = np . outer (( ephi2 [ iman , :] * tyi ), dt_man ) ivar += Y for iwoman in range ( Y ): dT_woman = dT [ iwoman , :] dmuxy [ iwoman : n_prod_categories : Y , :] += np . outer ( ( ephi2 [:, iwoman ] * txi ), dT_woman ) # add the term that comes from differentiating ephi2 muxy_vec2 = ( muxy * der_ephi2 ) . reshape ( n_prod_categories ) dmuxy [:, n_sum_categories :] += np . diag ( muxy_vec2 ) return ( Matching ( muxy , men_margins , women_margins ), marg_err_x , marg_err_y , dmuxy , dmux0 , dmu0y , )","title":"ipfp_homoskedastic_solver()"},{"location":"matching_utils/","text":"matching_utils module \u00b6 matching-related utilities MatchingFunctionParam = Callable [[ Matching , list [ Any ]], np . ndarray ] module-attribute \u00b6 Same with a list of additional parameters Matching dataclass \u00b6 stores the numbers of couples and singles of every type; muxy is an (X,Y)-matrix n is an X-vector m is an Y-vector mux0 and mu0y are generated as the corresponding numbers of singles as well as the total number of households n_households and the total number of individuals n_individuals Source code in cupid_matching/matching_utils.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 @dataclass class Matching : \"\"\"stores the numbers of couples and singles of every type; `muxy` is an (X,Y)-matrix `n` is an X-vector `m` is an Y-vector `mux0` and `mu0y` are generated as the corresponding numbers of singles as well as the total number of households `n_households` and the total number of individuals `n_individuals` \"\"\" muxy : np . ndarray n : np . ndarray m : np . ndarray mux0 : np . ndarray = field ( init = False ) mu0y : np . ndarray = field ( init = False ) n_households : float = field ( init = False ) n_individuals : float = field ( init = False ) def __str__ ( self ): X , Y = self . muxy . shape n_couples = np . sum ( self . muxy ) n_men , n_women = np . sum ( self . n ), np . sum ( self . m ) repr_str = f \"This is a matching with { n_men } men and { n_women } women. \\n \" repr_str += f \" with { n_couples } couples, \\n \\n \" repr_str += f \" We have { X } types of men and { Y } of women.\" return repr_str def __post_init__ ( self ): # print('inside __post_init__ method') X , Y = check_matrix ( self . muxy ) Xn = check_vector ( self . n ) Ym = check_vector ( self . m ) if Xn != X : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) self . mux0 , self . mu0y = get_singles ( self . muxy , self . n , self . m ) self . n_households = np . sum ( self . muxy ) + np . sum ( self . mux0 ) + np . sum ( self . mu0y ) self . n_individuals = ( 2.0 * np . sum ( self . muxy ) + np . sum ( self . mux0 ) + np . sum ( self . mu0y ) ) def unpack ( self ): muxy , mux0 , mu0y = self . muxy , self . mux0 , self . mu0y min_xy , min_x0 , min_0y = np . min ( muxy ), np . min ( mux0 ), np . min ( mu0y ) if min_xy < 0.0 : bs_error_abort ( f \"The smallest muxy is { min_xy } \" ) if min_x0 < 0.0 : bs_error_abort ( f \"The smallest mux0 is { min_x0 } \" ) if min_0y < 0.0 : bs_error_abort ( f \"The smallest mux0 is { min_0y } \" ) return muxy , mux0 , mu0y , self . n , self . m VarianceMatching dataclass \u00b6 initialized with the six matrix components of the variance of a Matching compute_s six more var_xyzt is the (XY, XY) var-cov matrix of muxy var_xyz0 is the (XY, X) covariance matrix of muxy and mux0 var_xy0t is the (XY, Y) covariance matrix of muxy and mu0y var_x0z0 is the (X, X) var-cov matrix of mux0 var_x00t is the (X, Y) covariance matrix of mux0 and mu0y var_0y0t is the (Y, Y) var-cov matrix of mu0y var_xyn is the (XY, X) covariance matrix of muxy and nx var_xym is the (XY, Y) covariance matrix of muxy and my var_nn is the (X, X) var-cov matrix of nx var_nm is the (X, Y) covariance matrix of nx and my var_mm is the (Y, Y) var-cov matrix of my var_allmus is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, mux0, mu0y) var_munm is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, n, m) Source code in cupid_matching/matching_utils.py 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 @dataclass class VarianceMatching : \"\"\"initialized with the six matrix components of the variance of a Matching compute_s six more `var_xyzt` is the (XY, XY) var-cov matrix of `muxy` `var_xyz0` is the (XY, X) covariance matrix of `muxy` and `mux0` `var_xy0t` is the (XY, Y) covariance matrix of `muxy` and `mu0y` `var_x0z0` is the (X, X) var-cov matrix of `mux0` `var_x00t` is the (X, Y) covariance matrix of `mux0` and `mu0y` `var_0y0t` is the (Y, Y) var-cov matrix of `mu0y` `var_xyn` is the (XY, X) covariance matrix of `muxy` and `nx` `var_xym` is the (XY, Y) covariance matrix of `muxy` and `my` `var_nn` is the (X, X) var-cov matrix of `nx` `var_nm` is the (X, Y) covariance matrix of `nx` and `my` `var_mm` is the (Y, Y) var-cov matrix of `my` `var_allmus` is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, mux0, mu0y) `var_munm` is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, n, m) \"\"\" var_xyzt : np . ndarray var_xyz0 : np . ndarray var_xy0t : np . ndarray var_x0z0 : np . ndarray var_x00t : np . ndarray var_0y0t : np . ndarray var_xyn : np . ndarray = field ( init = False ) var_xym : np . ndarray = field ( init = False ) var_nn : np . ndarray = field ( init = False ) var_nm : np . ndarray = field ( init = False ) var_mm : np . ndarray = field ( init = False ) var_allmus : np . ndarray = field ( init = False ) var_munm : np . ndarray = field ( init = False ) def __str__ ( self ): n_men = self . var_xyz0 . shape [ 1 ] n_women = self . var_xy0t . shape [ 1 ] repr_str = f \"This is a VarianceMatching with { n_men } men, { n_women } women. \\n \" return repr_str def __post_init__ ( self ): # print('inside __post_init__ method') v_xyzt = self . var_xyzt XY , XY2 = check_matrix ( v_xyzt ) if XY2 != XY : bs_error_abort ( f \"var_xyzt should be a square matrix, not ( { XY } , { XY2 } )\" ) v_xyz0 = self . var_xyz0 XY3 , X = check_matrix ( v_xyz0 ) if XY3 != XY : bs_error_abort ( f \"var_xyz0 should have { XY } rows, not { XY3 } )\" ) v_xy0t = self . var_xy0t XY4 , Y = check_matrix ( v_xy0t ) if XY4 != XY : bs_error_abort ( f \"var_xy0t should have { XY } rows, not { XY4 } )\" ) if X * Y != XY : bs_error_abort ( f \"var_xyzt has { XY } rows, but varxyz0 has { X } columns and varxy0t\" f \" has { Y } \" ) v_x0z0 = self . var_x0z0 X2 , X3 = check_matrix ( v_x0z0 ) if X2 != X : bs_error_abort ( f \"var_x0z0 has { X2 } rows, it should have { X } \" ) if X3 != X : bs_error_abort ( f \"var_x0z0 has { X3 } columns, it should have { X } \" ) v_x00t = self . var_x00t X4 , Y2 = check_matrix ( v_x00t ) if X4 != X : bs_error_abort ( f \"var_x00t has { X4 } rows, it should have { X } \" ) if Y2 != Y : bs_error_abort ( f \"var_x00t has { Y2 } columns, it should have { Y } \" ) v_0y0t = self . var_0y0t Y3 , Y4 = check_matrix ( v_0y0t ) if Y3 != Y : bs_error_abort ( f \"var_x00t has { Y3 } rows, it should have { Y } \" ) if Y4 != Y : bs_error_abort ( f \"var_x00t has { Y4 } columns, it should have { Y } \" ) # now we compute_ the five additional components v_xyn = v_xyz0 . copy () sumt_covx0_zt = np . zeros (( X , X )) iz = 0 for z in range ( X ): v_xyn [:, z ] += np . sum ( v_xyzt [:, iz : ( iz + Y )], 1 ) sumt_covx0_zt [:, z ] = np . sum ( v_xyz0 [ iz : ( iz + Y ), :], 0 ) iz += Y self . var_xyn = v_xyn v_xym = v_xy0t . copy () v_0ym = v_0y0t . copy () for t in range ( Y ): slice_t = slice ( t , XY , Y ) v_xym [:, t ] += np . sum ( v_xyzt [:, slice_t ], 1 ) v_0ym [:, t ] += np . sum ( v_xy0t [ slice_t , :], 0 ) self . var_xym = v_xym v_x0n = v_x0z0 + sumt_covx0_zt v_nn = v_x0n v_0yn = v_x00t . copy () . T ix = 0 for x in range ( X ): v_nn [ x , :] += np . sum ( v_xyn [ ix : ( ix + Y ), :], 0 ) v_0yn [:, x ] += np . sum ( v_xy0t [ ix : ( ix + Y ), :], 0 ) ix += Y self . var_nn = v_nn v_nm = v_0yn . T v_mm = v_0ym for y in range ( Y ): slice_y = slice ( y , XY , Y ) v_nm [:, y ] += np . sum ( v_xyn [ slice_y , :], 0 ) v_mm [ y , :] += np . sum ( v_xym [ slice_y , :], 0 ) self . var_nm = v_nm self . var_mm = v_mm self . var_allmus = self . make_var_allmus () self . var_munm = self . make_var_munm () def unpack ( self ): \"\"\"return a tuple of all members of this `VarianceMatching`\"\"\" return ( self . var_xyzt , self . var_xyz0 , self . var_xy0t , self . var_x0z0 , self . var_x00t , self . var_0y0t , self . var_xyn , self . var_xym , self . var_nn , self . var_nm , self . var_mm , ) def make_var_allmus ( self : Any ) -> np . ndarray : \"\"\"create the variance-covariance of `(muxy, mux0, mu0y)` Args: self: the VarianceMatching object Returns: an (XY+X+Y, XY+X+Y) symmetric positive matrix \"\"\" v_xyzt , v_xyz0 , v_xy0t , v_x0z0 , v_x00t , v_0y0t , * _ = self . unpack () X , Y = v_x0z0 . shape [ 0 ], v_0y0t . shape [ 0 ] XY = X * Y sz = XY + X + Y v_allmus = np . zeros (( sz , sz )) v_allmus [: XY , : XY ] = v_xyzt v_allmus [: XY , XY : ( XY + X )] = v_xyz0 v_allmus [ XY : ( XY + X ), : XY ] = v_xyz0 . T v_allmus [: XY , ( XY + X ) :] = v_xy0t v_allmus [( XY + X ) :, : XY ] = v_xy0t . T v_allmus [ XY : ( XY + X ), XY : ( XY + X )] = v_x0z0 v_allmus [ XY : ( XY + X ), ( XY + X ) :] = v_x00t v_allmus [( XY + X ) :, XY : ( XY + X )] = v_x00t . T v_allmus [( XY + X ) :, ( XY + X ) :] = v_0y0t return v_allmus def make_var_munm ( self : Any ) -> np . ndarray : \"\"\"create the variance-covariance of (muxy, n, m) Args: self: this `VarianceMatching` object Returns: an (XY+X+Y, XY+X+Y) symmetric positive matrix \"\"\" v_xyzt , * _ , v_xyn , v_xym , v_nn , v_nm , v_mm = self . unpack () X , Y = v_nn . shape [ 0 ], v_mm . shape [ 0 ] XY = X * Y sz = XY + X + Y v_munm = np . zeros (( sz , sz )) v_munm [: XY , : XY ] = v_xyzt v_munm [: XY , XY : ( XY + X )] = v_xyn v_munm [ XY : ( XY + X ), : XY ] = v_xyn . T v_munm [: XY , ( XY + X ) :] = v_xym v_munm [( XY + X ) :, : XY ] = v_xym . T v_munm [ XY : ( XY + X ), XY : ( XY + X )] = v_nn v_munm [ XY : ( XY + X ), ( XY + X ) :] = v_nm v_munm [( XY + X ) :, XY : ( XY + X )] = v_nm . T v_munm [( XY + X ) :, ( XY + X ) :] = v_mm return v_munm make_var_allmus () \u00b6 create the variance-covariance of (muxy, mux0, mu0y) Parameters: Name Type Description Default self Any the VarianceMatching object required Returns: Type Description np . ndarray an (XY+X+Y, XY+X+Y) symmetric positive matrix Source code in cupid_matching/matching_utils.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 def make_var_allmus ( self : Any ) -> np . ndarray : \"\"\"create the variance-covariance of `(muxy, mux0, mu0y)` Args: self: the VarianceMatching object Returns: an (XY+X+Y, XY+X+Y) symmetric positive matrix \"\"\" v_xyzt , v_xyz0 , v_xy0t , v_x0z0 , v_x00t , v_0y0t , * _ = self . unpack () X , Y = v_x0z0 . shape [ 0 ], v_0y0t . shape [ 0 ] XY = X * Y sz = XY + X + Y v_allmus = np . zeros (( sz , sz )) v_allmus [: XY , : XY ] = v_xyzt v_allmus [: XY , XY : ( XY + X )] = v_xyz0 v_allmus [ XY : ( XY + X ), : XY ] = v_xyz0 . T v_allmus [: XY , ( XY + X ) :] = v_xy0t v_allmus [( XY + X ) :, : XY ] = v_xy0t . T v_allmus [ XY : ( XY + X ), XY : ( XY + X )] = v_x0z0 v_allmus [ XY : ( XY + X ), ( XY + X ) :] = v_x00t v_allmus [( XY + X ) :, XY : ( XY + X )] = v_x00t . T v_allmus [( XY + X ) :, ( XY + X ) :] = v_0y0t return v_allmus make_var_munm () \u00b6 create the variance-covariance of (muxy, n, m) Parameters: Name Type Description Default self Any this VarianceMatching object required Returns: Type Description np . ndarray an (XY+X+Y, XY+X+Y) symmetric positive matrix Source code in cupid_matching/matching_utils.py 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 def make_var_munm ( self : Any ) -> np . ndarray : \"\"\"create the variance-covariance of (muxy, n, m) Args: self: this `VarianceMatching` object Returns: an (XY+X+Y, XY+X+Y) symmetric positive matrix \"\"\" v_xyzt , * _ , v_xyn , v_xym , v_nn , v_nm , v_mm = self . unpack () X , Y = v_nn . shape [ 0 ], v_mm . shape [ 0 ] XY = X * Y sz = XY + X + Y v_munm = np . zeros (( sz , sz )) v_munm [: XY , : XY ] = v_xyzt v_munm [: XY , XY : ( XY + X )] = v_xyn v_munm [ XY : ( XY + X ), : XY ] = v_xyn . T v_munm [: XY , ( XY + X ) :] = v_xym v_munm [( XY + X ) :, : XY ] = v_xym . T v_munm [ XY : ( XY + X ), XY : ( XY + X )] = v_nn v_munm [ XY : ( XY + X ), ( XY + X ) :] = v_nm v_munm [( XY + X ) :, XY : ( XY + X )] = v_nm . T v_munm [( XY + X ) :, ( XY + X ) :] = v_mm return v_munm unpack () \u00b6 return a tuple of all members of this VarianceMatching Source code in cupid_matching/matching_utils.py 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 def unpack ( self ): \"\"\"return a tuple of all members of this `VarianceMatching`\"\"\" return ( self . var_xyzt , self . var_xyz0 , self . var_xy0t , self . var_x0z0 , self . var_x00t , self . var_0y0t , self . var_xyn , self . var_xym , self . var_nn , self . var_nm , self . var_mm , ) compute_margins ( muxy , mux0 , mu0y ) \u00b6 Computes the margins from the matches and the singles. Source code in cupid_matching/matching_utils.py 21 22 23 24 25 def compute_margins ( muxy : np . ndarray , mux0 : np . ndarray , mu0y : np . ndarray ) -> TwoArrays : \"\"\"Computes the margins from the matches and the singles.\"\"\" n = np . sum ( muxy , 1 ) + mux0 m = np . sum ( muxy , 0 ) + mu0y return n , m get_margins ( mus ) \u00b6 compute_s the numbers of each type from the matching patterns Source code in cupid_matching/matching_utils.py 92 93 94 95 def get_margins ( mus : Matching ) -> TwoArrays : \"\"\"compute_s the numbers of each type from the matching patterns\"\"\" _ , _ , _ , n , m = mus . unpack () return n , m get_singles ( muxy , n , m ) \u00b6 Computes the numbers of singles from the matches and the margins. Source code in cupid_matching/matching_utils.py 14 15 16 17 18 def get_singles ( muxy : np . ndarray , n : np . ndarray , m : np . ndarray ) -> TwoArrays : \"\"\"Computes the numbers of singles from the matches and the margins.\"\"\" mux0 = n - np . sum ( muxy , 1 ) mu0y = m - np . sum ( muxy , 0 ) return mux0 , mu0y var_divide ( varmus , d ) \u00b6 divide all members by the same number Source code in cupid_matching/matching_utils.py 323 324 325 326 327 328 329 330 331 332 333 def var_divide ( varmus : VarianceMatching , d : float ) -> VarianceMatching : \"\"\"divide all members by the same number\"\"\" vardiv = VarianceMatching ( varmus . var_xyzt / d , varmus . var_xyz0 / d , varmus . var_xy0t / d , varmus . var_x0z0 / d , varmus . var_x00t / d , varmus . var_0y0t / d , ) return vardiv variance_muhat ( muhat ) \u00b6 Computes the unweighted variance-covariance matrix of the observed matching patterns Parameters: Name Type Description Default muhat Matching a Matching object required Returns: Type Description VarianceMatching the corresponding VarianceMatching object Source code in cupid_matching/matching_utils.py 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 def variance_muhat ( muhat : Matching ) -> VarianceMatching : \"\"\" Computes the unweighted variance-covariance matrix of the observed matching patterns Args: muhat: a Matching object Returns: the corresponding VarianceMatching object \"\"\" muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape # normalize all proportions n_households = muhat . n_households muxy_norm = ( muxy / n_households ) . ravel () mux0_norm = mux0 / n_households mu0y_norm = mu0y / n_households # we construct the variance of (muxy, mux0, mu0y) # variance of muxy v_xyzt = np . diag ( muxy_norm ) - np . outer ( muxy_norm , muxy_norm ) # covariance of muxy and mux0 v_xyz0 = - np . outer ( muxy_norm , mux0_norm ) # covariance of muxy and mu0y v_xy0t = - np . outer ( muxy_norm , mu0y_norm ) # variance of mux0 v_x0z0 = np . diag ( mux0_norm ) - np . outer ( mux0_norm , mux0_norm ) # covariance of mux0 and mu0y v_x00t = - np . outer ( mux0_norm , mu0y_norm ) # variance of mu0y v_0y0t = np . diag ( mu0y_norm ) - np . outer ( mu0y_norm , mu0y_norm ) v_xyzt *= n_households v_xyz0 *= n_households v_xy0t *= n_households v_x0z0 *= n_households v_x00t *= n_households v_0y0t *= n_households varmus = VarianceMatching ( var_xyzt = v_xyzt , var_xyz0 = v_xyz0 , var_xy0t = v_xy0t , var_x0z0 = v_x0z0 , var_x00t = v_x00t , var_0y0t = v_0y0t , ) return varmus","title":"Utilities for Matching"},{"location":"matching_utils/#matching_utils-module","text":"matching-related utilities","title":"matching_utils module"},{"location":"matching_utils/#cupid_matching.matching_utils.MatchingFunctionParam","text":"Same with a list of additional parameters","title":"MatchingFunctionParam"},{"location":"matching_utils/#cupid_matching.matching_utils.Matching","text":"stores the numbers of couples and singles of every type; muxy is an (X,Y)-matrix n is an X-vector m is an Y-vector mux0 and mu0y are generated as the corresponding numbers of singles as well as the total number of households n_households and the total number of individuals n_individuals Source code in cupid_matching/matching_utils.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 @dataclass class Matching : \"\"\"stores the numbers of couples and singles of every type; `muxy` is an (X,Y)-matrix `n` is an X-vector `m` is an Y-vector `mux0` and `mu0y` are generated as the corresponding numbers of singles as well as the total number of households `n_households` and the total number of individuals `n_individuals` \"\"\" muxy : np . ndarray n : np . ndarray m : np . ndarray mux0 : np . ndarray = field ( init = False ) mu0y : np . ndarray = field ( init = False ) n_households : float = field ( init = False ) n_individuals : float = field ( init = False ) def __str__ ( self ): X , Y = self . muxy . shape n_couples = np . sum ( self . muxy ) n_men , n_women = np . sum ( self . n ), np . sum ( self . m ) repr_str = f \"This is a matching with { n_men } men and { n_women } women. \\n \" repr_str += f \" with { n_couples } couples, \\n \\n \" repr_str += f \" We have { X } types of men and { Y } of women.\" return repr_str def __post_init__ ( self ): # print('inside __post_init__ method') X , Y = check_matrix ( self . muxy ) Xn = check_vector ( self . n ) Ym = check_vector ( self . m ) if Xn != X : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"muxy is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) self . mux0 , self . mu0y = get_singles ( self . muxy , self . n , self . m ) self . n_households = np . sum ( self . muxy ) + np . sum ( self . mux0 ) + np . sum ( self . mu0y ) self . n_individuals = ( 2.0 * np . sum ( self . muxy ) + np . sum ( self . mux0 ) + np . sum ( self . mu0y ) ) def unpack ( self ): muxy , mux0 , mu0y = self . muxy , self . mux0 , self . mu0y min_xy , min_x0 , min_0y = np . min ( muxy ), np . min ( mux0 ), np . min ( mu0y ) if min_xy < 0.0 : bs_error_abort ( f \"The smallest muxy is { min_xy } \" ) if min_x0 < 0.0 : bs_error_abort ( f \"The smallest mux0 is { min_x0 } \" ) if min_0y < 0.0 : bs_error_abort ( f \"The smallest mux0 is { min_0y } \" ) return muxy , mux0 , mu0y , self . n , self . m","title":"Matching"},{"location":"matching_utils/#cupid_matching.matching_utils.VarianceMatching","text":"initialized with the six matrix components of the variance of a Matching compute_s six more var_xyzt is the (XY, XY) var-cov matrix of muxy var_xyz0 is the (XY, X) covariance matrix of muxy and mux0 var_xy0t is the (XY, Y) covariance matrix of muxy and mu0y var_x0z0 is the (X, X) var-cov matrix of mux0 var_x00t is the (X, Y) covariance matrix of mux0 and mu0y var_0y0t is the (Y, Y) var-cov matrix of mu0y var_xyn is the (XY, X) covariance matrix of muxy and nx var_xym is the (XY, Y) covariance matrix of muxy and my var_nn is the (X, X) var-cov matrix of nx var_nm is the (X, Y) covariance matrix of nx and my var_mm is the (Y, Y) var-cov matrix of my var_allmus is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, mux0, mu0y) var_munm is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, n, m) Source code in cupid_matching/matching_utils.py 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 @dataclass class VarianceMatching : \"\"\"initialized with the six matrix components of the variance of a Matching compute_s six more `var_xyzt` is the (XY, XY) var-cov matrix of `muxy` `var_xyz0` is the (XY, X) covariance matrix of `muxy` and `mux0` `var_xy0t` is the (XY, Y) covariance matrix of `muxy` and `mu0y` `var_x0z0` is the (X, X) var-cov matrix of `mux0` `var_x00t` is the (X, Y) covariance matrix of `mux0` and `mu0y` `var_0y0t` is the (Y, Y) var-cov matrix of `mu0y` `var_xyn` is the (XY, X) covariance matrix of `muxy` and `nx` `var_xym` is the (XY, Y) covariance matrix of `muxy` and `my` `var_nn` is the (X, X) var-cov matrix of `nx` `var_nm` is the (X, Y) covariance matrix of `nx` and `my` `var_mm` is the (Y, Y) var-cov matrix of `my` `var_allmus` is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, mux0, mu0y) `var_munm` is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, n, m) \"\"\" var_xyzt : np . ndarray var_xyz0 : np . ndarray var_xy0t : np . ndarray var_x0z0 : np . ndarray var_x00t : np . ndarray var_0y0t : np . ndarray var_xyn : np . ndarray = field ( init = False ) var_xym : np . ndarray = field ( init = False ) var_nn : np . ndarray = field ( init = False ) var_nm : np . ndarray = field ( init = False ) var_mm : np . ndarray = field ( init = False ) var_allmus : np . ndarray = field ( init = False ) var_munm : np . ndarray = field ( init = False ) def __str__ ( self ): n_men = self . var_xyz0 . shape [ 1 ] n_women = self . var_xy0t . shape [ 1 ] repr_str = f \"This is a VarianceMatching with { n_men } men, { n_women } women. \\n \" return repr_str def __post_init__ ( self ): # print('inside __post_init__ method') v_xyzt = self . var_xyzt XY , XY2 = check_matrix ( v_xyzt ) if XY2 != XY : bs_error_abort ( f \"var_xyzt should be a square matrix, not ( { XY } , { XY2 } )\" ) v_xyz0 = self . var_xyz0 XY3 , X = check_matrix ( v_xyz0 ) if XY3 != XY : bs_error_abort ( f \"var_xyz0 should have { XY } rows, not { XY3 } )\" ) v_xy0t = self . var_xy0t XY4 , Y = check_matrix ( v_xy0t ) if XY4 != XY : bs_error_abort ( f \"var_xy0t should have { XY } rows, not { XY4 } )\" ) if X * Y != XY : bs_error_abort ( f \"var_xyzt has { XY } rows, but varxyz0 has { X } columns and varxy0t\" f \" has { Y } \" ) v_x0z0 = self . var_x0z0 X2 , X3 = check_matrix ( v_x0z0 ) if X2 != X : bs_error_abort ( f \"var_x0z0 has { X2 } rows, it should have { X } \" ) if X3 != X : bs_error_abort ( f \"var_x0z0 has { X3 } columns, it should have { X } \" ) v_x00t = self . var_x00t X4 , Y2 = check_matrix ( v_x00t ) if X4 != X : bs_error_abort ( f \"var_x00t has { X4 } rows, it should have { X } \" ) if Y2 != Y : bs_error_abort ( f \"var_x00t has { Y2 } columns, it should have { Y } \" ) v_0y0t = self . var_0y0t Y3 , Y4 = check_matrix ( v_0y0t ) if Y3 != Y : bs_error_abort ( f \"var_x00t has { Y3 } rows, it should have { Y } \" ) if Y4 != Y : bs_error_abort ( f \"var_x00t has { Y4 } columns, it should have { Y } \" ) # now we compute_ the five additional components v_xyn = v_xyz0 . copy () sumt_covx0_zt = np . zeros (( X , X )) iz = 0 for z in range ( X ): v_xyn [:, z ] += np . sum ( v_xyzt [:, iz : ( iz + Y )], 1 ) sumt_covx0_zt [:, z ] = np . sum ( v_xyz0 [ iz : ( iz + Y ), :], 0 ) iz += Y self . var_xyn = v_xyn v_xym = v_xy0t . copy () v_0ym = v_0y0t . copy () for t in range ( Y ): slice_t = slice ( t , XY , Y ) v_xym [:, t ] += np . sum ( v_xyzt [:, slice_t ], 1 ) v_0ym [:, t ] += np . sum ( v_xy0t [ slice_t , :], 0 ) self . var_xym = v_xym v_x0n = v_x0z0 + sumt_covx0_zt v_nn = v_x0n v_0yn = v_x00t . copy () . T ix = 0 for x in range ( X ): v_nn [ x , :] += np . sum ( v_xyn [ ix : ( ix + Y ), :], 0 ) v_0yn [:, x ] += np . sum ( v_xy0t [ ix : ( ix + Y ), :], 0 ) ix += Y self . var_nn = v_nn v_nm = v_0yn . T v_mm = v_0ym for y in range ( Y ): slice_y = slice ( y , XY , Y ) v_nm [:, y ] += np . sum ( v_xyn [ slice_y , :], 0 ) v_mm [ y , :] += np . sum ( v_xym [ slice_y , :], 0 ) self . var_nm = v_nm self . var_mm = v_mm self . var_allmus = self . make_var_allmus () self . var_munm = self . make_var_munm () def unpack ( self ): \"\"\"return a tuple of all members of this `VarianceMatching`\"\"\" return ( self . var_xyzt , self . var_xyz0 , self . var_xy0t , self . var_x0z0 , self . var_x00t , self . var_0y0t , self . var_xyn , self . var_xym , self . var_nn , self . var_nm , self . var_mm , ) def make_var_allmus ( self : Any ) -> np . ndarray : \"\"\"create the variance-covariance of `(muxy, mux0, mu0y)` Args: self: the VarianceMatching object Returns: an (XY+X+Y, XY+X+Y) symmetric positive matrix \"\"\" v_xyzt , v_xyz0 , v_xy0t , v_x0z0 , v_x00t , v_0y0t , * _ = self . unpack () X , Y = v_x0z0 . shape [ 0 ], v_0y0t . shape [ 0 ] XY = X * Y sz = XY + X + Y v_allmus = np . zeros (( sz , sz )) v_allmus [: XY , : XY ] = v_xyzt v_allmus [: XY , XY : ( XY + X )] = v_xyz0 v_allmus [ XY : ( XY + X ), : XY ] = v_xyz0 . T v_allmus [: XY , ( XY + X ) :] = v_xy0t v_allmus [( XY + X ) :, : XY ] = v_xy0t . T v_allmus [ XY : ( XY + X ), XY : ( XY + X )] = v_x0z0 v_allmus [ XY : ( XY + X ), ( XY + X ) :] = v_x00t v_allmus [( XY + X ) :, XY : ( XY + X )] = v_x00t . T v_allmus [( XY + X ) :, ( XY + X ) :] = v_0y0t return v_allmus def make_var_munm ( self : Any ) -> np . ndarray : \"\"\"create the variance-covariance of (muxy, n, m) Args: self: this `VarianceMatching` object Returns: an (XY+X+Y, XY+X+Y) symmetric positive matrix \"\"\" v_xyzt , * _ , v_xyn , v_xym , v_nn , v_nm , v_mm = self . unpack () X , Y = v_nn . shape [ 0 ], v_mm . shape [ 0 ] XY = X * Y sz = XY + X + Y v_munm = np . zeros (( sz , sz )) v_munm [: XY , : XY ] = v_xyzt v_munm [: XY , XY : ( XY + X )] = v_xyn v_munm [ XY : ( XY + X ), : XY ] = v_xyn . T v_munm [: XY , ( XY + X ) :] = v_xym v_munm [( XY + X ) :, : XY ] = v_xym . T v_munm [ XY : ( XY + X ), XY : ( XY + X )] = v_nn v_munm [ XY : ( XY + X ), ( XY + X ) :] = v_nm v_munm [( XY + X ) :, XY : ( XY + X )] = v_nm . T v_munm [( XY + X ) :, ( XY + X ) :] = v_mm return v_munm","title":"VarianceMatching"},{"location":"matching_utils/#cupid_matching.matching_utils.VarianceMatching.make_var_allmus","text":"create the variance-covariance of (muxy, mux0, mu0y) Parameters: Name Type Description Default self Any the VarianceMatching object required Returns: Type Description np . ndarray an (XY+X+Y, XY+X+Y) symmetric positive matrix Source code in cupid_matching/matching_utils.py 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 def make_var_allmus ( self : Any ) -> np . ndarray : \"\"\"create the variance-covariance of `(muxy, mux0, mu0y)` Args: self: the VarianceMatching object Returns: an (XY+X+Y, XY+X+Y) symmetric positive matrix \"\"\" v_xyzt , v_xyz0 , v_xy0t , v_x0z0 , v_x00t , v_0y0t , * _ = self . unpack () X , Y = v_x0z0 . shape [ 0 ], v_0y0t . shape [ 0 ] XY = X * Y sz = XY + X + Y v_allmus = np . zeros (( sz , sz )) v_allmus [: XY , : XY ] = v_xyzt v_allmus [: XY , XY : ( XY + X )] = v_xyz0 v_allmus [ XY : ( XY + X ), : XY ] = v_xyz0 . T v_allmus [: XY , ( XY + X ) :] = v_xy0t v_allmus [( XY + X ) :, : XY ] = v_xy0t . T v_allmus [ XY : ( XY + X ), XY : ( XY + X )] = v_x0z0 v_allmus [ XY : ( XY + X ), ( XY + X ) :] = v_x00t v_allmus [( XY + X ) :, XY : ( XY + X )] = v_x00t . T v_allmus [( XY + X ) :, ( XY + X ) :] = v_0y0t return v_allmus","title":"make_var_allmus()"},{"location":"matching_utils/#cupid_matching.matching_utils.VarianceMatching.make_var_munm","text":"create the variance-covariance of (muxy, n, m) Parameters: Name Type Description Default self Any this VarianceMatching object required Returns: Type Description np . ndarray an (XY+X+Y, XY+X+Y) symmetric positive matrix Source code in cupid_matching/matching_utils.py 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 def make_var_munm ( self : Any ) -> np . ndarray : \"\"\"create the variance-covariance of (muxy, n, m) Args: self: this `VarianceMatching` object Returns: an (XY+X+Y, XY+X+Y) symmetric positive matrix \"\"\" v_xyzt , * _ , v_xyn , v_xym , v_nn , v_nm , v_mm = self . unpack () X , Y = v_nn . shape [ 0 ], v_mm . shape [ 0 ] XY = X * Y sz = XY + X + Y v_munm = np . zeros (( sz , sz )) v_munm [: XY , : XY ] = v_xyzt v_munm [: XY , XY : ( XY + X )] = v_xyn v_munm [ XY : ( XY + X ), : XY ] = v_xyn . T v_munm [: XY , ( XY + X ) :] = v_xym v_munm [( XY + X ) :, : XY ] = v_xym . T v_munm [ XY : ( XY + X ), XY : ( XY + X )] = v_nn v_munm [ XY : ( XY + X ), ( XY + X ) :] = v_nm v_munm [( XY + X ) :, XY : ( XY + X )] = v_nm . T v_munm [( XY + X ) :, ( XY + X ) :] = v_mm return v_munm","title":"make_var_munm()"},{"location":"matching_utils/#cupid_matching.matching_utils.VarianceMatching.unpack","text":"return a tuple of all members of this VarianceMatching Source code in cupid_matching/matching_utils.py 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 def unpack ( self ): \"\"\"return a tuple of all members of this `VarianceMatching`\"\"\" return ( self . var_xyzt , self . var_xyz0 , self . var_xy0t , self . var_x0z0 , self . var_x00t , self . var_0y0t , self . var_xyn , self . var_xym , self . var_nn , self . var_nm , self . var_mm , )","title":"unpack()"},{"location":"matching_utils/#cupid_matching.matching_utils.compute_margins","text":"Computes the margins from the matches and the singles. Source code in cupid_matching/matching_utils.py 21 22 23 24 25 def compute_margins ( muxy : np . ndarray , mux0 : np . ndarray , mu0y : np . ndarray ) -> TwoArrays : \"\"\"Computes the margins from the matches and the singles.\"\"\" n = np . sum ( muxy , 1 ) + mux0 m = np . sum ( muxy , 0 ) + mu0y return n , m","title":"compute_margins()"},{"location":"matching_utils/#cupid_matching.matching_utils.get_margins","text":"compute_s the numbers of each type from the matching patterns Source code in cupid_matching/matching_utils.py 92 93 94 95 def get_margins ( mus : Matching ) -> TwoArrays : \"\"\"compute_s the numbers of each type from the matching patterns\"\"\" _ , _ , _ , n , m = mus . unpack () return n , m","title":"get_margins()"},{"location":"matching_utils/#cupid_matching.matching_utils.get_singles","text":"Computes the numbers of singles from the matches and the margins. Source code in cupid_matching/matching_utils.py 14 15 16 17 18 def get_singles ( muxy : np . ndarray , n : np . ndarray , m : np . ndarray ) -> TwoArrays : \"\"\"Computes the numbers of singles from the matches and the margins.\"\"\" mux0 = n - np . sum ( muxy , 1 ) mu0y = m - np . sum ( muxy , 0 ) return mux0 , mu0y","title":"get_singles()"},{"location":"matching_utils/#cupid_matching.matching_utils.var_divide","text":"divide all members by the same number Source code in cupid_matching/matching_utils.py 323 324 325 326 327 328 329 330 331 332 333 def var_divide ( varmus : VarianceMatching , d : float ) -> VarianceMatching : \"\"\"divide all members by the same number\"\"\" vardiv = VarianceMatching ( varmus . var_xyzt / d , varmus . var_xyz0 / d , varmus . var_xy0t / d , varmus . var_x0z0 / d , varmus . var_x00t / d , varmus . var_0y0t / d , ) return vardiv","title":"var_divide()"},{"location":"matching_utils/#cupid_matching.matching_utils.variance_muhat","text":"Computes the unweighted variance-covariance matrix of the observed matching patterns Parameters: Name Type Description Default muhat Matching a Matching object required Returns: Type Description VarianceMatching the corresponding VarianceMatching object Source code in cupid_matching/matching_utils.py 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 def variance_muhat ( muhat : Matching ) -> VarianceMatching : \"\"\" Computes the unweighted variance-covariance matrix of the observed matching patterns Args: muhat: a Matching object Returns: the corresponding VarianceMatching object \"\"\" muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape # normalize all proportions n_households = muhat . n_households muxy_norm = ( muxy / n_households ) . ravel () mux0_norm = mux0 / n_households mu0y_norm = mu0y / n_households # we construct the variance of (muxy, mux0, mu0y) # variance of muxy v_xyzt = np . diag ( muxy_norm ) - np . outer ( muxy_norm , muxy_norm ) # covariance of muxy and mux0 v_xyz0 = - np . outer ( muxy_norm , mux0_norm ) # covariance of muxy and mu0y v_xy0t = - np . outer ( muxy_norm , mu0y_norm ) # variance of mux0 v_x0z0 = np . diag ( mux0_norm ) - np . outer ( mux0_norm , mux0_norm ) # covariance of mux0 and mu0y v_x00t = - np . outer ( mux0_norm , mu0y_norm ) # variance of mu0y v_0y0t = np . diag ( mu0y_norm ) - np . outer ( mu0y_norm , mu0y_norm ) v_xyzt *= n_households v_xyz0 *= n_households v_xy0t *= n_households v_x0z0 *= n_households v_x00t *= n_households v_0y0t *= n_households varmus = VarianceMatching ( var_xyzt = v_xyzt , var_xyz0 = v_xyz0 , var_xy0t = v_xy0t , var_x0z0 = v_x0z0 , var_x00t = v_x00t , var_0y0t = v_0y0t , ) return varmus","title":"variance_muhat()"},{"location":"min_distance/","text":"min_distance module \u00b6 Estimates semilinear separable models with a given entropy function. The entropy function and the surplus matrix must both be linear in the parameters. estimate_semilinear_mde ( muhat , phi_bases , entropy , additional_parameters = None , initial_weights = None ) \u00b6 Estimates the parameters of the distributions and of the base functions. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases np . ndarray an (X, Y, K) array of bases required entropy EntropyFunctions an EntropyFunctions object required additional_parameters list | None additional parameters of the distribution of errors, if any None initial_weights np . ndarray | None if specified, used as the weighting matrix for the first step when entropy.param_dependent is True None Returns: Type Description MDEResults an MDEResults instance Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # We simulate a Choo and Siow homoskedastic marriage market # and we estimate a gender-heteroskedastic model on the simulated data. X , Y , K = 10 , 20 , 2 n_households = int ( 1e6 ) lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) choo_siow_instance . describe () entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np . ones ( n_alpha ) true_coeffs = np . concatenate (( true_alpha , lambda_true )) print_stars ( entropy_model . description ) mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy_model ) mde_results . print_results ( true_coeffs = true_coeffs , n_alpha = 1 ) Source code in cupid_matching/min_distance.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 def estimate_semilinear_mde ( muhat : Matching , phi_bases : np . ndarray , entropy : EntropyFunctions , additional_parameters : list | None = None , initial_weights : np . ndarray | None = None , ) -> MDEResults : \"\"\" Estimates the parameters of the distributions and of the base functions. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases entropy: an `EntropyFunctions` object additional_parameters: additional parameters of the distribution of errors, if any initial_weights: if specified, used as the weighting matrix for the first step when `entropy.param_dependent` is `True` Returns: an `MDEResults` instance Example: ```py # We simulate a Choo and Siow homoskedastic marriage market # and we estimate a gender-heteroskedastic model on the simulated data. X, Y, K = 10, 20, 2 n_households = int(1e6) lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) n = np.ones(X) m = np.ones(Y) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) choo_siow_instance.describe() entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np.ones(n_alpha) true_coeffs = np.concatenate((true_alpha, lambda_true)) print_stars(entropy_model.description) mde_results = estimate_semilinear_mde( mus_sim, phi_bases, entropy_model) mde_results.print_results(true_coeffs=true_coeffs, n_alpha=1) ``` \"\"\" muxyhat , _ , _ , nhat , mhat = muhat . unpack () X , Y = muxyhat . shape XY = X * Y ndims_phi = phi_bases . ndim if ndims_phi != 3 : bs_error_abort ( f \"phi_bases should have 3 dimensions, not { ndims_phi } \" ) Xp , Yp , K = phi_bases . shape if Xp != X or Yp != Y : bs_error_abort ( f \"phi_bases should have shape ( { X } , { Y } , { K } ) not ( { Xp } , { Yp } , { K } )\" ) parameterized_entropy = entropy . parameter_dependent if parameterized_entropy : if initial_weights is None : print_stars ( \"Using the identity matrix as weighting matrix in the first step.\" ) S_mat = np . eye ( XY ) else : S_mat = initial_weights phi_mat = _make_XY_K_mat ( phi_bases ) e0_fun = entropy . e0_fun if additional_parameters is None : e0_fun = cast ( MatchingFunction , e0_fun ) e0_vals = e0_fun ( muhat ) else : e0_fun = cast ( MatchingFunctionParam , e0_fun ) e0_vals = e0_fun ( muhat , additional_parameters ) e0_hat = e0_vals . ravel () if not parameterized_entropy : # we only have e0(mu,r) n_pars = K hessian = entropy . hessian if hessian == \"provided\" : e0_derivative = cast ( EntropyHessians , entropy . e0_derivative ) if additional_parameters is None : hessian_components_mumu = e0_derivative [ 0 ]( muhat ) hessian_components_mur = e0_derivative [ 1 ]( muhat ) else : e0_derivative1 = cast ( EntropyHessiansParam , entropy . e0_derivative ) hessian_components_mumu = e0_derivative1 [ 0 ]( muhat , additional_parameters ) hessian_components_mur = e0_derivative1 [ 1 ]( muhat , additional_parameters ) else : if additional_parameters is None : hessian_components = _numeric_hessian ( entropy , muhat ) else : hessian_components = _numeric_hessian ( entropy , muhat , additional_parameters = additional_parameters , ) ( hessian_components_mumu , hessian_components_mur , ) = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) var_muhat = variance_muhat ( muhat ) var_munm = var_muhat . var_munm var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) estimated_coefficients , varcov_coefficients = compute_estimates ( phi_mat , S_mat , e0_hat ) stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ estimated_coefficients residuals = est_Phi + e0_hat else : # parameterized entropy: e0(mu,r) + e(mu,r) . alpha # create the F matrix if additional_parameters is None : e_fun = cast ( MatchingFunction , entropy . e_fun ) e_vals = e_fun ( muhat ) else : e_fun1 = cast ( MatchingFunctionParam , entropy . e_fun ) e_vals = e_fun1 ( muhat , additional_parameters ) e_hat = _make_XY_K_mat ( e_vals ) F_hat = np . column_stack (( e_hat , phi_mat )) n_pars = e_hat . shape [ 1 ] + K # first pass with an initial weighting matrix first_coeffs , _ = compute_estimates ( F_hat , S_mat , e0_hat ) first_alpha = first_coeffs [: - K ] # compute_ the efficient weighting matrix hessian = entropy . hessian if hessian == \"provided\" : if additional_parameters is None : e0_derivative = cast ( EntropyHessians , entropy . e0_derivative ) e_derivative = cast ( EntropyHessians , entropy . e_derivative ) e0_derivative_mumu = cast ( EntropyHessianMuMu , e0_derivative [ 0 ]) hessian_components_mumu_e0 = e0_derivative_mumu ( muhat ) e0_derivative_mur = cast ( EntropyHessianMuR , e0_derivative [ 1 ]) hessian_components_mur_e0 = e0_derivative_mur ( muhat ) e_derivative_mumu = cast ( EntropyHessianMuMu , e_derivative [ 0 ]) hessian_components_mumu_e = e_derivative_mumu ( muhat ) e_derivative_mur = cast ( EntropyHessianMuR , e_derivative [ 1 ]) hessian_components_mur_e = e_derivative_mur ( muhat ) else : e0_derivative1 = cast ( EntropyHessiansParam , entropy . e0_derivative ) e_derivative1 = cast ( EntropyHessiansParam , entropy . e_derivative ) e0_derivative_mumu1 = cast ( EntropyHessianMuMuParam , e0_derivative1 [ 0 ]) e0_derivative_mur1 = cast ( EntropyHessianMuRParam , e0_derivative1 [ 1 ]) e_derivative_mumu1 = cast ( EntropyHessianMuMuParam , e_derivative1 [ 0 ]) e_derivative_mur1 = cast ( EntropyHessianMuRParam , e_derivative1 [ 1 ]) hessian_components_mumu_e0 = e0_derivative_mumu1 ( muhat , additional_parameters ) hessian_components_mur_e0 = e0_derivative_mur1 ( muhat , additional_parameters ) hessian_components_mumu_e = e_derivative_mumu1 ( muhat , additional_parameters ) hessian_components_mur_e = e_derivative_mur1 ( muhat , additional_parameters ) # print_stars(\"First-stage estimates:\") # print(first_coeffs) hessian_components_mumu1 = ( hessian_components_mumu_e0 [ 0 ] + hessian_components_mumu_e [ 0 ] @ first_alpha , hessian_components_mumu_e0 [ 1 ] + hessian_components_mumu_e [ 1 ] @ first_alpha , hessian_components_mumu_e0 [ 2 ] + hessian_components_mumu_e [ 2 ] @ first_alpha , ) hessian_components_mur1 = ( hessian_components_mur_e0 [ 0 ] + hessian_components_mur_e [ 0 ] @ first_alpha , hessian_components_mur_e0 [ 1 ] + hessian_components_mur_e [ 1 ] @ first_alpha , ) hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu1 ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur1 ) else : # numeric hessian if additional_parameters is None : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha ) else : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha , additional_parameters = additional_parameters , ) ( hessian_components_mumu , hessian_components_mur , ) = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) varmus = variance_muhat ( muhat ) var_munm = varmus . var_munm var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) # second pass estimated_coefficients , varcov_coefficients = compute_estimates ( F_hat , S_mat , e0_hat ) est_alpha , est_beta = ( estimated_coefficients [: - K ], estimated_coefficients [ - K :], ) stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ est_beta residuals = est_Phi + e0_hat + e_hat @ est_alpha value_obj = residuals . T @ S_mat @ residuals ndf = X * Y - n_pars test_stat = value_obj n_individuals = np . sum ( nhat ) + np . sum ( mhat ) n_households = n_individuals - np . sum ( muxyhat ) results = MDEResults ( X = X , Y = Y , K = K , number_households = n_households , estimated_coefficients = estimated_coefficients , varcov_coefficients = varcov_coefficients , stderrs_coefficients = stderrs_coefficients , estimated_Phi = est_Phi . reshape (( X , Y )), test_statistic = test_stat , ndf = ndf , test_pvalue = sts . chi2 . sf ( test_stat , ndf ), parameterized_entropy = parameterized_entropy , ) return results","title":"Minimum Distance Estimator"},{"location":"min_distance/#min_distance-module","text":"Estimates semilinear separable models with a given entropy function. The entropy function and the surplus matrix must both be linear in the parameters.","title":"min_distance module"},{"location":"min_distance/#cupid_matching.min_distance.estimate_semilinear_mde","text":"Estimates the parameters of the distributions and of the base functions. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases np . ndarray an (X, Y, K) array of bases required entropy EntropyFunctions an EntropyFunctions object required additional_parameters list | None additional parameters of the distribution of errors, if any None initial_weights np . ndarray | None if specified, used as the weighting matrix for the first step when entropy.param_dependent is True None Returns: Type Description MDEResults an MDEResults instance Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # We simulate a Choo and Siow homoskedastic marriage market # and we estimate a gender-heteroskedastic model on the simulated data. X , Y , K = 10 , 20 , 2 n_households = int ( 1e6 ) lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) n = np . ones ( X ) m = np . ones ( Y ) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) choo_siow_instance . describe () entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np . ones ( n_alpha ) true_coeffs = np . concatenate (( true_alpha , lambda_true )) print_stars ( entropy_model . description ) mde_results = estimate_semilinear_mde ( mus_sim , phi_bases , entropy_model ) mde_results . print_results ( true_coeffs = true_coeffs , n_alpha = 1 ) Source code in cupid_matching/min_distance.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 def estimate_semilinear_mde ( muhat : Matching , phi_bases : np . ndarray , entropy : EntropyFunctions , additional_parameters : list | None = None , initial_weights : np . ndarray | None = None , ) -> MDEResults : \"\"\" Estimates the parameters of the distributions and of the base functions. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases entropy: an `EntropyFunctions` object additional_parameters: additional parameters of the distribution of errors, if any initial_weights: if specified, used as the weighting matrix for the first step when `entropy.param_dependent` is `True` Returns: an `MDEResults` instance Example: ```py # We simulate a Choo and Siow homoskedastic marriage market # and we estimate a gender-heteroskedastic model on the simulated data. X, Y, K = 10, 20, 2 n_households = int(1e6) lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) n = np.ones(X) m = np.ones(Y) Phi = phi_bases @ lambda_true choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) choo_siow_instance.describe() entropy_model = entropy_choo_siow_gender_heteroskedastic_numeric n_alpha = 1 true_alpha = np.ones(n_alpha) true_coeffs = np.concatenate((true_alpha, lambda_true)) print_stars(entropy_model.description) mde_results = estimate_semilinear_mde( mus_sim, phi_bases, entropy_model) mde_results.print_results(true_coeffs=true_coeffs, n_alpha=1) ``` \"\"\" muxyhat , _ , _ , nhat , mhat = muhat . unpack () X , Y = muxyhat . shape XY = X * Y ndims_phi = phi_bases . ndim if ndims_phi != 3 : bs_error_abort ( f \"phi_bases should have 3 dimensions, not { ndims_phi } \" ) Xp , Yp , K = phi_bases . shape if Xp != X or Yp != Y : bs_error_abort ( f \"phi_bases should have shape ( { X } , { Y } , { K } ) not ( { Xp } , { Yp } , { K } )\" ) parameterized_entropy = entropy . parameter_dependent if parameterized_entropy : if initial_weights is None : print_stars ( \"Using the identity matrix as weighting matrix in the first step.\" ) S_mat = np . eye ( XY ) else : S_mat = initial_weights phi_mat = _make_XY_K_mat ( phi_bases ) e0_fun = entropy . e0_fun if additional_parameters is None : e0_fun = cast ( MatchingFunction , e0_fun ) e0_vals = e0_fun ( muhat ) else : e0_fun = cast ( MatchingFunctionParam , e0_fun ) e0_vals = e0_fun ( muhat , additional_parameters ) e0_hat = e0_vals . ravel () if not parameterized_entropy : # we only have e0(mu,r) n_pars = K hessian = entropy . hessian if hessian == \"provided\" : e0_derivative = cast ( EntropyHessians , entropy . e0_derivative ) if additional_parameters is None : hessian_components_mumu = e0_derivative [ 0 ]( muhat ) hessian_components_mur = e0_derivative [ 1 ]( muhat ) else : e0_derivative1 = cast ( EntropyHessiansParam , entropy . e0_derivative ) hessian_components_mumu = e0_derivative1 [ 0 ]( muhat , additional_parameters ) hessian_components_mur = e0_derivative1 [ 1 ]( muhat , additional_parameters ) else : if additional_parameters is None : hessian_components = _numeric_hessian ( entropy , muhat ) else : hessian_components = _numeric_hessian ( entropy , muhat , additional_parameters = additional_parameters , ) ( hessian_components_mumu , hessian_components_mur , ) = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) var_muhat = variance_muhat ( muhat ) var_munm = var_muhat . var_munm var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) estimated_coefficients , varcov_coefficients = compute_estimates ( phi_mat , S_mat , e0_hat ) stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ estimated_coefficients residuals = est_Phi + e0_hat else : # parameterized entropy: e0(mu,r) + e(mu,r) . alpha # create the F matrix if additional_parameters is None : e_fun = cast ( MatchingFunction , entropy . e_fun ) e_vals = e_fun ( muhat ) else : e_fun1 = cast ( MatchingFunctionParam , entropy . e_fun ) e_vals = e_fun1 ( muhat , additional_parameters ) e_hat = _make_XY_K_mat ( e_vals ) F_hat = np . column_stack (( e_hat , phi_mat )) n_pars = e_hat . shape [ 1 ] + K # first pass with an initial weighting matrix first_coeffs , _ = compute_estimates ( F_hat , S_mat , e0_hat ) first_alpha = first_coeffs [: - K ] # compute_ the efficient weighting matrix hessian = entropy . hessian if hessian == \"provided\" : if additional_parameters is None : e0_derivative = cast ( EntropyHessians , entropy . e0_derivative ) e_derivative = cast ( EntropyHessians , entropy . e_derivative ) e0_derivative_mumu = cast ( EntropyHessianMuMu , e0_derivative [ 0 ]) hessian_components_mumu_e0 = e0_derivative_mumu ( muhat ) e0_derivative_mur = cast ( EntropyHessianMuR , e0_derivative [ 1 ]) hessian_components_mur_e0 = e0_derivative_mur ( muhat ) e_derivative_mumu = cast ( EntropyHessianMuMu , e_derivative [ 0 ]) hessian_components_mumu_e = e_derivative_mumu ( muhat ) e_derivative_mur = cast ( EntropyHessianMuR , e_derivative [ 1 ]) hessian_components_mur_e = e_derivative_mur ( muhat ) else : e0_derivative1 = cast ( EntropyHessiansParam , entropy . e0_derivative ) e_derivative1 = cast ( EntropyHessiansParam , entropy . e_derivative ) e0_derivative_mumu1 = cast ( EntropyHessianMuMuParam , e0_derivative1 [ 0 ]) e0_derivative_mur1 = cast ( EntropyHessianMuRParam , e0_derivative1 [ 1 ]) e_derivative_mumu1 = cast ( EntropyHessianMuMuParam , e_derivative1 [ 0 ]) e_derivative_mur1 = cast ( EntropyHessianMuRParam , e_derivative1 [ 1 ]) hessian_components_mumu_e0 = e0_derivative_mumu1 ( muhat , additional_parameters ) hessian_components_mur_e0 = e0_derivative_mur1 ( muhat , additional_parameters ) hessian_components_mumu_e = e_derivative_mumu1 ( muhat , additional_parameters ) hessian_components_mur_e = e_derivative_mur1 ( muhat , additional_parameters ) # print_stars(\"First-stage estimates:\") # print(first_coeffs) hessian_components_mumu1 = ( hessian_components_mumu_e0 [ 0 ] + hessian_components_mumu_e [ 0 ] @ first_alpha , hessian_components_mumu_e0 [ 1 ] + hessian_components_mumu_e [ 1 ] @ first_alpha , hessian_components_mumu_e0 [ 2 ] + hessian_components_mumu_e [ 2 ] @ first_alpha , ) hessian_components_mur1 = ( hessian_components_mur_e0 [ 0 ] + hessian_components_mur_e [ 0 ] @ first_alpha , hessian_components_mur_e0 [ 1 ] + hessian_components_mur_e [ 1 ] @ first_alpha , ) hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu1 ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur1 ) else : # numeric hessian if additional_parameters is None : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha ) else : hessian_components = _numeric_hessian ( entropy , muhat , alpha = first_alpha , additional_parameters = additional_parameters , ) ( hessian_components_mumu , hessian_components_mur , ) = hessian_components hessian_mumu = _fill_hessianMuMu_from_components ( hessian_components_mumu ) hessian_mur = _fill_hessianMuR_from_components ( hessian_components_mur ) hessians_both = np . concatenate (( hessian_mumu , hessian_mur ), axis = 1 ) varmus = variance_muhat ( muhat ) var_munm = varmus . var_munm var_entropy_gradient = hessians_both @ var_munm @ hessians_both . T S_mat = spla . inv ( var_entropy_gradient ) # second pass estimated_coefficients , varcov_coefficients = compute_estimates ( F_hat , S_mat , e0_hat ) est_alpha , est_beta = ( estimated_coefficients [: - K ], estimated_coefficients [ - K :], ) stderrs_coefficients = np . sqrt ( np . diag ( varcov_coefficients )) est_Phi = phi_mat @ est_beta residuals = est_Phi + e0_hat + e_hat @ est_alpha value_obj = residuals . T @ S_mat @ residuals ndf = X * Y - n_pars test_stat = value_obj n_individuals = np . sum ( nhat ) + np . sum ( mhat ) n_households = n_individuals - np . sum ( muxyhat ) results = MDEResults ( X = X , Y = Y , K = K , number_households = n_households , estimated_coefficients = estimated_coefficients , varcov_coefficients = varcov_coefficients , stderrs_coefficients = stderrs_coefficients , estimated_Phi = est_Phi . reshape (( X , Y )), test_statistic = test_stat , ndf = ndf , test_pvalue = sts . chi2 . sf ( test_stat , ndf ), parameterized_entropy = parameterized_entropy , ) return results","title":"estimate_semilinear_mde()"},{"location":"min_distance_utils/","text":"min_distance_utils module \u00b6 Utility programs used in min_distance.py . MDEResults dataclass \u00b6 The results from minimum-distance estimation and testing. Parameters: Name Type Description Default X int the number of types of men required Y int the number of types of women required K int the number of bases required number_households int the number of households in the sample required estimated_coefficients np . ndarray the estimated coefficients required varcov_coefficients np . ndarray their eetimated var-covar required stderrs_coefficients np . ndarray their estimated stderrs required estimated_Phi np . ndarray the estimated joint surplus required test_statistic float the value of the misspecification statistic required test_pvalue float the p-value of the test required ndf int the number of degrees of freedom required parameterized_entropy bool | None True if the derivative of the entropy has unknown parameters False Source code in cupid_matching/min_distance_utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 @dataclass class MDEResults : \"\"\" The results from minimum-distance estimation and testing. Args: X: the number of types of men Y: the number of types of women K: the number of bases number_households: the number of households in the sample estimated_coefficients: the estimated coefficients varcov_coefficients: their eetimated var-covar stderrs_coefficients: their estimated stderrs estimated_Phi: the estimated joint surplus test_statistic: the value of the misspecification statistic test_pvalue: the p-value of the test ndf: the number of degrees of freedom parameterized_entropy: True if the derivative of the entropy has unknown parameters \"\"\" X : int Y : int K : int number_households : int estimated_coefficients : np . ndarray varcov_coefficients : np . ndarray stderrs_coefficients : np . ndarray estimated_Phi : np . ndarray test_statistic : float test_pvalue : float ndf : int parameterized_entropy : bool | None = False def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" if self . parameterized_entropy : n_alpha = self . estimated_coefficients . size - self . K entropy_str = f \" The entropy has { n_alpha } parameters.\" else : entropy_str = \" The entropy is parameter-free.\" n_alpha = 0 model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += f \"The model has { self . X } x { self . Y } margins \\n { entropy_str } \\n \" model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += \"The estimated coefficients (and their standard errors) are \\n\\n \" if self . parameterized_entropy : for i , coeff in enumerate ( self . estimated_coefficients [: n_alpha ]): repr_str += ( f \" alpha( { i + 1 } ): { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ i ] : .3f } ) \\n \" ) repr_str += \" \\n \" for i , coeff in enumerate ( self . estimated_coefficients [ n_alpha :]): repr_str += ( f \" base { i + 1 } : { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ n_alpha + i ] : .3f } ) \\n \" ) repr_str += \" \\n Specification test: \\n \" repr_str += ( f \" the value of the test statistic is { self . test_statistic : > 10.3f } \\n \" ) repr_str += ( f \" for a chi2( { self . ndf } ), the p-value is { self . test_pvalue : > 10.3f } \\n \" ) return repr_str + line_stars def print_results ( self , true_coeffs : np . ndarray | None = None , n_alpha : int = 0 ) -> None | float : estimates = self . estimated_coefficients stderrs = self . stderrs_coefficients if true_coeffs is not None : repr_str = ( \"The true and estimated coefficients \" + \"(and their standard errors) are \\n\\n \" ) for i , coeff in enumerate ( estimates [: n_alpha ]): repr_str += f \" alpha( { i + 1 } ): { true_coeffs [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs [ i ] : > 10.3f } ) \\n \" repr_str += \" \\n \" for i , coeff in enumerate ( estimates [ n_alpha :]): j = n_alpha + i repr_str += ( f \" base { i + 1 } : { true_coeffs [ j ] : > 10.3f } \" + f \" { coeff : > 10.3f } ( { stderrs [ j ] : > 10.3f } ) \\n \" ) print_stars ( repr_str ) discrepancy = npmaxabs ( true_coeffs - estimates ) print_stars ( \"The largest difference between true and estimated coefficients is\" f \" { discrepancy : .2e } \" ) else : repr_str = ( \"The estimated coefficients \" + \"(and their standard errors) are \\n\\n \" ) for i , coeff in enumerate ( estimates [: n_alpha ]): repr_str + f \" { coeff : > 10.3f } ( { stderrs [ i ] : > 10.3f } ) \\n \" repr_str += \" \\n \" for i , coeff in enumerate ( estimates [ n_alpha :]): j = n_alpha + i repr_str += f \" { coeff : > 10.3f } ( { stderrs [ j ] : > 10.3f } ) \\n \" print_stars ( repr_str ) repr_str = \" \\n Specification test: \\n \" repr_str += ( \" the value of the test statistic is \" + f \" { self . test_statistic : > 10.3f } \\n \" ) repr_str += ( f \" for a chi2( { self . ndf } ), \" + f \"the p-value is { self . test_pvalue : > 10.3f } \\n \" ) print_stars ( repr_str ) if true_coeffs is not None : return cast ( float , discrepancy ) return None compute_estimates ( M , S_mat , d ) \u00b6 Returns the QGLS estimates and their variance-covariance. Parameters: Name Type Description Default M np . ndarray an (XY,p) matrix required S_mat np . ndarray an (XY, XY) weighting matrix required d np . ndarray an XY-vector required Returns: Type Description tuple [ np . ndarray , np . ndarray ] the p-vector of estimates and their estimated (p,p) variance Source code in cupid_matching/min_distance_utils.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def compute_estimates ( M : np . ndarray , S_mat : np . ndarray , d : np . ndarray ) -> tuple [ np . ndarray , np . ndarray ]: \"\"\"Returns the QGLS estimates and their variance-covariance. Args: M: an (XY,p) matrix S_mat: an (XY, XY) weighting matrix d: an XY-vector Returns: the p-vector of estimates and their estimated (p,p) variance \"\"\" M_T = M . T M_S_d = M_T @ S_mat @ d M_S_M = M_T @ S_mat @ M est_coeffs = - spla . solve ( M_S_M , M_S_d ) varcov_coeffs = spla . inv ( M_S_M ) return est_coeffs , varcov_coeffs","title":"Utilities for MDE"},{"location":"min_distance_utils/#min_distance_utils-module","text":"Utility programs used in min_distance.py .","title":"min_distance_utils module"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.MDEResults","text":"The results from minimum-distance estimation and testing. Parameters: Name Type Description Default X int the number of types of men required Y int the number of types of women required K int the number of bases required number_households int the number of households in the sample required estimated_coefficients np . ndarray the estimated coefficients required varcov_coefficients np . ndarray their eetimated var-covar required stderrs_coefficients np . ndarray their estimated stderrs required estimated_Phi np . ndarray the estimated joint surplus required test_statistic float the value of the misspecification statistic required test_pvalue float the p-value of the test required ndf int the number of degrees of freedom required parameterized_entropy bool | None True if the derivative of the entropy has unknown parameters False Source code in cupid_matching/min_distance_utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 @dataclass class MDEResults : \"\"\" The results from minimum-distance estimation and testing. Args: X: the number of types of men Y: the number of types of women K: the number of bases number_households: the number of households in the sample estimated_coefficients: the estimated coefficients varcov_coefficients: their eetimated var-covar stderrs_coefficients: their estimated stderrs estimated_Phi: the estimated joint surplus test_statistic: the value of the misspecification statistic test_pvalue: the p-value of the test ndf: the number of degrees of freedom parameterized_entropy: True if the derivative of the entropy has unknown parameters \"\"\" X : int Y : int K : int number_households : int estimated_coefficients : np . ndarray varcov_coefficients : np . ndarray stderrs_coefficients : np . ndarray estimated_Phi : np . ndarray test_statistic : float test_pvalue : float ndf : int parameterized_entropy : bool | None = False def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" if self . parameterized_entropy : n_alpha = self . estimated_coefficients . size - self . K entropy_str = f \" The entropy has { n_alpha } parameters.\" else : entropy_str = \" The entropy is parameter-free.\" n_alpha = 0 model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += f \"The model has { self . X } x { self . Y } margins \\n { entropy_str } \\n \" model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += \"The estimated coefficients (and their standard errors) are \\n\\n \" if self . parameterized_entropy : for i , coeff in enumerate ( self . estimated_coefficients [: n_alpha ]): repr_str += ( f \" alpha( { i + 1 } ): { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ i ] : .3f } ) \\n \" ) repr_str += \" \\n \" for i , coeff in enumerate ( self . estimated_coefficients [ n_alpha :]): repr_str += ( f \" base { i + 1 } : { coeff : > 10.3f } \" + f \"( { self . stderrs_coefficients [ n_alpha + i ] : .3f } ) \\n \" ) repr_str += \" \\n Specification test: \\n \" repr_str += ( f \" the value of the test statistic is { self . test_statistic : > 10.3f } \\n \" ) repr_str += ( f \" for a chi2( { self . ndf } ), the p-value is { self . test_pvalue : > 10.3f } \\n \" ) return repr_str + line_stars def print_results ( self , true_coeffs : np . ndarray | None = None , n_alpha : int = 0 ) -> None | float : estimates = self . estimated_coefficients stderrs = self . stderrs_coefficients if true_coeffs is not None : repr_str = ( \"The true and estimated coefficients \" + \"(and their standard errors) are \\n\\n \" ) for i , coeff in enumerate ( estimates [: n_alpha ]): repr_str += f \" alpha( { i + 1 } ): { true_coeffs [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs [ i ] : > 10.3f } ) \\n \" repr_str += \" \\n \" for i , coeff in enumerate ( estimates [ n_alpha :]): j = n_alpha + i repr_str += ( f \" base { i + 1 } : { true_coeffs [ j ] : > 10.3f } \" + f \" { coeff : > 10.3f } ( { stderrs [ j ] : > 10.3f } ) \\n \" ) print_stars ( repr_str ) discrepancy = npmaxabs ( true_coeffs - estimates ) print_stars ( \"The largest difference between true and estimated coefficients is\" f \" { discrepancy : .2e } \" ) else : repr_str = ( \"The estimated coefficients \" + \"(and their standard errors) are \\n\\n \" ) for i , coeff in enumerate ( estimates [: n_alpha ]): repr_str + f \" { coeff : > 10.3f } ( { stderrs [ i ] : > 10.3f } ) \\n \" repr_str += \" \\n \" for i , coeff in enumerate ( estimates [ n_alpha :]): j = n_alpha + i repr_str += f \" { coeff : > 10.3f } ( { stderrs [ j ] : > 10.3f } ) \\n \" print_stars ( repr_str ) repr_str = \" \\n Specification test: \\n \" repr_str += ( \" the value of the test statistic is \" + f \" { self . test_statistic : > 10.3f } \\n \" ) repr_str += ( f \" for a chi2( { self . ndf } ), \" + f \"the p-value is { self . test_pvalue : > 10.3f } \\n \" ) print_stars ( repr_str ) if true_coeffs is not None : return cast ( float , discrepancy ) return None","title":"MDEResults"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.compute_estimates","text":"Returns the QGLS estimates and their variance-covariance. Parameters: Name Type Description Default M np . ndarray an (XY,p) matrix required S_mat np . ndarray an (XY, XY) weighting matrix required d np . ndarray an XY-vector required Returns: Type Description tuple [ np . ndarray , np . ndarray ] the p-vector of estimates and their estimated (p,p) variance Source code in cupid_matching/min_distance_utils.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def compute_estimates ( M : np . ndarray , S_mat : np . ndarray , d : np . ndarray ) -> tuple [ np . ndarray , np . ndarray ]: \"\"\"Returns the QGLS estimates and their variance-covariance. Args: M: an (XY,p) matrix S_mat: an (XY, XY) weighting matrix d: an XY-vector Returns: the p-vector of estimates and their estimated (p,p) variance \"\"\" M_T = M . T M_S_d = M_T @ S_mat @ d M_S_M = M_T @ S_mat @ M est_coeffs = - spla . solve ( M_S_M , M_S_d ) varcov_coeffs = spla . inv ( M_S_M ) return est_coeffs , varcov_coeffs","title":"compute_estimates()"},{"location":"model_classes/","text":"model_classes module \u00b6 NestedLogitPrimitives dataclass \u00b6 Source code in cupid_matching/model_classes.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 @dataclass class NestedLogitPrimitives : Phi : np . ndarray n : np . ndarray m : np . ndarray nests_for_each_x : NestsList # given by user, e.g. [[1, 3], [2,4]] has y=1 and y=3 in first nest nests_for_each_y : NestsList nests_over_Y : NestsList # rebased to zero: the above example becomes [[0, 2], [1,3]] nests_over_X : NestsList i_nest_of_x : Nest # mapping x -> n' i_nest_of_y : Nest # mapping y -> n n_alphas : int mus : Matching | None = None true_alphas : np . ndarray | None = None def __init__ ( self , Phi : np . ndarray , n : np . ndarray , m : np . ndarray , nests_for_each_x : NestsList , nests_for_each_y : NestsList , true_alphas : np . ndarray | None = None , ): \"\"\" We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Args: Phi: the (X,Y) joint surplus matrix n: the X-vector of men margins m: the X-vector of women margins nests_for_each_x: the composition of the nests over 1...Y, a list of r lists nests_for_each_y: the composition of the nests over 1...X, a list of d lists true_alphas: the true nest parameters, if any; should be an (r+d)-vector \"\"\" X , Y = check_matrix ( Phi ) Xn = check_vector ( n ) Ym = check_vector ( m ) # we need to rebase the indices to zero self . nests_over_X = _change_indices ( nests_for_each_y ) self . nests_over_Y = _change_indices ( nests_for_each_x ) self . n_alphas = len ( nests_for_each_y ) + len ( nests_for_each_x ) if Xn != X : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) if true_alphas is not None : alpha_size = check_vector ( true_alphas ) if alpha_size != self . n_alphas : bs_error_abort ( f \"true_alphas shoud have { self . n_alphas } elements, not { alpha_size } \" ) self . Phi = Phi self . n = n self . m = m self . true_alphas = true_alphas self . nests_for_each_x = nests_for_each_x self . nests_for_each_y = nests_for_each_y # check that every x is in a nest, and just once nests_check = [] i_nest_of_x = np . zeros ( X , int ) for x in range ( X ): i_nest_of_x [ x ] = _find_nest_of ( self . nests_over_X , x ) nests_check . append ( i_nest_of_x [ x ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_y ): bs_error_abort ( \"Check your nests_for_each_y\" ) # check that every y is in a nest, and just once nests_check = [] i_nest_of_y = np . zeros ( Y , int ) for y in range ( Y ): i_nest_of_y [ y ] = _find_nest_of ( self . nests_over_Y , y ) nests_check . append ( i_nest_of_y [ y ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_x ): bs_error_abort ( \"Check your nests_for_each_x\" ) self . i_nest_of_x = i_nest_of_x . tolist () self . i_nest_of_y = i_nest_of_y . tolist () def __str__ ( self ): X , Y = self . Phi . shape nmen , nwomen = np . sum ( self . n ), np . sum ( self . m ) repr_str = ( f \"This is a 2-level nested logit with { nmen } men of { X } types\" + f \" and { nwomen } women of { Y } types. \\n \" ) repr_str += ( f \" We have { self . n_nests_over_Y } nests over 1...Y \" + f \" and { self . n_nests_over_X } nests over 1...X, \\n \" ) if self . true_alphas is None : repr_str += \" with unspecified nests parameters.\" else : alpha_vals = self . true_alphas repr_str += \" with respective nests parameters: \\n \" repr_str += f \" { alpha_vals [: self . n_nests_over_Y ] } \\n \" repr_str += f \" and { alpha_vals [ self . n_nests_over_Y :] } \\n \" print_stars ( repr_str ) def ipfp_nested_logit_solver ( self , tol : float = 1e-9 , verbose : bool = False , maxiter : int = 1000 ) -> tuple [ Matching , np . ndarray , np . ndarray ]: \"\"\"Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute_ the gradient of the matching patterns Args: tol: tolerance on change in solution verbose: if `True`, prints information maxiter: maximum number of iterations Returns: the matching patterns marg_err_x, marg_err_y: the errors on the margins \"\"\" alphas = self . true_alphas if alphas is None : bs_error_abort ( \"cannot solve without nest parameters\" ) else : alphas = cast ( np . ndarray , alphas ) n_rhos = len ( self . nests_over_Y ) n_deltas = len ( self . nests_over_X ) rhos = alphas [: n_rhos ] deltas = alphas [ n_rhos :] ############################################################################# # we solve the equilibrium equations # starting with a reasonable initial point muxy, mux0, mu0y = bigc # it is important that it fit the number of individuals ############################################################################# n , m = self . n , self . m X , Y = n . size , m . size nests_over_X , nests_over_Y = self . nests_over_X , self . nests_over_Y i_nest_of_x , i_nest_of_y = self . i_nest_of_x , self . i_nest_of_y rho_vals = rhos [ i_nest_of_y ] # rho(n) for y in n in the paper delta_vals = deltas [ i_nest_of_x ] # delta(n') for x in n' in the paper ephi = npexp ( self . Phi / np . add . outer ( delta_vals , rho_vals )) # initial values nindivs = np . sum ( n ) + np . sum ( m ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi )) mux0 , mu0y , muxy = ( np . full ( X , bigc ), np . full ( Y , bigc ), np . full (( X , Y ), bigc ), ) muxn = np . zeros (( X , n_rhos )) for i_nest_y , nest_y in enumerate ( nests_over_Y ): muxn [:, i_nest_y ] = np . sum ( muxy [:, nest_y ], 1 ) muny = np . zeros (( n_deltas , Y )) for i_nest_x , nest_x in enumerate ( nests_over_X ): muny [ i_nest_x , :] = np . sum ( muxy [ nest_x , :], 0 ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol max_newton = 2000 MIN_REST = 1e-4 * bigc # used to bound mus below in the Newton iterations niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros ( ( X , n_rhos ) ) # this will be the $\\bar{G}^x_n$ of the note gbar_pow = np . zeros (( X , n_rhos )) biga = np . zeros ( X ) # this will be the $A_x$ of the note for i_nest_x , nest_x in enumerate ( nests_over_X ): # i_nest_x is n' in the paper delta_x = deltas [ i_nest_x ] muny_x = muny [ i_nest_x , :] # mu(n', :) for x in nest_x : ephi_x = ephi [ x , :] for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper mu_n = muny_x [ nest_y ] mu0_n = mu0y [ nest_y ] evec_n = ephi_x [ nest_y ] rho_n = rhos [ i_nest_y ] sum_rd = rho_n + delta_x mun_term = nppow ( mu_n , ( delta_x - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ x , i_nest_y ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ x , i_nest_y ] = nppow ( gbar [ x , i_nest_y ], sum_rd / ( delta_x + 1.0 ) ) biga [ x ] += gbar_pow [ x , i_nest_y ] # now we take one Newton step for all types of men delta_vals1 = 1.0 + delta_vals mux0_term = nppow ( mux0 , 1.0 / delta_vals1 ) bigb = mux0_term * biga # this is the $B_x$ of the note numer = n * delta_vals1 - delta_vals * bigb lower_bound = np . full ( X , MIN_REST ) mux0_new = mux0 * np . maximum ( numer / ( delta_vals1 * mux0 + bigb ), lower_bound ) muxn_new = gbar_pow * mux0_term . reshape (( - 1 , 1 )) mux0 = mux0_new muxn = muxn_new errxi = mux0 + np . sum ( muxn , 1 ) - n err_newton = npmaxabs ( errxi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for men after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on men is { err_newton } after { i_newton } iterations\" ) # Newton iterates for women err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros (( Y , n_deltas )) gbar_pow = np . zeros (( Y , n_deltas )) biga = np . zeros ( Y ) for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper rho_y = rhos [ i_nest_y ] muxn_y = muxn [:, i_nest_y ] # mu(:, n) for y in nest_y : ephi_y = ephi [:, y ] for i_nest_x , nest_x in enumerate ( nests_over_X ): mu_n = muxn_y [ nest_x ] mu0_n = mux0 [ nest_x ] evec_n = ephi_y [ nest_x ] delta_n = deltas [ i_nest_x ] sum_rd = rho_y + delta_n mun_term = nppow ( mu_n , ( rho_n - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ y , i_nest_x ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ y , i_nest_x ] = nppow ( gbar [ y , i_nest_x ], sum_rd / ( 1.0 + rho_y ) ) biga [ y ] += gbar_pow [ y , i_nest_x ] # now we take one Newton step for all types of women rho_vals1 = 1.0 + rho_vals mu0y_term = nppow ( mu0y , 1.0 / rho_vals1 ) bigb = mu0y_term * biga numer = m * rho_vals1 - rho_vals * bigb lower_bound = np . full ( Y , MIN_REST ) mu0y_new = mu0y * np . maximum ( numer / ( rho_vals1 * mu0y + bigb ), lower_bound ) muny_new = gbar_pow . T * mu0y_term mu0y = mu0y_new muny = muny_new erryi = mu0y + np . sum ( muny , 0 ) - m err_newton = npmaxabs ( erryi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for women after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on women is { err_newton } after { i_newton } iterations\" ) muxy = np . zeros (( X , Y )) for x in range ( X ): i_nest_x = i_nest_of_x [ x ] # n' ephi_x = ephi [ x , :] mux0_x = mux0 [ x ] muxn_x = muxn [ x , :] delta_x = delta_vals [ x ] muny_x = muny [ i_nest_x , :] for y in range ( Y ): i_nest_y = i_nest_of_y [ y ] # n mu0y_y = mu0y [ y ] rho_y = rho_vals [ y ] muxn_xy = muxn_x [ i_nest_y ] muny_xy = muny_x [ y ] mu_term = ( mux0_x * mu0y_y * ( muxn_xy ** ( rho_y - 1.0 )) * ( muny_xy ** ( delta_x - 1.0 )) ) muxy [ x , y ] = ephi_x [ y ] * ( mu_term ** ( 1.0 / ( delta_x + rho_y ))) n_sim , m_sim = compute_margins ( muxy , mux0 , mu0y ) marg_err_x , marg_err_y = n_sim - n , m_sim - m if verbose : print ( f \"Margin error on men is { marg_err_x } \" f \" after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { marg_err_y } \" f \" after { niter } IPFP iterations\" ) err_diff = npmaxabs ( marg_err_x ) + npmaxabs ( marg_err_y ) niter += 1 n_sim , m_sim = compute_margins ( muxy , mux0 , mu0y ) marg_err_x = n_sim - n marg_err_y = m_sim - m if verbose : print ( f \"Margin error on men is { npmaxabs ( marg_err_x ) } after { niter } IPFP\" \" iterations\" ) print ( f \"Margin error on women is { npmaxabs ( marg_err_y ) } after { niter } IPFP\" \" iterations\" ) return Matching ( muxy , n , m ), marg_err_x , marg_err_y def ipfp_solve ( self ) -> Matching : if self . true_alphas is None : bs_error_abort ( \"true_alphas must be specified to solve the nested logit by IPFP.\" ) self . mus , err_x , err_y = self . ipfp_nested_logit_solver ( verbose = False ) return self . mus def simulate ( self , n_households : int , seed : int | None = None ) -> Matching : self . mus = self . ipfp_solve () mus_sim = _simulate_sample_from_mus ( self . mus , n_households , seed ) return mus_sim __init__ ( Phi , n , m , nests_for_each_x , nests_for_each_y , true_alphas = None ) \u00b6 We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Parameters: Name Type Description Default Phi np . ndarray the (X,Y) joint surplus matrix required n np . ndarray the X-vector of men margins required m np . ndarray the X-vector of women margins required nests_for_each_x NestsList the composition of the nests over 1...Y, a list of r lists required nests_for_each_y NestsList the composition of the nests over 1...X, a list of d lists required true_alphas np . ndarray | None the true nest parameters, if any; should be an (r+d)-vector None Source code in cupid_matching/model_classes.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def __init__ ( self , Phi : np . ndarray , n : np . ndarray , m : np . ndarray , nests_for_each_x : NestsList , nests_for_each_y : NestsList , true_alphas : np . ndarray | None = None , ): \"\"\" We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Args: Phi: the (X,Y) joint surplus matrix n: the X-vector of men margins m: the X-vector of women margins nests_for_each_x: the composition of the nests over 1...Y, a list of r lists nests_for_each_y: the composition of the nests over 1...X, a list of d lists true_alphas: the true nest parameters, if any; should be an (r+d)-vector \"\"\" X , Y = check_matrix ( Phi ) Xn = check_vector ( n ) Ym = check_vector ( m ) # we need to rebase the indices to zero self . nests_over_X = _change_indices ( nests_for_each_y ) self . nests_over_Y = _change_indices ( nests_for_each_x ) self . n_alphas = len ( nests_for_each_y ) + len ( nests_for_each_x ) if Xn != X : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) if true_alphas is not None : alpha_size = check_vector ( true_alphas ) if alpha_size != self . n_alphas : bs_error_abort ( f \"true_alphas shoud have { self . n_alphas } elements, not { alpha_size } \" ) self . Phi = Phi self . n = n self . m = m self . true_alphas = true_alphas self . nests_for_each_x = nests_for_each_x self . nests_for_each_y = nests_for_each_y # check that every x is in a nest, and just once nests_check = [] i_nest_of_x = np . zeros ( X , int ) for x in range ( X ): i_nest_of_x [ x ] = _find_nest_of ( self . nests_over_X , x ) nests_check . append ( i_nest_of_x [ x ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_y ): bs_error_abort ( \"Check your nests_for_each_y\" ) # check that every y is in a nest, and just once nests_check = [] i_nest_of_y = np . zeros ( Y , int ) for y in range ( Y ): i_nest_of_y [ y ] = _find_nest_of ( self . nests_over_Y , y ) nests_check . append ( i_nest_of_y [ y ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_x ): bs_error_abort ( \"Check your nests_for_each_x\" ) self . i_nest_of_x = i_nest_of_x . tolist () self . i_nest_of_y = i_nest_of_y . tolist () ipfp_nested_logit_solver ( tol = 1e-09 , verbose = False , maxiter = 1000 ) \u00b6 Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute_ the gradient of the matching patterns Parameters: Name Type Description Default tol float tolerance on change in solution 1e-09 verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description Matching the matching patterns np . ndarray marg_err_x, marg_err_y: the errors on the margins Source code in cupid_matching/model_classes.py 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 def ipfp_nested_logit_solver ( self , tol : float = 1e-9 , verbose : bool = False , maxiter : int = 1000 ) -> tuple [ Matching , np . ndarray , np . ndarray ]: \"\"\"Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute_ the gradient of the matching patterns Args: tol: tolerance on change in solution verbose: if `True`, prints information maxiter: maximum number of iterations Returns: the matching patterns marg_err_x, marg_err_y: the errors on the margins \"\"\" alphas = self . true_alphas if alphas is None : bs_error_abort ( \"cannot solve without nest parameters\" ) else : alphas = cast ( np . ndarray , alphas ) n_rhos = len ( self . nests_over_Y ) n_deltas = len ( self . nests_over_X ) rhos = alphas [: n_rhos ] deltas = alphas [ n_rhos :] ############################################################################# # we solve the equilibrium equations # starting with a reasonable initial point muxy, mux0, mu0y = bigc # it is important that it fit the number of individuals ############################################################################# n , m = self . n , self . m X , Y = n . size , m . size nests_over_X , nests_over_Y = self . nests_over_X , self . nests_over_Y i_nest_of_x , i_nest_of_y = self . i_nest_of_x , self . i_nest_of_y rho_vals = rhos [ i_nest_of_y ] # rho(n) for y in n in the paper delta_vals = deltas [ i_nest_of_x ] # delta(n') for x in n' in the paper ephi = npexp ( self . Phi / np . add . outer ( delta_vals , rho_vals )) # initial values nindivs = np . sum ( n ) + np . sum ( m ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi )) mux0 , mu0y , muxy = ( np . full ( X , bigc ), np . full ( Y , bigc ), np . full (( X , Y ), bigc ), ) muxn = np . zeros (( X , n_rhos )) for i_nest_y , nest_y in enumerate ( nests_over_Y ): muxn [:, i_nest_y ] = np . sum ( muxy [:, nest_y ], 1 ) muny = np . zeros (( n_deltas , Y )) for i_nest_x , nest_x in enumerate ( nests_over_X ): muny [ i_nest_x , :] = np . sum ( muxy [ nest_x , :], 0 ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol max_newton = 2000 MIN_REST = 1e-4 * bigc # used to bound mus below in the Newton iterations niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros ( ( X , n_rhos ) ) # this will be the $\\bar{G}^x_n$ of the note gbar_pow = np . zeros (( X , n_rhos )) biga = np . zeros ( X ) # this will be the $A_x$ of the note for i_nest_x , nest_x in enumerate ( nests_over_X ): # i_nest_x is n' in the paper delta_x = deltas [ i_nest_x ] muny_x = muny [ i_nest_x , :] # mu(n', :) for x in nest_x : ephi_x = ephi [ x , :] for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper mu_n = muny_x [ nest_y ] mu0_n = mu0y [ nest_y ] evec_n = ephi_x [ nest_y ] rho_n = rhos [ i_nest_y ] sum_rd = rho_n + delta_x mun_term = nppow ( mu_n , ( delta_x - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ x , i_nest_y ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ x , i_nest_y ] = nppow ( gbar [ x , i_nest_y ], sum_rd / ( delta_x + 1.0 ) ) biga [ x ] += gbar_pow [ x , i_nest_y ] # now we take one Newton step for all types of men delta_vals1 = 1.0 + delta_vals mux0_term = nppow ( mux0 , 1.0 / delta_vals1 ) bigb = mux0_term * biga # this is the $B_x$ of the note numer = n * delta_vals1 - delta_vals * bigb lower_bound = np . full ( X , MIN_REST ) mux0_new = mux0 * np . maximum ( numer / ( delta_vals1 * mux0 + bigb ), lower_bound ) muxn_new = gbar_pow * mux0_term . reshape (( - 1 , 1 )) mux0 = mux0_new muxn = muxn_new errxi = mux0 + np . sum ( muxn , 1 ) - n err_newton = npmaxabs ( errxi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for men after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on men is { err_newton } after { i_newton } iterations\" ) # Newton iterates for women err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros (( Y , n_deltas )) gbar_pow = np . zeros (( Y , n_deltas )) biga = np . zeros ( Y ) for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper rho_y = rhos [ i_nest_y ] muxn_y = muxn [:, i_nest_y ] # mu(:, n) for y in nest_y : ephi_y = ephi [:, y ] for i_nest_x , nest_x in enumerate ( nests_over_X ): mu_n = muxn_y [ nest_x ] mu0_n = mux0 [ nest_x ] evec_n = ephi_y [ nest_x ] delta_n = deltas [ i_nest_x ] sum_rd = rho_y + delta_n mun_term = nppow ( mu_n , ( rho_n - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ y , i_nest_x ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ y , i_nest_x ] = nppow ( gbar [ y , i_nest_x ], sum_rd / ( 1.0 + rho_y ) ) biga [ y ] += gbar_pow [ y , i_nest_x ] # now we take one Newton step for all types of women rho_vals1 = 1.0 + rho_vals mu0y_term = nppow ( mu0y , 1.0 / rho_vals1 ) bigb = mu0y_term * biga numer = m * rho_vals1 - rho_vals * bigb lower_bound = np . full ( Y , MIN_REST ) mu0y_new = mu0y * np . maximum ( numer / ( rho_vals1 * mu0y + bigb ), lower_bound ) muny_new = gbar_pow . T * mu0y_term mu0y = mu0y_new muny = muny_new erryi = mu0y + np . sum ( muny , 0 ) - m err_newton = npmaxabs ( erryi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for women after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on women is { err_newton } after { i_newton } iterations\" ) muxy = np . zeros (( X , Y )) for x in range ( X ): i_nest_x = i_nest_of_x [ x ] # n' ephi_x = ephi [ x , :] mux0_x = mux0 [ x ] muxn_x = muxn [ x , :] delta_x = delta_vals [ x ] muny_x = muny [ i_nest_x , :] for y in range ( Y ): i_nest_y = i_nest_of_y [ y ] # n mu0y_y = mu0y [ y ] rho_y = rho_vals [ y ] muxn_xy = muxn_x [ i_nest_y ] muny_xy = muny_x [ y ] mu_term = ( mux0_x * mu0y_y * ( muxn_xy ** ( rho_y - 1.0 )) * ( muny_xy ** ( delta_x - 1.0 )) ) muxy [ x , y ] = ephi_x [ y ] * ( mu_term ** ( 1.0 / ( delta_x + rho_y ))) n_sim , m_sim = compute_margins ( muxy , mux0 , mu0y ) marg_err_x , marg_err_y = n_sim - n , m_sim - m if verbose : print ( f \"Margin error on men is { marg_err_x } \" f \" after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { marg_err_y } \" f \" after { niter } IPFP iterations\" ) err_diff = npmaxabs ( marg_err_x ) + npmaxabs ( marg_err_y ) niter += 1 n_sim , m_sim = compute_margins ( muxy , mux0 , mu0y ) marg_err_x = n_sim - n marg_err_y = m_sim - m if verbose : print ( f \"Margin error on men is { npmaxabs ( marg_err_x ) } after { niter } IPFP\" \" iterations\" ) print ( f \"Margin error on women is { npmaxabs ( marg_err_y ) } after { niter } IPFP\" \" iterations\" ) return Matching ( muxy , n , m ), marg_err_x , marg_err_y","title":"Classes used"},{"location":"model_classes/#model_classes-module","text":"","title":"model_classes module"},{"location":"model_classes/#cupid_matching.model_classes.NestedLogitPrimitives","text":"Source code in cupid_matching/model_classes.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 @dataclass class NestedLogitPrimitives : Phi : np . ndarray n : np . ndarray m : np . ndarray nests_for_each_x : NestsList # given by user, e.g. [[1, 3], [2,4]] has y=1 and y=3 in first nest nests_for_each_y : NestsList nests_over_Y : NestsList # rebased to zero: the above example becomes [[0, 2], [1,3]] nests_over_X : NestsList i_nest_of_x : Nest # mapping x -> n' i_nest_of_y : Nest # mapping y -> n n_alphas : int mus : Matching | None = None true_alphas : np . ndarray | None = None def __init__ ( self , Phi : np . ndarray , n : np . ndarray , m : np . ndarray , nests_for_each_x : NestsList , nests_for_each_y : NestsList , true_alphas : np . ndarray | None = None , ): \"\"\" We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Args: Phi: the (X,Y) joint surplus matrix n: the X-vector of men margins m: the X-vector of women margins nests_for_each_x: the composition of the nests over 1...Y, a list of r lists nests_for_each_y: the composition of the nests over 1...X, a list of d lists true_alphas: the true nest parameters, if any; should be an (r+d)-vector \"\"\" X , Y = check_matrix ( Phi ) Xn = check_vector ( n ) Ym = check_vector ( m ) # we need to rebase the indices to zero self . nests_over_X = _change_indices ( nests_for_each_y ) self . nests_over_Y = _change_indices ( nests_for_each_x ) self . n_alphas = len ( nests_for_each_y ) + len ( nests_for_each_x ) if Xn != X : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) if true_alphas is not None : alpha_size = check_vector ( true_alphas ) if alpha_size != self . n_alphas : bs_error_abort ( f \"true_alphas shoud have { self . n_alphas } elements, not { alpha_size } \" ) self . Phi = Phi self . n = n self . m = m self . true_alphas = true_alphas self . nests_for_each_x = nests_for_each_x self . nests_for_each_y = nests_for_each_y # check that every x is in a nest, and just once nests_check = [] i_nest_of_x = np . zeros ( X , int ) for x in range ( X ): i_nest_of_x [ x ] = _find_nest_of ( self . nests_over_X , x ) nests_check . append ( i_nest_of_x [ x ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_y ): bs_error_abort ( \"Check your nests_for_each_y\" ) # check that every y is in a nest, and just once nests_check = [] i_nest_of_y = np . zeros ( Y , int ) for y in range ( Y ): i_nest_of_y [ y ] = _find_nest_of ( self . nests_over_Y , y ) nests_check . append ( i_nest_of_y [ y ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_x ): bs_error_abort ( \"Check your nests_for_each_x\" ) self . i_nest_of_x = i_nest_of_x . tolist () self . i_nest_of_y = i_nest_of_y . tolist () def __str__ ( self ): X , Y = self . Phi . shape nmen , nwomen = np . sum ( self . n ), np . sum ( self . m ) repr_str = ( f \"This is a 2-level nested logit with { nmen } men of { X } types\" + f \" and { nwomen } women of { Y } types. \\n \" ) repr_str += ( f \" We have { self . n_nests_over_Y } nests over 1...Y \" + f \" and { self . n_nests_over_X } nests over 1...X, \\n \" ) if self . true_alphas is None : repr_str += \" with unspecified nests parameters.\" else : alpha_vals = self . true_alphas repr_str += \" with respective nests parameters: \\n \" repr_str += f \" { alpha_vals [: self . n_nests_over_Y ] } \\n \" repr_str += f \" and { alpha_vals [ self . n_nests_over_Y :] } \\n \" print_stars ( repr_str ) def ipfp_nested_logit_solver ( self , tol : float = 1e-9 , verbose : bool = False , maxiter : int = 1000 ) -> tuple [ Matching , np . ndarray , np . ndarray ]: \"\"\"Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute_ the gradient of the matching patterns Args: tol: tolerance on change in solution verbose: if `True`, prints information maxiter: maximum number of iterations Returns: the matching patterns marg_err_x, marg_err_y: the errors on the margins \"\"\" alphas = self . true_alphas if alphas is None : bs_error_abort ( \"cannot solve without nest parameters\" ) else : alphas = cast ( np . ndarray , alphas ) n_rhos = len ( self . nests_over_Y ) n_deltas = len ( self . nests_over_X ) rhos = alphas [: n_rhos ] deltas = alphas [ n_rhos :] ############################################################################# # we solve the equilibrium equations # starting with a reasonable initial point muxy, mux0, mu0y = bigc # it is important that it fit the number of individuals ############################################################################# n , m = self . n , self . m X , Y = n . size , m . size nests_over_X , nests_over_Y = self . nests_over_X , self . nests_over_Y i_nest_of_x , i_nest_of_y = self . i_nest_of_x , self . i_nest_of_y rho_vals = rhos [ i_nest_of_y ] # rho(n) for y in n in the paper delta_vals = deltas [ i_nest_of_x ] # delta(n') for x in n' in the paper ephi = npexp ( self . Phi / np . add . outer ( delta_vals , rho_vals )) # initial values nindivs = np . sum ( n ) + np . sum ( m ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi )) mux0 , mu0y , muxy = ( np . full ( X , bigc ), np . full ( Y , bigc ), np . full (( X , Y ), bigc ), ) muxn = np . zeros (( X , n_rhos )) for i_nest_y , nest_y in enumerate ( nests_over_Y ): muxn [:, i_nest_y ] = np . sum ( muxy [:, nest_y ], 1 ) muny = np . zeros (( n_deltas , Y )) for i_nest_x , nest_x in enumerate ( nests_over_X ): muny [ i_nest_x , :] = np . sum ( muxy [ nest_x , :], 0 ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol max_newton = 2000 MIN_REST = 1e-4 * bigc # used to bound mus below in the Newton iterations niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros ( ( X , n_rhos ) ) # this will be the $\\bar{G}^x_n$ of the note gbar_pow = np . zeros (( X , n_rhos )) biga = np . zeros ( X ) # this will be the $A_x$ of the note for i_nest_x , nest_x in enumerate ( nests_over_X ): # i_nest_x is n' in the paper delta_x = deltas [ i_nest_x ] muny_x = muny [ i_nest_x , :] # mu(n', :) for x in nest_x : ephi_x = ephi [ x , :] for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper mu_n = muny_x [ nest_y ] mu0_n = mu0y [ nest_y ] evec_n = ephi_x [ nest_y ] rho_n = rhos [ i_nest_y ] sum_rd = rho_n + delta_x mun_term = nppow ( mu_n , ( delta_x - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ x , i_nest_y ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ x , i_nest_y ] = nppow ( gbar [ x , i_nest_y ], sum_rd / ( delta_x + 1.0 ) ) biga [ x ] += gbar_pow [ x , i_nest_y ] # now we take one Newton step for all types of men delta_vals1 = 1.0 + delta_vals mux0_term = nppow ( mux0 , 1.0 / delta_vals1 ) bigb = mux0_term * biga # this is the $B_x$ of the note numer = n * delta_vals1 - delta_vals * bigb lower_bound = np . full ( X , MIN_REST ) mux0_new = mux0 * np . maximum ( numer / ( delta_vals1 * mux0 + bigb ), lower_bound ) muxn_new = gbar_pow * mux0_term . reshape (( - 1 , 1 )) mux0 = mux0_new muxn = muxn_new errxi = mux0 + np . sum ( muxn , 1 ) - n err_newton = npmaxabs ( errxi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for men after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on men is { err_newton } after { i_newton } iterations\" ) # Newton iterates for women err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros (( Y , n_deltas )) gbar_pow = np . zeros (( Y , n_deltas )) biga = np . zeros ( Y ) for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper rho_y = rhos [ i_nest_y ] muxn_y = muxn [:, i_nest_y ] # mu(:, n) for y in nest_y : ephi_y = ephi [:, y ] for i_nest_x , nest_x in enumerate ( nests_over_X ): mu_n = muxn_y [ nest_x ] mu0_n = mux0 [ nest_x ] evec_n = ephi_y [ nest_x ] delta_n = deltas [ i_nest_x ] sum_rd = rho_y + delta_n mun_term = nppow ( mu_n , ( rho_n - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ y , i_nest_x ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ y , i_nest_x ] = nppow ( gbar [ y , i_nest_x ], sum_rd / ( 1.0 + rho_y ) ) biga [ y ] += gbar_pow [ y , i_nest_x ] # now we take one Newton step for all types of women rho_vals1 = 1.0 + rho_vals mu0y_term = nppow ( mu0y , 1.0 / rho_vals1 ) bigb = mu0y_term * biga numer = m * rho_vals1 - rho_vals * bigb lower_bound = np . full ( Y , MIN_REST ) mu0y_new = mu0y * np . maximum ( numer / ( rho_vals1 * mu0y + bigb ), lower_bound ) muny_new = gbar_pow . T * mu0y_term mu0y = mu0y_new muny = muny_new erryi = mu0y + np . sum ( muny , 0 ) - m err_newton = npmaxabs ( erryi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for women after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on women is { err_newton } after { i_newton } iterations\" ) muxy = np . zeros (( X , Y )) for x in range ( X ): i_nest_x = i_nest_of_x [ x ] # n' ephi_x = ephi [ x , :] mux0_x = mux0 [ x ] muxn_x = muxn [ x , :] delta_x = delta_vals [ x ] muny_x = muny [ i_nest_x , :] for y in range ( Y ): i_nest_y = i_nest_of_y [ y ] # n mu0y_y = mu0y [ y ] rho_y = rho_vals [ y ] muxn_xy = muxn_x [ i_nest_y ] muny_xy = muny_x [ y ] mu_term = ( mux0_x * mu0y_y * ( muxn_xy ** ( rho_y - 1.0 )) * ( muny_xy ** ( delta_x - 1.0 )) ) muxy [ x , y ] = ephi_x [ y ] * ( mu_term ** ( 1.0 / ( delta_x + rho_y ))) n_sim , m_sim = compute_margins ( muxy , mux0 , mu0y ) marg_err_x , marg_err_y = n_sim - n , m_sim - m if verbose : print ( f \"Margin error on men is { marg_err_x } \" f \" after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { marg_err_y } \" f \" after { niter } IPFP iterations\" ) err_diff = npmaxabs ( marg_err_x ) + npmaxabs ( marg_err_y ) niter += 1 n_sim , m_sim = compute_margins ( muxy , mux0 , mu0y ) marg_err_x = n_sim - n marg_err_y = m_sim - m if verbose : print ( f \"Margin error on men is { npmaxabs ( marg_err_x ) } after { niter } IPFP\" \" iterations\" ) print ( f \"Margin error on women is { npmaxabs ( marg_err_y ) } after { niter } IPFP\" \" iterations\" ) return Matching ( muxy , n , m ), marg_err_x , marg_err_y def ipfp_solve ( self ) -> Matching : if self . true_alphas is None : bs_error_abort ( \"true_alphas must be specified to solve the nested logit by IPFP.\" ) self . mus , err_x , err_y = self . ipfp_nested_logit_solver ( verbose = False ) return self . mus def simulate ( self , n_households : int , seed : int | None = None ) -> Matching : self . mus = self . ipfp_solve () mus_sim = _simulate_sample_from_mus ( self . mus , n_households , seed ) return mus_sim","title":"NestedLogitPrimitives"},{"location":"model_classes/#cupid_matching.model_classes.NestedLogitPrimitives.__init__","text":"We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Parameters: Name Type Description Default Phi np . ndarray the (X,Y) joint surplus matrix required n np . ndarray the X-vector of men margins required m np . ndarray the X-vector of women margins required nests_for_each_x NestsList the composition of the nests over 1...Y, a list of r lists required nests_for_each_y NestsList the composition of the nests over 1...X, a list of d lists required true_alphas np . ndarray | None the true nest parameters, if any; should be an (r+d)-vector None Source code in cupid_matching/model_classes.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def __init__ ( self , Phi : np . ndarray , n : np . ndarray , m : np . ndarray , nests_for_each_x : NestsList , nests_for_each_y : NestsList , true_alphas : np . ndarray | None = None , ): \"\"\" We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type. Args: Phi: the (X,Y) joint surplus matrix n: the X-vector of men margins m: the X-vector of women margins nests_for_each_x: the composition of the nests over 1...Y, a list of r lists nests_for_each_y: the composition of the nests over 1...X, a list of d lists true_alphas: the true nest parameters, if any; should be an (r+d)-vector \"\"\" X , Y = check_matrix ( Phi ) Xn = check_vector ( n ) Ym = check_vector ( m ) # we need to rebase the indices to zero self . nests_over_X = _change_indices ( nests_for_each_y ) self . nests_over_Y = _change_indices ( nests_for_each_x ) self . n_alphas = len ( nests_for_each_y ) + len ( nests_for_each_x ) if Xn != X : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but n has { Xn } elements.\" ) if Ym != Y : bs_error_abort ( f \"Phi is a ( { X } , { Y } ) matrix but m has { Ym } elements.\" ) if true_alphas is not None : alpha_size = check_vector ( true_alphas ) if alpha_size != self . n_alphas : bs_error_abort ( f \"true_alphas shoud have { self . n_alphas } elements, not { alpha_size } \" ) self . Phi = Phi self . n = n self . m = m self . true_alphas = true_alphas self . nests_for_each_x = nests_for_each_x self . nests_for_each_y = nests_for_each_y # check that every x is in a nest, and just once nests_check = [] i_nest_of_x = np . zeros ( X , int ) for x in range ( X ): i_nest_of_x [ x ] = _find_nest_of ( self . nests_over_X , x ) nests_check . append ( i_nest_of_x [ x ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_y ): bs_error_abort ( \"Check your nests_for_each_y\" ) # check that every y is in a nest, and just once nests_check = [] i_nest_of_y = np . zeros ( Y , int ) for y in range ( Y ): i_nest_of_y [ y ] = _find_nest_of ( self . nests_over_Y , y ) nests_check . append ( i_nest_of_y [ y ]) if - 1 in nests_check or len ( set ( nests_check )) != len ( nests_for_each_x ): bs_error_abort ( \"Check your nests_for_each_x\" ) self . i_nest_of_x = i_nest_of_x . tolist () self . i_nest_of_y = i_nest_of_y . tolist ()","title":"__init__()"},{"location":"model_classes/#cupid_matching.model_classes.NestedLogitPrimitives.ipfp_nested_logit_solver","text":"Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute_ the gradient of the matching patterns Parameters: Name Type Description Default tol float tolerance on change in solution 1e-09 verbose bool if True , prints information False maxiter int maximum number of iterations 1000 Returns: Type Description Matching the matching patterns np . ndarray marg_err_x, marg_err_y: the errors on the margins Source code in cupid_matching/model_classes.py 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 def ipfp_nested_logit_solver ( self , tol : float = 1e-9 , verbose : bool = False , maxiter : int = 1000 ) -> tuple [ Matching , np . ndarray , np . ndarray ]: \"\"\"Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute_ the gradient of the matching patterns Args: tol: tolerance on change in solution verbose: if `True`, prints information maxiter: maximum number of iterations Returns: the matching patterns marg_err_x, marg_err_y: the errors on the margins \"\"\" alphas = self . true_alphas if alphas is None : bs_error_abort ( \"cannot solve without nest parameters\" ) else : alphas = cast ( np . ndarray , alphas ) n_rhos = len ( self . nests_over_Y ) n_deltas = len ( self . nests_over_X ) rhos = alphas [: n_rhos ] deltas = alphas [ n_rhos :] ############################################################################# # we solve the equilibrium equations # starting with a reasonable initial point muxy, mux0, mu0y = bigc # it is important that it fit the number of individuals ############################################################################# n , m = self . n , self . m X , Y = n . size , m . size nests_over_X , nests_over_Y = self . nests_over_X , self . nests_over_Y i_nest_of_x , i_nest_of_y = self . i_nest_of_x , self . i_nest_of_y rho_vals = rhos [ i_nest_of_y ] # rho(n) for y in n in the paper delta_vals = deltas [ i_nest_of_x ] # delta(n') for x in n' in the paper ephi = npexp ( self . Phi / np . add . outer ( delta_vals , rho_vals )) # initial values nindivs = np . sum ( n ) + np . sum ( m ) bigc = nindivs / ( X + Y + 2.0 * np . sum ( ephi )) mux0 , mu0y , muxy = ( np . full ( X , bigc ), np . full ( Y , bigc ), np . full (( X , Y ), bigc ), ) muxn = np . zeros (( X , n_rhos )) for i_nest_y , nest_y in enumerate ( nests_over_Y ): muxn [:, i_nest_y ] = np . sum ( muxy [:, nest_y ], 1 ) muny = np . zeros (( n_deltas , Y )) for i_nest_x , nest_x in enumerate ( nests_over_X ): muny [ i_nest_x , :] = np . sum ( muxy [ nest_x , :], 0 ) err_diff = bigc tol_diff = tol * bigc tol_newton = tol max_newton = 2000 MIN_REST = 1e-4 * bigc # used to bound mus below in the Newton iterations niter = 0 while ( err_diff > tol_diff ) and ( niter < maxiter ): # IPFP main loop # Newton iterates for men err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros ( ( X , n_rhos ) ) # this will be the $\\bar{G}^x_n$ of the note gbar_pow = np . zeros (( X , n_rhos )) biga = np . zeros ( X ) # this will be the $A_x$ of the note for i_nest_x , nest_x in enumerate ( nests_over_X ): # i_nest_x is n' in the paper delta_x = deltas [ i_nest_x ] muny_x = muny [ i_nest_x , :] # mu(n', :) for x in nest_x : ephi_x = ephi [ x , :] for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper mu_n = muny_x [ nest_y ] mu0_n = mu0y [ nest_y ] evec_n = ephi_x [ nest_y ] rho_n = rhos [ i_nest_y ] sum_rd = rho_n + delta_x mun_term = nppow ( mu_n , ( delta_x - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ x , i_nest_y ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ x , i_nest_y ] = nppow ( gbar [ x , i_nest_y ], sum_rd / ( delta_x + 1.0 ) ) biga [ x ] += gbar_pow [ x , i_nest_y ] # now we take one Newton step for all types of men delta_vals1 = 1.0 + delta_vals mux0_term = nppow ( mux0 , 1.0 / delta_vals1 ) bigb = mux0_term * biga # this is the $B_x$ of the note numer = n * delta_vals1 - delta_vals * bigb lower_bound = np . full ( X , MIN_REST ) mux0_new = mux0 * np . maximum ( numer / ( delta_vals1 * mux0 + bigb ), lower_bound ) muxn_new = gbar_pow * mux0_term . reshape (( - 1 , 1 )) mux0 = mux0_new muxn = muxn_new errxi = mux0 + np . sum ( muxn , 1 ) - n err_newton = npmaxabs ( errxi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for men after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on men is { err_newton } after { i_newton } iterations\" ) # Newton iterates for women err_newton = bigc i_newton = 0 while err_newton > tol_newton : gbar = np . zeros (( Y , n_deltas )) gbar_pow = np . zeros (( Y , n_deltas )) biga = np . zeros ( Y ) for i_nest_y , nest_y in enumerate ( nests_over_Y ): # i_nest_y is n in the paper rho_y = rhos [ i_nest_y ] muxn_y = muxn [:, i_nest_y ] # mu(:, n) for y in nest_y : ephi_y = ephi [:, y ] for i_nest_x , nest_x in enumerate ( nests_over_X ): mu_n = muxn_y [ nest_x ] mu0_n = mux0 [ nest_x ] evec_n = ephi_y [ nest_x ] delta_n = deltas [ i_nest_x ] sum_rd = rho_y + delta_n mun_term = nppow ( mu_n , ( rho_n - 1.0 ) / sum_rd ) mu0_term = nppow ( mu0_n , 1.0 / sum_rd ) gbar [ y , i_nest_x ] = np . sum ( mun_term * mu0_term * evec_n ) gbar_pow [ y , i_nest_x ] = nppow ( gbar [ y , i_nest_x ], sum_rd / ( 1.0 + rho_y ) ) biga [ y ] += gbar_pow [ y , i_nest_x ] # now we take one Newton step for all types of women rho_vals1 = 1.0 + rho_vals mu0y_term = nppow ( mu0y , 1.0 / rho_vals1 ) bigb = mu0y_term * biga numer = m * rho_vals1 - rho_vals * bigb lower_bound = np . full ( Y , MIN_REST ) mu0y_new = mu0y * np . maximum ( numer / ( rho_vals1 * mu0y + bigb ), lower_bound ) muny_new = gbar_pow . T * mu0y_term mu0y = mu0y_new muny = muny_new erryi = mu0y + np . sum ( muny , 0 ) - m err_newton = npmaxabs ( erryi ) i_newton += 1 if i_newton > max_newton : bs_error_abort ( f \"Newton solver failed for women after { max_newton } iterations\" ) if verbose : print ( f \"Newton error on women is { err_newton } after { i_newton } iterations\" ) muxy = np . zeros (( X , Y )) for x in range ( X ): i_nest_x = i_nest_of_x [ x ] # n' ephi_x = ephi [ x , :] mux0_x = mux0 [ x ] muxn_x = muxn [ x , :] delta_x = delta_vals [ x ] muny_x = muny [ i_nest_x , :] for y in range ( Y ): i_nest_y = i_nest_of_y [ y ] # n mu0y_y = mu0y [ y ] rho_y = rho_vals [ y ] muxn_xy = muxn_x [ i_nest_y ] muny_xy = muny_x [ y ] mu_term = ( mux0_x * mu0y_y * ( muxn_xy ** ( rho_y - 1.0 )) * ( muny_xy ** ( delta_x - 1.0 )) ) muxy [ x , y ] = ephi_x [ y ] * ( mu_term ** ( 1.0 / ( delta_x + rho_y ))) n_sim , m_sim = compute_margins ( muxy , mux0 , mu0y ) marg_err_x , marg_err_y = n_sim - n , m_sim - m if verbose : print ( f \"Margin error on men is { marg_err_x } \" f \" after { niter } IPFP iterations\" ) print ( f \"Margin error on women is { marg_err_y } \" f \" after { niter } IPFP iterations\" ) err_diff = npmaxabs ( marg_err_x ) + npmaxabs ( marg_err_y ) niter += 1 n_sim , m_sim = compute_margins ( muxy , mux0 , mu0y ) marg_err_x = n_sim - n marg_err_y = m_sim - m if verbose : print ( f \"Margin error on men is { npmaxabs ( marg_err_x ) } after { niter } IPFP\" \" iterations\" ) print ( f \"Margin error on women is { npmaxabs ( marg_err_y ) } after { niter } IPFP\" \" iterations\" ) return Matching ( muxy , n , m ), marg_err_x , marg_err_y","title":"ipfp_nested_logit_solver()"},{"location":"nested_logit/","text":"nested_logit module \u00b6 The components of the derivative of the entropy for a two-layer nested logit model. One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters. e0_derivative_mu_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(\\mu\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt \\((\\mu,\\mu)\\) . Source code in cupid_matching/nested_logit.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def e0_derivative_mu_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $\\\\mu$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu,\\\\mu)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y for x in range ( X ): dlogx0 = der_logx0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) der_logxn = 1.0 / mu_xn for y in nest : hess_x [ x , y , :] = - dlogx0 hess_x [ x , y , nest ] -= der_logxn for y in range ( Y ): dlog0y = der_log0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) der_logny = 1.0 / mu_ny for x in nest : hess_y [ x , y , :] = - dlog0y hess_y [ x , y , nest ] -= der_logny for x in range ( X ): for y in range ( Y ): hess_xy [ x , y ] = hess_x [ x , y , y ] + hess_y [ x , y , x ] return hess_x , hess_y , hess_xy e0_derivative_r_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(r\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt \\((\\mu,r)\\) . Source code in cupid_matching/nested_logit.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 def e0_derivative_r_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu,r)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y for x in range ( X ): dlogx0 = der_logx0 [ x ] for nest in nests_x : for y in nest : hess_n [ x , y ] = dlogx0 for y in range ( Y ): dlog0y = der_log0y [ y ] for nest in nests_y : for x in nest : hess_m [ x , y ] = dlog0y return hess_n , hess_m e0_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the values of the parameter-independent part \\(e_0\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy. Source code in cupid_matching/nested_logit.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def e0_nested_logit ( muhat : Matching , additional_parameters : list [ Any ]) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape e0_vals = np . zeros (( X , Y )) for x in range ( X ): mux0_x = mux0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) e0_vals [ x , nest ] = - log ( mu_xn / mux0_x ) for y in range ( Y ): mu0y_y = mu0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) e0_vals [ nest , y ] -= log ( mu_ny / mu0y_y ) return e0_vals e_derivative_mu_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(\\mu\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt \\((\\mu,\\mu)\\) . Source code in cupid_matching/nested_logit.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 def e_derivative_mu_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\\\mu$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\\\mu,\\\\mu)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) der_logxn = 1.0 / mu_xn for t in nest : hess_x [ x , nest , t , i_n ] = der_logxn hess_xy [ x , nest , i_n ] = der_logxn - der_logxy [ x , nest ] for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) der_logny = 1.0 / mu_ny i_n2 = i_n + n_rhos for z in nest : hess_y [ nest , y , z , i_n2 ] = der_logny hess_xy [ nest , y , i_n2 ] = der_logny - der_logxy [ nest , y ] return hess_x , hess_y , hess_xy e_derivative_r_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(r\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt \\((\\mu,r)\\) . Source code in cupid_matching/nested_logit.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 def e_derivative_r_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\\\mu,r)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) return hess_n , hess_m e_nested_logit ( muhat , additional_parameters ) \u00b6 Returns the values of the parameter-dependent part \\(e\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description np . ndarray the (X,Y,n_alpha) array of the parameter-dependent part np . ndarray of the first derivative of the entropy. Source code in cupid_matching/nested_logit.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 def e_nested_logit ( muhat : Matching , additional_parameters : list [ Any ]) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the (X,Y,n_alpha) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape e_vals = np . zeros (( X , Y , n_alpha )) for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) e_vals [ x , nest , i_n ] = - np . log ( mux_nest_n / mu_xn ) for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) e_vals [ nest , y , ( i_n + n_rhos )] -= np . log ( muy_nest_n / mu_ny ) return e_vals","title":"Nested Logit"},{"location":"nested_logit/#nested_logit-module","text":"The components of the derivative of the entropy for a two-layer nested logit model. One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters.","title":"nested_logit module"},{"location":"nested_logit/#cupid_matching.nested_logit.e0_derivative_mu_nested_logit","text":"Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(\\mu\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description ThreeArrays the parameter-independent part of the hessian of the entropy ThreeArrays wrt \\((\\mu,\\mu)\\) . Source code in cupid_matching/nested_logit.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def e0_derivative_mu_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $\\\\mu$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu,\\\\mu)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y )) hess_y = np . zeros (( X , Y , X )) hess_xy = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y for x in range ( X ): dlogx0 = der_logx0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) der_logxn = 1.0 / mu_xn for y in nest : hess_x [ x , y , :] = - dlogx0 hess_x [ x , y , nest ] -= der_logxn for y in range ( Y ): dlog0y = der_log0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) der_logny = 1.0 / mu_ny for x in nest : hess_y [ x , y , :] = - dlog0y hess_y [ x , y , nest ] -= der_logny for x in range ( X ): for y in range ( Y ): hess_xy [ x , y ] = hess_x [ x , y , y ] + hess_y [ x , y , x ] return hess_x , hess_y , hess_xy","title":"e0_derivative_mu_nested_logit()"},{"location":"nested_logit/#cupid_matching.nested_logit.e0_derivative_r_nested_logit","text":"Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(r\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description TwoArrays the parameter-independent part of the hessian of the entropy TwoArrays wrt \\((\\mu,r)\\) . Source code in cupid_matching/nested_logit.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 def e0_derivative_r_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-independent part of the hessian of the entropy wrt $(\\\\mu,r)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , n , m = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y )) hess_m = np . zeros (( X , Y )) der_logx0 = 1.0 / mux0 der_log0y = 1.0 / mu0y for x in range ( X ): dlogx0 = der_logx0 [ x ] for nest in nests_x : for y in nest : hess_n [ x , y ] = dlogx0 for y in range ( Y ): dlog0y = der_log0y [ y ] for nest in nests_y : for x in nest : hess_m [ x , y ] = dlog0y return hess_n , hess_m","title":"e0_derivative_r_nested_logit()"},{"location":"nested_logit/#cupid_matching.nested_logit.e0_nested_logit","text":"Returns the values of the parameter-independent part \\(e_0\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description np . ndarray the (X,Y) matrix of the parameter-independent part np . ndarray of the first derivative of the entropy. Source code in cupid_matching/nested_logit.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def e0_nested_logit ( muhat : Matching , additional_parameters : list [ Any ]) -> np . ndarray : \"\"\"Returns the values of the parameter-independent part $e_0$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the (X,Y) matrix of the parameter-independent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) muxy , mux0 , mu0y , * _ = muhat . unpack () X , Y = muxy . shape e0_vals = np . zeros (( X , Y )) for x in range ( X ): mux0_x = mux0 [ x ] for nest in nests_x : mu_xn = np . sum ( muxy [ x , nest ]) e0_vals [ x , nest ] = - log ( mu_xn / mux0_x ) for y in range ( Y ): mu0y_y = mu0y [ y ] for nest in nests_y : mu_ny = np . sum ( muxy [ nest , y ]) e0_vals [ nest , y ] -= log ( mu_ny / mu0y_y ) return e0_vals","title":"e0_nested_logit()"},{"location":"nested_logit/#cupid_matching.nested_logit.e_derivative_mu_nested_logit","text":"Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(\\mu\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description ThreeArrays the parameter-dependent part of the hessian of the entropy ThreeArrays wrt \\((\\mu,\\mu)\\) . Source code in cupid_matching/nested_logit.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 def e_derivative_mu_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> ThreeArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $\\\\mu$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\\\mu,\\\\mu)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_x = np . zeros (( X , Y , Y , n_alpha )) hess_y = np . zeros (( X , Y , X , n_alpha )) hess_xy = np . zeros (( X , Y , n_alpha )) der_logxy = 1.0 / muxy for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) der_logxn = 1.0 / mu_xn for t in nest : hess_x [ x , nest , t , i_n ] = der_logxn hess_xy [ x , nest , i_n ] = der_logxn - der_logxy [ x , nest ] for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) der_logny = 1.0 / mu_ny i_n2 = i_n + n_rhos for z in nest : hess_y [ nest , y , z , i_n2 ] = der_logny hess_xy [ nest , y , i_n2 ] = der_logny - der_logxy [ nest , y ] return hess_x , hess_y , hess_xy","title":"e_derivative_mu_nested_logit()"},{"location":"nested_logit/#cupid_matching.nested_logit.e_derivative_r_nested_logit","text":"Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(r\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description TwoArrays the parameter-dependent part of the hessian of the entropy TwoArrays wrt \\((\\mu,r)\\) . Source code in cupid_matching/nested_logit.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 def e_derivative_r_nested_logit ( muhat : Matching , additional_parameters : list [ Any ] ) -> TwoArrays : \"\"\"Returns the derivatives of the parameter-dependent part $e$ wrt $r$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the parameter-dependent part of the hessian of the entropy wrt $(\\\\mu,r)$. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape hess_n = np . zeros (( X , Y , n_alpha )) hess_m = np . zeros (( X , Y , n_alpha )) return hess_n , hess_m","title":"e_derivative_r_nested_logit()"},{"location":"nested_logit/#cupid_matching.nested_logit.e_nested_logit","text":"Returns the values of the parameter-dependent part \\(e\\) for the nested logit. Parameters: Name Type Description Default muhat Matching a Matching required additional_parameters list [ Any ] a list with the nest structure required Returns: Type Description np . ndarray the (X,Y,n_alpha) array of the parameter-dependent part np . ndarray of the first derivative of the entropy. Source code in cupid_matching/nested_logit.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 def e_nested_logit ( muhat : Matching , additional_parameters : list [ Any ]) -> np . ndarray : \"\"\"Returns the values of the parameter-dependent part $e$ for the nested logit. Args: muhat: a Matching additional_parameters: a list with the nest structure Returns: the (X,Y,n_alpha) array of the parameter-dependent part of the first derivative of the entropy. \"\"\" nests_for_each_x , nests_for_each_y = additional_parameters nests_x = _change_indices ( nests_for_each_x ) nests_y = _change_indices ( nests_for_each_y ) n_rhos = len ( nests_for_each_x ) n_deltas = len ( nests_for_each_y ) n_alpha = n_rhos + n_deltas muxy , * _ = muhat . unpack () X , Y = muxy . shape e_vals = np . zeros (( X , Y , n_alpha )) for x in range ( X ): for i_n , nest in enumerate ( nests_x ): mux_nest_n = muxy [ x , nest ] mu_xn = np . sum ( mux_nest_n ) e_vals [ x , nest , i_n ] = - np . log ( mux_nest_n / mu_xn ) for y in range ( Y ): for i_n , nest in enumerate ( nests_y ): muy_nest_n = muxy [ nest , y ] mu_ny = np . sum ( muy_nest_n ) e_vals [ nest , y , ( i_n + n_rhos )] -= np . log ( muy_nest_n / mu_ny ) return e_vals","title":"e_nested_logit()"},{"location":"poisson_glm/","text":"poisson_glm module \u00b6 Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. choo_siow_poisson_glm ( muhat , phi_bases , tol = 1e-12 , max_iter = 10000 , verbose = 1 ) \u00b6 Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases np . ndarray an (X, Y, K) array of bases required tol float | None tolerance level for linear_model.PoissonRegressor.fit 1e-12 max_iter int | None maximum number of iterations for linear_model.PoissonRegressor.fit 10000 verbose int | None defines how much output we want (0 = least) 1 Returns: Type Description PoissonGLMResults a PoissonGLMResults instance Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 n_households = 1e6 X , Y , K = 4 , 3 , 6 # we setup a quadratic set of basis functions phi_bases = np . zeros (( X , Y , K )) phi_bases [:, :, 0 ] = 1 for x in range ( X ): phi_bases [ x , :, 1 ] = x phi_bases [ x , :, 3 ] = x * x for y in range ( Y ): phi_bases [ x , y , 4 ] = x * y for y in range ( Y ): phi_bases [:, y , 2 ] = y phi_bases [:, y , 5 ] = y * y lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np . ones ( X ) m = np . ones ( Y ) choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () results = choo_siow_poisson_glm ( mus_sim , phi_bases ) # compare true and estimated parameters results . print_results ( lambda_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ) ) Source code in cupid_matching/poisson_glm.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 def choo_siow_poisson_glm ( muhat : Matching , phi_bases : np . ndarray , tol : float | None = 1e-12 , max_iter : int | None = 10000 , verbose : int | None = 1 , ) -> PoissonGLMResults : \"\"\"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases tol: tolerance level for `linear_model.PoissonRegressor.fit` max_iter: maximum number of iterations for `linear_model.PoissonRegressor.fit` verbose: defines how much output we want (0 = least) Returns: a `PoissonGLMResults` instance Example: ```py n_households = 1e6 X, Y, K = 4, 3, 6 # we setup a quadratic set of basis functions phi_bases = np.zeros((X, Y, K)) phi_bases[:, :, 0] = 1 for x in range(X): phi_bases[x, :, 1] = x phi_bases[x, :, 3] = x * x for y in range(Y): phi_bases[x, y, 4] = x * y for y in range(Y): phi_bases[:, y, 2] = y phi_bases[:, y, 5] = y * y lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np.ones(X) m = np.ones(Y) choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack() results = choo_siow_poisson_glm(mus_sim, phi_bases) # compare true and estimated parameters results.print_results( lambda_true, u_true=-np.log(mux0_sim / n_sim), v_true=-np.log(mu0y_sim / m_sim) ) ``` \"\"\" try_sparse = False X , Y , K = phi_bases . shape XY = X * Y n_rows = XY + X + Y n_cols = X + Y + K # the vector of weights for the Poisson regression w = np . concatenate (( 2 * np . ones ( XY ), np . ones ( X + Y ))) # reshape the bases phi_mat = _make_XY_K_mat ( phi_bases ) if try_sparse : w_mat = spr . csr_matrix ( np . concatenate (( 2 * np . ones (( XY , n_cols )), np . ones (( X + Y , n_cols )))) ) # construct the Z matrix ones_X = spr . csr_matrix ( np . ones (( X , 1 ))) ones_Y = spr . csr_matrix ( np . ones (( Y , 1 ))) zeros_XK = spr . csr_matrix ( np . zeros (( X , K ))) zeros_YK = spr . csr_matrix ( np . zeros (( Y , K ))) zeros_XY = spr . csr_matrix ( np . zeros (( X , Y ))) zeros_YX = spr . csr_matrix ( np . zeros (( Y , X ))) id_X = spr . csr_matrix ( np . eye ( X )) id_Y = spr . csr_matrix ( np . eye ( Y )) Z_unweighted = spr . vstack ( [ spr . hstack ( [ - spr . kron ( id_X , ones_Y ), - spr . kron ( ones_X , id_Y ), phi_mat , ] ), spr . hstack ([ - id_X , zeros_XY , zeros_XK ]), spr . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w_mat else : ones_X = np . ones (( X , 1 )) ones_Y = np . ones (( Y , 1 )) zeros_XK = np . zeros (( X , K )) zeros_YK = np . zeros (( Y , K )) zeros_XY = np . zeros (( X , Y )) zeros_YX = np . zeros (( Y , X )) id_X = np . eye ( X ) id_Y = np . eye ( Y ) Z_unweighted = np . vstack ( [ np . hstack ([ - np . kron ( id_X , ones_Y ), - np . kron ( ones_X , id_Y ), phi_mat ]), np . hstack ([ - id_X , zeros_XY , zeros_XK ]), np . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w . reshape (( - 1 , 1 )) _ , _ , _ , n , m = muhat . unpack () var_muhat = variance_muhat ( muhat ) ( muxyhat_norm , var_muhat_norm , n_households , n_individuals , ) = _prepare_data ( muhat , var_muhat ) clf = linear_model . PoissonRegressor ( fit_intercept = False , tol = tol , verbose = verbose , alpha = 0 , max_iter = max_iter , ) clf . fit ( Z , muxyhat_norm , sample_weight = w ) gamma_est = clf . coef_ # we compute_ the variance-covariance of the estimator var_allmus_norm = var_muhat_norm . var_allmus nr , nc = Z . shape exp_Zg = np . exp ( Z @ gamma_est ) . reshape ( n_rows ) A_hat = np . zeros (( nc , nc )) B_hat = np . zeros (( nc , nc )) for i in range ( nr ): Zi = Z [ i , :] wi = w [ i ] A_hat += wi * exp_Zg [ i ] * np . outer ( Zi , Zi ) for j in range ( nr ): Zj = Z [ j , :] B_hat += wi * w [ j ] * var_allmus_norm [ i , j ] * np . outer ( Zi , Zj ) A_inv = spla . inv ( A_hat ) varcov_gamma = A_inv @ B_hat @ A_inv stderrs_gamma = np . sqrt ( np . diag ( varcov_gamma )) beta_est = gamma_est [ - K :] varcov_beta = varcov_gamma [ - K :, - K :] beta_std = stderrs_gamma [ - K :] Phi_est = phi_bases @ beta_est # we correct for the effect of the normalization n_norm = n / n_individuals m_norm = m / n_individuals u_est = gamma_est [: X ] + np . log ( n_norm ) v_est = gamma_est [ X : - K ] + np . log ( m_norm ) # since u = a + log(n_norm) we also need to adjust the estimated variance var_munm_norm = var_muhat_norm . var_munm var_n_norm = var_munm_norm [ XY : ( XY + X ), XY : ( XY + X )] var_m_norm = var_munm_norm [( XY + X ) :, ( XY + X ) :] Z_unweighted_T = Z_unweighted . T u_std = np . zeros ( X ) ix = XY for x in range ( X ): n_norm_x = n_norm [ x ] A_inv_x = A_inv [ x , :] var_log_nx = var_n_norm [ x , x ] / n_norm_x / n_norm_x slice_x = slice ( x * Y , ( x + 1 ) * Y ) covar_term = var_allmus_norm [:, ix ] + np . sum ( var_allmus_norm [:, slice_x ], 1 ) cov_a_lognx = ( A_inv_x @ Z_unweighted_T @ covar_term ) / n_norm_x ux_var = varcov_gamma [ x , x ] + var_log_nx + 2.0 * cov_a_lognx u_std [ x ] = sqrt ( ux_var ) ix += 1 v_std = stderrs_gamma [ X : - K ] iy , jy = X , XY + X for y in range ( Y ): m_norm_y = m_norm [ y ] A_inv_y = A_inv [ iy , :] var_log_my = var_m_norm [ y , y ] / m_norm_y / m_norm_y slice_y = slice ( y , XY , Y ) covar_term = var_allmus_norm [:, jy ] + np . sum ( var_allmus_norm [:, slice_y ], 1 ) cov_b_logmy = ( A_inv_y @ Z_unweighted_T @ covar_term ) / m_norm_y vy_var = varcov_gamma [ iy , iy ] + var_log_my + 2.0 * cov_b_logmy v_std [ y ] = sqrt ( vy_var ) iy += 1 jy += 1 results = PoissonGLMResults ( X = X , Y = Y , K = K , number_households = n_households , number_individuals = n_individuals , estimated_gamma = gamma_est , estimated_Phi = Phi_est , estimated_beta = beta_est , estimated_u = u_est , estimated_v = v_est , varcov_gamma = varcov_gamma , varcov_beta = varcov_beta , stderrs_gamma = stderrs_gamma , stderrs_beta = beta_std , stderrs_u = u_std , stderrs_v = v_std , ) return results","title":"Poisson estimator"},{"location":"poisson_glm/#poisson_glm-module","text":"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM.","title":"poisson_glm module"},{"location":"poisson_glm/#cupid_matching.poisson_glm.choo_siow_poisson_glm","text":"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Parameters: Name Type Description Default muhat Matching the observed Matching required phi_bases np . ndarray an (X, Y, K) array of bases required tol float | None tolerance level for linear_model.PoissonRegressor.fit 1e-12 max_iter int | None maximum number of iterations for linear_model.PoissonRegressor.fit 10000 verbose int | None defines how much output we want (0 = least) 1 Returns: Type Description PoissonGLMResults a PoissonGLMResults instance Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 n_households = 1e6 X , Y , K = 4 , 3 , 6 # we setup a quadratic set of basis functions phi_bases = np . zeros (( X , Y , K )) phi_bases [:, :, 0 ] = 1 for x in range ( X ): phi_bases [ x , :, 1 ] = x phi_bases [ x , :, 3 ] = x * x for y in range ( Y ): phi_bases [ x , y , 4 ] = x * y for y in range ( Y ): phi_bases [:, y , 2 ] = y phi_bases [:, y , 5 ] = y * y lambda_true = np . random . randn ( K ) phi_bases = np . random . randn ( X , Y , K ) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np . ones ( X ) m = np . ones ( Y ) choo_siow_instance = ChooSiowPrimitives ( Phi , n , m ) mus_sim = choo_siow_instance . simulate ( n_households ) muxy_sim , mux0_sim , mu0y_sim , n_sim , m_sim = mus_sim . unpack () results = choo_siow_poisson_glm ( mus_sim , phi_bases ) # compare true and estimated parameters results . print_results ( lambda_true , u_true =- np . log ( mux0_sim / n_sim ), v_true =- np . log ( mu0y_sim / m_sim ) ) Source code in cupid_matching/poisson_glm.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 def choo_siow_poisson_glm ( muhat : Matching , phi_bases : np . ndarray , tol : float | None = 1e-12 , max_iter : int | None = 10000 , verbose : int | None = 1 , ) -> PoissonGLMResults : \"\"\"Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM. Args: muhat: the observed Matching phi_bases: an (X, Y, K) array of bases tol: tolerance level for `linear_model.PoissonRegressor.fit` max_iter: maximum number of iterations for `linear_model.PoissonRegressor.fit` verbose: defines how much output we want (0 = least) Returns: a `PoissonGLMResults` instance Example: ```py n_households = 1e6 X, Y, K = 4, 3, 6 # we setup a quadratic set of basis functions phi_bases = np.zeros((X, Y, K)) phi_bases[:, :, 0] = 1 for x in range(X): phi_bases[x, :, 1] = x phi_bases[x, :, 3] = x * x for y in range(Y): phi_bases[x, y, 4] = x * y for y in range(Y): phi_bases[:, y, 2] = y phi_bases[:, y, 5] = y * y lambda_true = np.random.randn(K) phi_bases = np.random.randn(X, Y, K) Phi = phi_bases @ lambda_true # we simulate a Choo and Siow sample from a population # with equal numbers of men and women of each type n = np.ones(X) m = np.ones(Y) choo_siow_instance = ChooSiowPrimitives(Phi, n, m) mus_sim = choo_siow_instance.simulate(n_households) muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack() results = choo_siow_poisson_glm(mus_sim, phi_bases) # compare true and estimated parameters results.print_results( lambda_true, u_true=-np.log(mux0_sim / n_sim), v_true=-np.log(mu0y_sim / m_sim) ) ``` \"\"\" try_sparse = False X , Y , K = phi_bases . shape XY = X * Y n_rows = XY + X + Y n_cols = X + Y + K # the vector of weights for the Poisson regression w = np . concatenate (( 2 * np . ones ( XY ), np . ones ( X + Y ))) # reshape the bases phi_mat = _make_XY_K_mat ( phi_bases ) if try_sparse : w_mat = spr . csr_matrix ( np . concatenate (( 2 * np . ones (( XY , n_cols )), np . ones (( X + Y , n_cols )))) ) # construct the Z matrix ones_X = spr . csr_matrix ( np . ones (( X , 1 ))) ones_Y = spr . csr_matrix ( np . ones (( Y , 1 ))) zeros_XK = spr . csr_matrix ( np . zeros (( X , K ))) zeros_YK = spr . csr_matrix ( np . zeros (( Y , K ))) zeros_XY = spr . csr_matrix ( np . zeros (( X , Y ))) zeros_YX = spr . csr_matrix ( np . zeros (( Y , X ))) id_X = spr . csr_matrix ( np . eye ( X )) id_Y = spr . csr_matrix ( np . eye ( Y )) Z_unweighted = spr . vstack ( [ spr . hstack ( [ - spr . kron ( id_X , ones_Y ), - spr . kron ( ones_X , id_Y ), phi_mat , ] ), spr . hstack ([ - id_X , zeros_XY , zeros_XK ]), spr . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w_mat else : ones_X = np . ones (( X , 1 )) ones_Y = np . ones (( Y , 1 )) zeros_XK = np . zeros (( X , K )) zeros_YK = np . zeros (( Y , K )) zeros_XY = np . zeros (( X , Y )) zeros_YX = np . zeros (( Y , X )) id_X = np . eye ( X ) id_Y = np . eye ( Y ) Z_unweighted = np . vstack ( [ np . hstack ([ - np . kron ( id_X , ones_Y ), - np . kron ( ones_X , id_Y ), phi_mat ]), np . hstack ([ - id_X , zeros_XY , zeros_XK ]), np . hstack ([ zeros_YX , - id_Y , zeros_YK ]), ] ) Z = Z_unweighted / w . reshape (( - 1 , 1 )) _ , _ , _ , n , m = muhat . unpack () var_muhat = variance_muhat ( muhat ) ( muxyhat_norm , var_muhat_norm , n_households , n_individuals , ) = _prepare_data ( muhat , var_muhat ) clf = linear_model . PoissonRegressor ( fit_intercept = False , tol = tol , verbose = verbose , alpha = 0 , max_iter = max_iter , ) clf . fit ( Z , muxyhat_norm , sample_weight = w ) gamma_est = clf . coef_ # we compute_ the variance-covariance of the estimator var_allmus_norm = var_muhat_norm . var_allmus nr , nc = Z . shape exp_Zg = np . exp ( Z @ gamma_est ) . reshape ( n_rows ) A_hat = np . zeros (( nc , nc )) B_hat = np . zeros (( nc , nc )) for i in range ( nr ): Zi = Z [ i , :] wi = w [ i ] A_hat += wi * exp_Zg [ i ] * np . outer ( Zi , Zi ) for j in range ( nr ): Zj = Z [ j , :] B_hat += wi * w [ j ] * var_allmus_norm [ i , j ] * np . outer ( Zi , Zj ) A_inv = spla . inv ( A_hat ) varcov_gamma = A_inv @ B_hat @ A_inv stderrs_gamma = np . sqrt ( np . diag ( varcov_gamma )) beta_est = gamma_est [ - K :] varcov_beta = varcov_gamma [ - K :, - K :] beta_std = stderrs_gamma [ - K :] Phi_est = phi_bases @ beta_est # we correct for the effect of the normalization n_norm = n / n_individuals m_norm = m / n_individuals u_est = gamma_est [: X ] + np . log ( n_norm ) v_est = gamma_est [ X : - K ] + np . log ( m_norm ) # since u = a + log(n_norm) we also need to adjust the estimated variance var_munm_norm = var_muhat_norm . var_munm var_n_norm = var_munm_norm [ XY : ( XY + X ), XY : ( XY + X )] var_m_norm = var_munm_norm [( XY + X ) :, ( XY + X ) :] Z_unweighted_T = Z_unweighted . T u_std = np . zeros ( X ) ix = XY for x in range ( X ): n_norm_x = n_norm [ x ] A_inv_x = A_inv [ x , :] var_log_nx = var_n_norm [ x , x ] / n_norm_x / n_norm_x slice_x = slice ( x * Y , ( x + 1 ) * Y ) covar_term = var_allmus_norm [:, ix ] + np . sum ( var_allmus_norm [:, slice_x ], 1 ) cov_a_lognx = ( A_inv_x @ Z_unweighted_T @ covar_term ) / n_norm_x ux_var = varcov_gamma [ x , x ] + var_log_nx + 2.0 * cov_a_lognx u_std [ x ] = sqrt ( ux_var ) ix += 1 v_std = stderrs_gamma [ X : - K ] iy , jy = X , XY + X for y in range ( Y ): m_norm_y = m_norm [ y ] A_inv_y = A_inv [ iy , :] var_log_my = var_m_norm [ y , y ] / m_norm_y / m_norm_y slice_y = slice ( y , XY , Y ) covar_term = var_allmus_norm [:, jy ] + np . sum ( var_allmus_norm [:, slice_y ], 1 ) cov_b_logmy = ( A_inv_y @ Z_unweighted_T @ covar_term ) / m_norm_y vy_var = varcov_gamma [ iy , iy ] + var_log_my + 2.0 * cov_b_logmy v_std [ y ] = sqrt ( vy_var ) iy += 1 jy += 1 results = PoissonGLMResults ( X = X , Y = Y , K = K , number_households = n_households , number_individuals = n_individuals , estimated_gamma = gamma_est , estimated_Phi = Phi_est , estimated_beta = beta_est , estimated_u = u_est , estimated_v = v_est , varcov_gamma = varcov_gamma , varcov_beta = varcov_beta , stderrs_gamma = stderrs_gamma , stderrs_beta = beta_std , stderrs_u = u_std , stderrs_v = v_std , ) return results","title":"choo_siow_poisson_glm()"},{"location":"poisson_glm_utils/","text":"poisson_glm_utils module \u00b6 Utilities for Poisson GLM. PoissonGLMResults dataclass \u00b6 Stores and formats the estimation results. Parameters: Name Type Description Default X int int required Y int int required K int int required number_households int int required number_individuals int int required estimated_gamma np . ndarray np.ndarray required varcov_gamma np . ndarray np.ndarray required stderrs_gamma np . ndarray np.ndarray required estimated_beta np . ndarray np.ndarray required estimated_u np . ndarray np.ndarray required estimated_v np . ndarray np.ndarray required varcov_beta np . ndarray np.ndarray required stderrs_beta np . ndarray np.ndarray required stderrs_u np . ndarray np.ndarray required stderrs_v np . ndarray np.ndarray required estimated_Phi np . ndarray np.ndarray required Source code in cupid_matching/poisson_glm_utils.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 @dataclass class PoissonGLMResults : \"\"\"Stores and formats the estimation results. Args: X: int Y: int K: int number_households: int number_individuals: int estimated_gamma: np.ndarray varcov_gamma: np.ndarray stderrs_gamma: np.ndarray estimated_beta: np.ndarray estimated_u: np.ndarray estimated_v: np.ndarray varcov_beta: np.ndarray stderrs_beta: np.ndarray stderrs_u: np.ndarray stderrs_v: np.ndarray estimated_Phi: np.ndarray \"\"\" X : int Y : int K : int number_households : int number_individuals : int estimated_gamma : np . ndarray varcov_gamma : np . ndarray stderrs_gamma : np . ndarray estimated_beta : np . ndarray varcov_beta : np . ndarray estimated_u : np . ndarray estimated_v : np . ndarray stderrs_beta : np . ndarray stderrs_u : np . ndarray stderrs_v : np . ndarray estimated_Phi : np . ndarray def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" print_stars ( \"Estimating a Choo and Siow model by Poisson GLM.\" ) model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += ( \"The estimated basis coefficients (and their standard errors) are \\n\\n \" ) for i in range ( self . K ): repr_str += ( f \" base_ { i + 1 } : { self . estimated_beta [ i ] : > 10.3f } \" + f \"( { self . stderrs_beta [ i ] : .3f } ) \\n \" ) repr_str += \"The estimated utilities of men (and their standard errors) are \\n\\n \" for i in range ( self . X ): repr_str += ( f \" u_ { i + 1 } : { self . estimated_u [ i ] : > 10.3f } \" + f \"( { self . stderrs_u [ i ] : .3f } ) \\n \" ) repr_str += ( \"The estimated utilities of women (and their standard errors) are \\n\\n \" ) for i in range ( self . Y ): repr_str += ( f \" v { i + 1 } : { self . estimated_v [ i ] : > 10.3f } \" + f \"( { self . stderrs_v [ i ] : .3f } ) \\n \" ) return repr_str + line_stars def print_results ( self , lambda_true : np . ndarray | None = None , u_true : np . ndarray | None = None , v_true : np . ndarray | None = None , ) -> float | None : estimates_beta = self . estimated_beta stderrs_beta = self . stderrs_beta if lambda_true is None : repr_str = \"The estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += f \" base { i + 1 } : { lambda_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) self . report_utilities ( \"men\" , u_true ) self . report_utilities ( \"women\" , v_true ) if lambda_true is None : return None else : discrepancy = npmaxabs ( lambda_true - estimates_beta ) print_stars ( \"The largest difference between true and estimated coefficients is\" f \" { discrepancy : .2e } \" ) return cast ( float , discrepancy ) def report_utilities ( self , gender : str , utils_true : np . ndarray | None ) -> None : if gender not in [ \"men\" , \"women\" ]: bs_error_abort ( f \"gender can only be 'men' or 'women', not { gender } \" ) utils_estimates = self . estimated_u if gender == \"men\" else self . estimated_v utils_stderrs = self . stderrs_u if gender == \"men\" else self . stderrs_v util_prefix = \"u\" if gender == \"men\" else \"v\" if utils_true is None : repr_str = f \"The estimated utilities for { gender } \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( utils_estimates ): repr_str += f \" { util_prefix } _ { i + 1 } : \" repr_str += f \" { coeff : > 10.3f } ( { utils_stderrs [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = f \"The true and estimated utilities for { gender } \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( utils_estimates ): repr_str += f \" { util_prefix } _ { i + 1 } : { utils_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { utils_stderrs [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str )","title":"Utilities for Poisson"},{"location":"poisson_glm_utils/#poisson_glm_utils-module","text":"Utilities for Poisson GLM.","title":"poisson_glm_utils module"},{"location":"poisson_glm_utils/#cupid_matching.poisson_glm_utils.PoissonGLMResults","text":"Stores and formats the estimation results. Parameters: Name Type Description Default X int int required Y int int required K int int required number_households int int required number_individuals int int required estimated_gamma np . ndarray np.ndarray required varcov_gamma np . ndarray np.ndarray required stderrs_gamma np . ndarray np.ndarray required estimated_beta np . ndarray np.ndarray required estimated_u np . ndarray np.ndarray required estimated_v np . ndarray np.ndarray required varcov_beta np . ndarray np.ndarray required stderrs_beta np . ndarray np.ndarray required stderrs_u np . ndarray np.ndarray required stderrs_v np . ndarray np.ndarray required estimated_Phi np . ndarray np.ndarray required Source code in cupid_matching/poisson_glm_utils.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 @dataclass class PoissonGLMResults : \"\"\"Stores and formats the estimation results. Args: X: int Y: int K: int number_households: int number_individuals: int estimated_gamma: np.ndarray varcov_gamma: np.ndarray stderrs_gamma: np.ndarray estimated_beta: np.ndarray estimated_u: np.ndarray estimated_v: np.ndarray varcov_beta: np.ndarray stderrs_beta: np.ndarray stderrs_u: np.ndarray stderrs_v: np.ndarray estimated_Phi: np.ndarray \"\"\" X : int Y : int K : int number_households : int number_individuals : int estimated_gamma : np . ndarray varcov_gamma : np . ndarray stderrs_gamma : np . ndarray estimated_beta : np . ndarray varcov_beta : np . ndarray estimated_u : np . ndarray estimated_v : np . ndarray stderrs_beta : np . ndarray stderrs_u : np . ndarray stderrs_v : np . ndarray estimated_Phi : np . ndarray def __str__ ( self ): line_stars = \"*\" * 80 + \" \\n \" print_stars ( \"Estimating a Choo and Siow model by Poisson GLM.\" ) model_str = f \"The data has { self . number_households } households \\n\\n \" model_str += f \"We use { self . K } basis functions. \\n\\n \" repr_str = line_stars + model_str repr_str += ( \"The estimated basis coefficients (and their standard errors) are \\n\\n \" ) for i in range ( self . K ): repr_str += ( f \" base_ { i + 1 } : { self . estimated_beta [ i ] : > 10.3f } \" + f \"( { self . stderrs_beta [ i ] : .3f } ) \\n \" ) repr_str += \"The estimated utilities of men (and their standard errors) are \\n\\n \" for i in range ( self . X ): repr_str += ( f \" u_ { i + 1 } : { self . estimated_u [ i ] : > 10.3f } \" + f \"( { self . stderrs_u [ i ] : .3f } ) \\n \" ) repr_str += ( \"The estimated utilities of women (and their standard errors) are \\n\\n \" ) for i in range ( self . Y ): repr_str += ( f \" v { i + 1 } : { self . estimated_v [ i ] : > 10.3f } \" + f \"( { self . stderrs_v [ i ] : .3f } ) \\n \" ) return repr_str + line_stars def print_results ( self , lambda_true : np . ndarray | None = None , u_true : np . ndarray | None = None , v_true : np . ndarray | None = None , ) -> float | None : estimates_beta = self . estimated_beta stderrs_beta = self . stderrs_beta if lambda_true is None : repr_str = \"The estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = \"The true and estimated coefficients \" repr_str += \"(and their standard errors) are \\n\\n \" for i , coeff in enumerate ( estimates_beta ): repr_str += f \" base { i + 1 } : { lambda_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { stderrs_beta [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) self . report_utilities ( \"men\" , u_true ) self . report_utilities ( \"women\" , v_true ) if lambda_true is None : return None else : discrepancy = npmaxabs ( lambda_true - estimates_beta ) print_stars ( \"The largest difference between true and estimated coefficients is\" f \" { discrepancy : .2e } \" ) return cast ( float , discrepancy ) def report_utilities ( self , gender : str , utils_true : np . ndarray | None ) -> None : if gender not in [ \"men\" , \"women\" ]: bs_error_abort ( f \"gender can only be 'men' or 'women', not { gender } \" ) utils_estimates = self . estimated_u if gender == \"men\" else self . estimated_v utils_stderrs = self . stderrs_u if gender == \"men\" else self . stderrs_v util_prefix = \"u\" if gender == \"men\" else \"v\" if utils_true is None : repr_str = f \"The estimated utilities for { gender } \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( utils_estimates ): repr_str += f \" { util_prefix } _ { i + 1 } : \" repr_str += f \" { coeff : > 10.3f } ( { utils_stderrs [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str ) else : repr_str = f \"The true and estimated utilities for { gender } \" repr_str += \"(and their standard errors) are: \\n\\n \" for i , coeff in enumerate ( utils_estimates ): repr_str += f \" { util_prefix } _ { i + 1 } : { utils_true [ i ] : > 10.3f } \" repr_str += f \" { coeff : > 10.3f } ( { utils_stderrs [ i ] : > 10.3f } ) \\n \" print_stars ( repr_str )","title":"PoissonGLMResults"},{"location":"utils/","text":"utils module \u00b6 This module contains some utility programs used by the package.","title":"General Utilities"},{"location":"utils/#utils-module","text":"This module contains some utility programs used by the package.","title":"utils module"}]}