{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"cupid_matching","text":"<p>A Python package to solve, simulate and estimate separable matching models</p> <ul> <li>Free software: MIT license</li> <li>Documentation: https://bsalanie.github.io/cupid_matching</li> <li>See also: An interactive Streamlit app</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install [-U] cupid_matching\n</code></pre> <p>The package relies on utilities from <code>bs_python_utils</code>; installing with <code>pip</code> pulls it in automatically, but you will need it available locally when running the test suite.</p>"},{"location":"#importing-functions-from-the-package","title":"Importing functions from the package","text":"<p>For instance:</p> <pre><code>from cupid_matching.min_distance import estimate_semilinear_mde\n</code></pre>"},{"location":"#how-it-works","title":"How it works","text":"<p>The following only describes the general ideas. See   here for more background and the API reference on this site for the technical documentation.</p> <p>The <code>cupid_matching</code> package has code </p> <ul> <li>to solve for the stable matching using our Iterative Projection Fitting Procedure (IPFP) in variants of the model of bipartite, one-to-one matching with perfectly transferable utility. It has IPFP solvers for variants of the Choo and Siow 2006 model with or without singles, homoskedastic and heteroskedastic; and also for a class of nested logit models</li> <li>to estimate the parameters of separable models with semilinear surplus and entropy using a minimum distance estimator</li> <li>to estimate the parameters of semilinear Choo and Siow models using a Poisson GLM estimator</li> <li>for a Streamlit interactive app that demonstrates solving and estimating the Choo and Siow model using the <code>cupid_matching</code> package. You can try it here.</li> </ul> <p>Incidentally, my ipfp_R Github repository contains R code to solve for equilibrium in (only) the basic version of the Choo and Siow model.</p> <p>The package builds on the pioneering work of Choo and Siow JPE 2006 and on my work with Alfred Galichon, especially our REStud 2022 paper and this working paper.</p> <p>At this stage, it only deals with bipartite models. As the heterosexual marriage market is a leading example, I will refer to the two sides as men and women. Each man \\(m\\) (resp. each women \\(w\\)) has an observed, discrete-valued type \\(x\\) (resp. \\(y\\)), along with unobserved heterogeneity.</p>"},{"location":"#the-primitives","title":"The primitives","text":"<p>The primitives of this class of matching models are </p> <ul> <li>the margins: the numbers \\(n_x\\) of men of type \\(x=1,\\ldots,X\\) and the numbers \\(m_y\\) of women of type \\(y=1,\\ldots,Y\\)</li> <li>the joint surplus created by the match of a man \\(m\\) of type \\(x\\) and a woman \\(w\\) of type \\(y\\). We assume separability: this joint surplus takes the form  $$ \\Phi_{xy}+\\varepsilon_{my} +\\eta_{xw}. $$  I will only describe here the case when the data also has singles, i.e., when \\(x=y=0\\) is a possible type. The fuller documentation explains how to deal with the case when singles are not observed.</li> </ul> <p>A single man has utility \\(\\varepsilon_{m0}\\) and a single woman has utility \\(\\eta_{0w}\\).</p> <p>The modeler chooses the distributions of the vectors \\((\\varepsilon_{m0},\\varepsilon_{m1},\\ldots, \\varepsilon_{mY})\\) and \\((\\eta_{0w},\\eta_{1w},\\ldots,\\eta_{Xw})\\).</p>"},{"location":"#the-solution-the-stable-matching","title":"The solution: the stable matching","text":"<p>We denote \\(\\mu_{xy}\\) the number of matches between men of type \\(x\\) and women of type \\(y\\), \\(\\mu_{x0}\\) the number of single men of type \\(x\\), and \\(\\mu_{0y}\\) the number of single women of type \\(y\\).</p> <p>The total numbers must add up to the margins:  $$ \\sum_{y=1}^Y \\mu_{xy}+\\mu_{x0}=n_x \\; \\text{ and } \\; \\sum_{x=1}^X \\mu_{xy}+\\mu_{0y}=m_y. $$  The total number of individuals is \\(N_i=\\sum_{x=1}^X n_x+ \\sum_{y=1}^Y m_y\\) and the total number of households is \\(N_h = N_i - \\sum_{x=1}^X \\sum_{y=1}^Y \\mu_{xy}\\).</p> <p>Galichon-Salani\u00e9 (REStud 2022) shows that in large markets, if the vectors \\(\\varepsilon\\) and \\(\\eta\\) have full support, the stable matching is the unique solution to the strictly convex program $$ \\max_{\\mu} \\left(\\sum_{x=1}^X \\sum_{y=1}^Y \\mu_{xy}\\Phi_{xy} + \\mathcal{E}(\\mu; n, m)\\right) $$ where \\(\\mathcal{E}\\), the generalized entropy function, depends on the assumed distributions of the \\(\\varepsilon\\) and \\(\\eta\\) random vectors.</p> <p>The files <code>choo_siow.py</code>, <code>choo_siow_gender_heteroskedastic</code>, <code>choo_siow_heteroskedastic</code>, and <code>nested_logit</code> provide <code>EntropyFunctions</code> objects that compute the generalized entropy and at least its first derivative for, respectively,</p> <ol> <li>the original Choo and Siow 2006 model, in which the \\(\\varepsilon\\) and \\(\\eta\\) terms are iid draws from a type I extreme value distribution</li> <li>the same model, without singles (to be used when only couples are observed)</li> <li>an extension of 1. that allows for a scale parameter \\(\\tau\\) for the distribution of \\(\\eta\\)</li> <li>an extension of 3. that has type-dependent scale parameters \\(\\sigma_x\\) and \\(\\tau_y\\) (with \\(\\sigma_1=1\\)</li> <li>a two-layer nested logit model in which singles (type 0) are in their own nest and the user chooses the structure of the other nests.</li> </ol> <p>Users of the package are welcome to code <code>EntropyFunctions</code> objects for different distributions of the unobserved heterogeneity terms.</p>"},{"location":"#solving-for-the-stable-matching","title":"Solving for the stable matching","text":"<p>Given any joint surplus matrix \\(\\Phi\\); margins \\(n\\) and \\(m\\); and a generalized entropy \\(\\mathcal{E}\\), one would like to compute the stable matching patterns \\(\\mu\\).</p> <p>For the five classes of models above, this can be done efficiently using the IPFP algorithm in Galichon-Salani\u00e9 (REStud 2022) , which is coded in <code>ipfp_solvers.py</code> for the four Choo and Siow variants and in <code>model_classes.py</code> for the nested logit.</p> <p>Here is an example, given a Numpy array \\(\\Phi\\) that is an \\((X,Y)\\) matrix and a number \\(\\tau&gt;0\\):</p> <pre><code>import numpy as np\n\nfrom cupid_matching.ipfp_solvers import ipfp_gender_homoskedastic solver\n\nsolution = ipfp_gender_heteroskedastic_solver(Phi, n, m, tau)\nmus, error_x, error_y = solution\nmuxy = mus.muxy\n</code></pre> <p>The <code>mus</code> above is an instance of a <code>Matching</code> object (defined in <code>matching_utils.py</code>). <code>mus.muxy</code> has the number of couples by \\((x,y)\\) cell at the stable matching; the vectors <code>mus.mux0</code> and <code>mus.mu0y</code> contain the numbers of single men and women of each type.</p> <p>The vectors <code>error_x</code> and <code>error_y</code> are estimates of the precision of the solution (see the code in <code>ipfp_solvers.py</code>).</p>"},{"location":"#estimating-the-joint-surplus","title":"Estimating the joint surplus","text":"<p>Given observed matching patterns \\(\\mu\\); a class of generalized entropy functions \\((\\mathcal{E}^{\\alpha})\\); and a class of joint surplus functions \\((\\Phi^{\\beta})\\), one would like to estimate the parameter vectors \\(\\alpha\\) and \\(\\beta\\).</p> <p>The package provides two estimators, which are described extensively in this paper:</p> <ul> <li>the minimum distance estimator in <code>min_distance.py</code> </li> <li>the Poisson estimator in <code>poisson_glm.py</code>, which only applies to the Choo and Siow homoskedastic model.</li> </ul> <p>At this stage <code>cupid_matching</code> only allows for linear models of the joint surplus:</p> \\[ \\Phi^{\\beta}_{xy} = \\sum_{k=1}^K \\phi_{xy}^k \\beta_k \\] <p>where the basis functions \\((\\phi^1,\\ldots,\\phi^K)\\) are imposed by the analyst. </p> <p>The minimum distance estimator works as follows, given </p> <ul> <li>an observed matching stored in a <code>Matching</code> object <code>mus</code></li> <li>an <code>EntropyFunction</code> object <code>entropy_model</code> that allows for <code>p</code> parameters in \\(\\alpha\\)</li> <li>an \\((X,Y,K)\\) Numpy array of basis functions <code>phi_bases</code>:</li> </ul> <p><pre><code>mde_results = estimate_semilinear_mde(\n    mus, phi_bases, entropy_model)\nmde_results.print_results(n_alpha=p)\n</code></pre> The <code>mde_results</code> object contains the estimated \\(\\alpha\\) and \\(\\beta\\), their estimated variance-covariance, and a specification test.</p> <p>The Poisson-GLM estimator of the Choo and Siow homoskedastic model takes as input the obserrved matching and the basis functions, and returns the estimated \\(\\beta\\) and its estimated variance-covariance. <pre><code>poisson_results = choo_siow_poisson_glm(mus_sim, phi_bases)\n    _, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack()\npoisson_results.print_results()\n</code></pre> The <code>poisson_results</code> object contains the estimated  \\(\\beta\\), the expected utilities \\(u_x\\) and \\(v_y\\), and their estimated variance-covariance.</p>"},{"location":"#examples","title":"Examples","text":"<p>The following can be found in the <code>examples</code> folder of the package:</p> <ul> <li>example_choosiow.py shows how to run minimum distance and Poisson estimators on a Choo and Siow homoskedastic model.</li> <li>example_choosiow_no_singles.py does the same for a model without singles.</li> <li>example_nested_logit.py shows how to run minimum distance estimators on a two-layer nested logit model.</li> </ul>"},{"location":"#warnings","title":"Warnings","text":"<ul> <li>many of these models (including all variants of Choo and Siow) rely heavily on logarithms and exponentials. It is easy to generate examples where numeric instability sets in.</li> <li>as a consequence, the <code>numeric</code> versions of the minimum distance estimator (which use numerical derivatives) are not recommended.</li> <li>the bias-corrected minimum distance estimator (<code>corrected</code>) may have a larger mean-squared error and/or introduce numerical instabilities.</li> <li>the estimated variance of the estimators assumes that the observed matching was sampled at the household level, and that sampling weights are all equal.</li> </ul>"},{"location":"#release-notes","title":"Release notes","text":""},{"location":"#version-14-october-18-2025","title":"version 1.4 (October 18, 2025)","text":"<ul> <li>switched to <code>uv</code> for package management.</li> <li>included an <code>examples</code> directory.</li> </ul>"},{"location":"#version-13-december-8-2023","title":"version 1.3 (December 8, 2023)","text":"<ul> <li>added <code>CupidMatchingDoc.pdf</code> on Github, with detailed explanations of the methods. </li> </ul>"},{"location":"#version-12-november-29-2023","title":"version 1.2 (November 29, 2023)","text":"<ul> <li>incorporates models without singles for both MDE and Poisson; example in <code>example_choo_siow_no_singles.py</code>.</li> </ul>"},{"location":"#version-113-november-8-2023","title":"version 1.1.3 (November 8, 2023)","text":"<ul> <li>fixed URL of Streamlit app.</li> </ul>"},{"location":"#version-112-november-7-2023","title":"version 1.1.2 (November 7, 2023)","text":"<ul> <li>improved the Streamlit app, now in two files: <code>cupid_streamlit.py</code> and  <code>cupid_streamlit_utils.py</code>.</li> </ul>"},{"location":"#version-111","title":"version 1.1.1","text":"<ul> <li>improved documentation</li> <li>the package now relies on my utilities package <code>bs_python_utils</code>.  The <code>VarianceMatching</code> class in <code>matching_utils,py</code> is new; this should be transparent for the user.</li> </ul>"},{"location":"#version-108","title":"version 1.0.8","text":"<ul> <li>deleted spurious print statement.</li> </ul>"},{"location":"#version-107","title":"version 1.0.7","text":"<ul> <li>fixed error in bias-correction term.</li> </ul>"},{"location":"#version-106","title":"version 1.0.6","text":"<ul> <li>corrected typo.</li> </ul>"},{"location":"#version-105","title":"version 1.0.5","text":"<ul> <li>simplified the bias-correction for the minimum distance estimator in the Choo and Siow homoskedastic model.</li> </ul>"},{"location":"#version-104","title":"version 1.0.4","text":"<ul> <li>added an optional bias-correction for the minimum distance estimator in the Choo and Siow homoskedastic model, to help with cases when the matching patterns vary a lot across cells.</li> <li>added two complete examples: <code>example_choosiow.py</code> and <code>example_nestedlogit.py</code>.</li> </ul>"},{"location":"choo_siow/","title":"<code>choo_siow</code> module","text":"<p>The components of the derivative of the entropy for the Choo and Siow homoskedastic model.</p>"},{"location":"choo_siow/#cupid_matching.choo_siow.e0_fun_choo_siow","title":"<code>e0_fun_choo_siow(muhat, additional_parameters=None)</code>","text":"<p>Returns the values of \\(e_0\\) for the Choo and Siow model.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the (X,Y) matrix of the first derivative of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def e0_fun_choo_siow(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; np.ndarray:\n    \"\"\"Returns the values of $e_0$ for the Choo and Siow model.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y) matrix of the first derivative of the entropy\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    entropy_res = cast(tuple[float, np.ndarray], _entropy_choo_siow(muhat, deriv=1))\n    return cast(np.ndarray, entropy_res[1])\n</code></pre>"},{"location":"choo_siow/#cupid_matching.choo_siow.e0_fun_choo_siow_corrected","title":"<code>e0_fun_choo_siow_corrected(muhat, additional_parameters=None)</code>","text":"<p>Returns the values of \\(e_0\\) for the Choo and Siow model, using the finite-sample correction log(p+(1-p)/(2N))</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the (X,Y) matrix of the first derivative of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def e0_fun_choo_siow_corrected(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; np.ndarray:\n    \"\"\"Returns the values of $e_0$ for the Choo and Siow model,\n    using the finite-sample correction log(p+(1-p)/(2N))\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y) matrix of the first derivative of the entropy\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    e0_val_corrected = _der_entropy_choo_siow_corrected(muhat, hessian=False)\n    return e0_val_corrected\n</code></pre>"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mumu_choo_siow","title":"<code>hessian_mumu_choo_siow(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of \\(e_0\\) in \\(\\mu\\) for the Choo and Siow model.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the three components of the hessian wrt \\((\\mu,\\mu)\\) of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def hessian_mumu_choo_siow(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; ThreeArrays:\n    \"\"\"Returns the derivatives of $e_0$ in $\\\\mu$\n    for the Choo and Siow model.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the three components of the hessian wrt $(\\\\mu,\\\\mu)$ of the entropy\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    entropy_res = cast(\n        tuple[float, np.ndarray, np.ndarray, np.ndarray],\n        _entropy_choo_siow(muhat, deriv=2),\n    )\n    hessmumu = entropy_res[2]\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    hess_x = np.zeros((X, Y, Y))\n    hess_y = np.zeros((X, Y, X))\n    hess_xy = np.zeros((X, Y))\n    for x in range(X):\n        for y in range(Y):\n            d2xy = hessmumu[x, y, :, :]\n            hess_x[x, y, :] = d2xy[x, :]\n            hess_y[x, y, :] = d2xy[:, y]\n            hess_xy[x, y] = d2xy[x, y]\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mumu_choo_siow_corrected","title":"<code>hessian_mumu_choo_siow_corrected(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of \\(e_0\\) in \\(\\mu\\) for the Choo and Siow model, with the small sample correction</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the three components of the hessian wrt \\((\\mu,\\mu)\\) of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def hessian_mumu_choo_siow_corrected(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; ThreeArrays:\n    \"\"\"Returns the derivatives of $e_0$ in $\\\\mu$\n    for the Choo and Siow model, with the small sample correction\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the three components of the hessian wrt $(\\\\mu,\\\\mu)$ of the entropy\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    _, hessmumu, _ = _der_entropy_choo_siow_corrected(muhat, hessian=True)\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    hess_x = np.zeros((X, Y, Y))\n    hess_y = np.zeros((X, Y, X))\n    hess_xy = np.zeros((X, Y))\n    for x in range(X):\n        for y in range(Y):\n            d2xy = hessmumu[x, y, :, :]\n            hess_x[x, y, :] = d2xy[x, :]\n            hess_y[x, y, :] = d2xy[:, y]\n            hess_xy[x, y] = d2xy[x, y]\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mur_choo_siow","title":"<code>hessian_mur_choo_siow(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of \\(e_0\\) in \\(r\\) for the Choo and Siow model.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the two components of the hessian wrt \\((\\mu,r)\\) of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def hessian_mur_choo_siow(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; TwoArrays:\n    \"\"\"Returns the derivatives of $e_0$ in $r$\n    for the Choo and Siow model.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the two components of the hessian wrt $(\\\\mu,r)$ of the entropy\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    entropy_res = cast(\n        tuple[float, np.ndarray, np.ndarray, np.ndarray],\n        _entropy_choo_siow(muhat, deriv=2),\n    )\n    hessmur = entropy_res[3]\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    hess_nx = np.zeros((X, Y))\n    hess_my = np.zeros((X, Y))\n    for x in range(X):\n        for y in range(Y):\n            d2r = hessmur[x, y, :]\n            hess_nx[x, y] = d2r[x]\n            hess_my[x, y] = d2r[X + y]\n    return hess_nx, hess_my\n</code></pre>"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mur_choo_siow_corrected","title":"<code>hessian_mur_choo_siow_corrected(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of \\(e_0\\) in \\(r\\) for the Choo and Siow model, with the small sample correction</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the two components of the hessian wrt \\((\\mu,r)\\) of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def hessian_mur_choo_siow_corrected(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; TwoArrays:\n    \"\"\"Returns the derivatives of $e_0$ in $r$\n    for the Choo and Siow model, with the small sample correction\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the two components of the hessian wrt $(\\\\mu,r)$ of the entropy\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    _, _, hessmur = _der_entropy_choo_siow_corrected(muhat, hessian=True)\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    hess_nx = np.zeros((X, Y))\n    hess_my = np.zeros((X, Y))\n    for x in range(X):\n        for y in range(Y):\n            d2r = hessmur[x, y, :]\n            hess_nx[x, y] = d2r[x]\n            hess_my[x, y] = d2r[X + y]\n    return hess_nx, hess_my\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/","title":"<code>choo_siow_gender_heteroskedastic</code> module","text":"<p>The components of the derivative of the entropy for the Choo and Siow gender-heteroskedastic model.</p> <p>We normalize the standard error for the X side at 1, and we estimate the standard error on the Y side.</p>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e0_choo_siow_gender_heteroskedastic","title":"<code>e0_choo_siow_gender_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the values of the parameter-independent part \\(e_0\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\).</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the (X,Y) matrix of the parameter-independent part</p> <code>ndarray</code> <p>of the first derivative of the entropy.</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e0_choo_siow_gender_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; np.ndarray:\n    \"\"\"Returns the values of the parameter-independent part $e_0$\n    for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y) matrix of the parameter-independent part\n        of the first derivative of the entropy.\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    e0_vals = -np.log(muxy / mux0.reshape((-1, 1)))\n    return cast(np.ndarray, e0_vals)\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e0_derivative_mu_gender_heteroskedastic","title":"<code>e0_derivative_mu_gender_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-independent part \\(e_0\\) in \\(\\mu\\). for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\).</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the  parameter-independent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt \\((\\mu,\\mu)\\).</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e0_derivative_mu_gender_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; ThreeArrays:\n    \"\"\"Returns the derivatives of the parameter-independent part $e_0$ in $\\\\mu$.\n    for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the  parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu,\\\\mu)$.\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    hess_x = np.zeros((X, Y, Y))\n    hess_y = np.zeros((X, Y, X))\n    hess_xy = np.zeros((X, Y))\n    der_logxy = 1.0 / muxy\n    der_logx0 = 1.0 / mux0\n    for x in range(X):\n        dlogx0 = der_logx0[x]\n        for y in range(Y):\n            hess_x[x, y, :] = -dlogx0\n            hess_xy[x, y] = -der_logxy[x, y] - dlogx0\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e0_derivative_r_gender_heteroskedastic","title":"<code>e0_derivative_r_gender_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(r\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\).</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-independent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt \\((\\mu,r)\\).</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e0_derivative_r_gender_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; TwoArrays:\n    \"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$\n    for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu,r)$.\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    hess_n = np.zeros((X, Y))\n    hess_m = np.zeros((X, Y))\n    der_logx0 = 1.0 / mux0\n    for x in range(X):\n        dlogx0 = der_logx0[x]\n        for y in range(Y):\n            hess_n[x, y] = dlogx0\n    return hess_n, hess_m\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e_choo_siow_gender_heteroskedastic","title":"<code>e_choo_siow_gender_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the values of the parameter-dependent part  \\(e\\) for the Choo and Siow gender-heteroskedastic model; we normalized \\(\\sigma=1\\).</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the (X,Y,1) array of the parameter-dependent part</p> <code>ndarray</code> <p>of the first derivative of the entropy.</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e_choo_siow_gender_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; np.ndarray:\n    \"\"\"Returns the values of the parameter-dependent part  $e$\n    for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y,1) array of the parameter-dependent part\n        of the first derivative of the entropy.\n    \"\"\"\n    muxy, _, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    n_alpha = 1\n\n    e_vals = np.zeros((X, Y, n_alpha))\n    e_vals[:, :, 0] = -np.log(muxy / mu0y)\n    return e_vals\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e_derivative_mu_gender_heteroskedastic","title":"<code>e_derivative_mu_gender_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-dependent part \\(e\\)  wrt \\(\\mu\\) for the Choo and Siow gender-heteroskedastic model;  we normalized \\(\\sigma_1=1\\).</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt \\((\\mu,\\mu)\\).</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e_derivative_mu_gender_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; ThreeArrays:\n    \"\"\"Returns the derivatives of the parameter-dependent part $e$\n     wrt $\\\\mu$ for the Choo and Siow gender-heteroskedastic model;\n     we normalized $\\\\sigma_1=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $(\\\\mu,\\\\mu)$.\n    \"\"\"\n    muxy, _, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    n_alpha = 1\n    hess_x = np.zeros((X, Y, Y, n_alpha))\n    hess_y = np.zeros((X, Y, X, n_alpha))\n    hess_xy = np.zeros((X, Y, n_alpha))\n    der_logxy = 1.0 / muxy\n    der_log0y = 1.0 / mu0y\n    for x in range(X):\n        for y in range(Y):\n            dlog0y = der_log0y[y]\n            hess_y[x, y, :, 0] = -dlog0y\n            hess_xy[x, y, 0] = -der_logxy[x, y] - dlog0y\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e_derivative_r_gender_heteroskedastic","title":"<code>e_derivative_r_gender_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-dependent part \\(e\\)  wrt \\(r\\) for the Choo and Siow gender-heteroskedastic model;  we normalized \\(\\sigma_1=1\\).</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt \\((\\mu,r)\\)</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e_derivative_r_gender_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; TwoArrays:\n    \"\"\"Returns the derivatives of the parameter-dependent part $e$\n     wrt $r$ for the Choo and Siow gender-heteroskedastic model;\n     we normalized $\\\\sigma_1=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $(\\\\mu,r)$\n    \"\"\"\n    muxy, _, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    n_alpha = 1\n    hess_n = np.zeros((X, Y, n_alpha))\n    hess_m = np.zeros((X, Y, n_alpha))\n    der_log0y = 1.0 / mu0y\n    for x in range(X):\n        for y in range(Y):\n            dlog0y = der_log0y[y]\n            hess_m[x, y, 0] = dlog0y\n    return hess_n, hess_m\n</code></pre>"},{"location":"choo_siow_heteroskedastic/","title":"<code>choo_siow_heteroskedastic</code> module","text":"<p>The components of the derivative of the entropy for the Choo and Siow fully heteroskedastic model.</p> <p>We normalize the standard error for X=1 at 1, and we estimate the standard errors for all other types on the X side and for all types on the Y side.</p>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e0_choo_siow_heteroskedastic","title":"<code>e0_choo_siow_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the values of the parameter-independent part \\(e_0\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\)</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the (X,Y) matrix of the parameter-independent part</p> <code>ndarray</code> <p>of the first derivative of the entropy</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e0_choo_siow_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; np.ndarray:\n    \"\"\"Returns the values of the parameter-independent part $e_0$\n    for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y) matrix of the parameter-independent part\n        of the first derivative of the entropy\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    mu1y = muxy[0, :]\n    mu10 = mux0[0]\n    e0_vals = np.zeros_like(muxy)\n    e0_vals[0, :] = -np.log(mu1y / mu10)\n    return cast(np.ndarray, e0_vals)\n</code></pre>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e0_derivative_mu_heteroskedastic","title":"<code>e0_derivative_mu_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(\\mu\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\)</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the parameter-independent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt \\((\\mu, \\mu)\\).</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e0_derivative_mu_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; ThreeArrays:\n    \"\"\"Returns the derivatives of the parameter-independent part $e_0$\n    wrt $\\\\mu$ for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu, \\\\mu)$.\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    mu1y = muxy[0, :]\n    mu10 = mux0[0]\n    hess_x = np.zeros((X, Y, Y))\n    hess_y = np.zeros((X, Y, X))\n    hess_xy = np.zeros((X, Y))\n    der_log1y = 1.0 / mu1y\n    der_log10 = 1.0 / mu10\n    for y in range(Y):\n        hess_x[0, y, :] = -der_log10\n        hess_xy[0, y] = -der_log1y[y] - der_log10\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e0_derivative_r_heteroskedastic","title":"<code>e0_derivative_r_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(r\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\)</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-independent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt \\((\\mu,r)\\).</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e0_derivative_r_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; TwoArrays:\n    \"\"\"Returns the derivatives of the parameter-independent part $e_0$\n    wrt $r$ for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu,r)$.\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    mu10 = mux0[0]\n    hess_n = np.zeros((X, Y))\n    hess_m = np.zeros((X, Y))\n    der_log10 = 1.0 / mu10\n    for y in range(Y):\n        hess_n[0, y] = der_log10\n    return hess_n, hess_m\n</code></pre>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e_choo_siow_heteroskedastic","title":"<code>e_choo_siow_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the values of the parameter-dependent part  \\(e\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\)</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy.</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e_choo_siow_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; np.ndarray:\n    \"\"\"Returns the values of the parameter-dependent part  $e$\n    for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy.\n    \"\"\"\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    n_alpha = X + Y - 1\n\n    e_vals = np.zeros((X, Y, n_alpha))\n    i = 0\n    for x in range(1, X):\n        e_vals[x, :, i] = -np.log(muxy[x, :] / mux0[x])\n        i += 1\n    for y in range(Y):\n        e_vals[:, y, i] = -np.log(muxy[:, y] / mu0y[y])\n        i += 1\n\n    return e_vals\n</code></pre>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e_derivative_mu_heteroskedastic","title":"<code>e_derivative_mu_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(\\mu\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\)</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt \\((\\mu,\\mu)\\).</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e_derivative_mu_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; ThreeArrays:\n    \"\"\"Returns the derivatives of the parameter-dependent part $e$\n    wrt $\\\\mu$ for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $(\\\\mu,\\\\mu)$.\n    \"\"\"\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    n_alpha = X + Y - 1\n    hess_x = np.zeros((X, Y, Y, n_alpha))\n    hess_y = np.zeros((X, Y, X, n_alpha))\n    hess_xy = np.zeros((X, Y, n_alpha))\n\n    der_logxy = 1.0 / muxy\n    der_logx0 = 1.0 / mux0\n    der_log0y = 1.0 / mu0y\n    i = 0\n    for x in range(1, X):\n        # derivatives wrt sigma_x\n        dlogx0 = der_logx0[x]\n        dlogxy = der_logxy[x, :]\n        for y in range(Y):\n            hess_x[x, y, :, i] = -dlogx0\n            hess_xy[x, y, i] = -dlogxy[y] - dlogx0\n        i += 1\n    for y in range(Y):\n        # derivatives wrt tau_y\n        dlog0y = der_log0y[y]\n        dlogxy = der_logxy[:, y]\n        for x in range(X):\n            hess_y[x, y, :, i] = -dlog0y\n            hess_xy[x, y, i] = -dlogxy[x] - dlog0y\n        i += 1\n\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e_derivative_r_heteroskedastic","title":"<code>e_derivative_r_heteroskedastic(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-dependent part \\(e\\) wrt \\(r\\) for the Choo and Siow heteroskedastic model; we normalized \\(\\sigma_1=1\\)</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt \\(r\\).</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e_derivative_r_heteroskedastic(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; TwoArrays:\n    \"\"\"Returns the derivatives of the parameter-dependent part $e$\n    wrt $r$ for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $r$.\n    \"\"\"\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    n_alpha = X + Y - 1\n    hess_n = np.zeros((X, Y, n_alpha))\n    hess_m = np.zeros((X, Y, n_alpha))\n\n    der_logx0 = 1.0 / mux0\n    der_log0y = 1.0 / mu0y\n    i = 0\n    for x in range(1, X):\n        # derivatives wrt sigma_x\n        dlogx0 = der_logx0[x]\n        for y in range(Y):\n            hess_n[x, y, i] = dlogx0\n        i += 1\n    for y in range(Y):\n        # derivatives wrt tau_y\n        dlog0y = der_log0y[y]\n        for x in range(X):\n            hess_m[x, y, i] = dlog0y\n        i += 1\n\n    return hess_n, hess_m\n</code></pre>"},{"location":"choo_siow_no_singles/","title":"<code>choo_siow_no_singles</code> module","text":"<p>The components of the derivative of the entropy for the Choo and Siow homoskedastic model w/o singles.</p>"},{"location":"choo_siow_no_singles/#cupid_matching.choo_siow_no_singles.e0_fun_choo_siow_no_singles","title":"<code>e0_fun_choo_siow_no_singles(muhat, additional_parameters=None)</code>","text":"<p>Returns the values of \\(e_0\\) for the Choo and Siow model w/o singles.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a <code>Matching</code></p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the <code>(X,Y)</code> matrix of the first derivative of the entropy</p> Source code in <code>cupid_matching/choo_siow_no_singles.py</code> <pre><code>def e0_fun_choo_siow_no_singles(\n    muhat: Matching,\n    additional_parameters: list | None = None,\n) -&gt; np.ndarray:\n    \"\"\"Returns the values of $e_0$ for the Choo and Siow model w/o singles.\n\n    Args:\n        muhat: a `Matching`\n\n    Returns:\n        the `(X,Y)` matrix of the first derivative of the entropy\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    _, der_entropy = cast(\n        tuple[float, np.ndarray], _entropy_choo_siow_no_singles(muhat, deriv=1)\n    )\n    return der_entropy\n</code></pre>"},{"location":"choo_siow_no_singles/#cupid_matching.choo_siow_no_singles.e0_fun_choo_siow_no_singles_corrected","title":"<code>e0_fun_choo_siow_no_singles_corrected(muhat, additional_parameters=None)</code>","text":"<p>Returns the values of \\(e_0\\) for the Choo and Siow model,     using the finite-sample correction \\(\\log(p+(1-p)/(2N))\\)</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a <code>Matching</code></p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the (X,Y) matrix of the first derivative of the entropy</p> Source code in <code>cupid_matching/choo_siow_no_singles.py</code> <pre><code>def e0_fun_choo_siow_no_singles_corrected(\n    muhat: Matching,\n    additional_parameters: list | None = None,\n) -&gt; np.ndarray:\n    \"\"\"Returns the values of $e_0$ for the Choo and Siow model,\n        using the finite-sample correction $\\\\log(p+(1-p)/(2N))$\n\n    Args:\n        muhat: a `Matching`\n\n    Returns:\n        the (X,Y) matrix of the first derivative of the entropy\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    e0_val_corrected = _der_entropy_choo_siow_no_singles_corrected(muhat, hessian=False)\n    return e0_val_corrected\n</code></pre>"},{"location":"choo_siow_no_singles/#cupid_matching.choo_siow_no_singles.hessian_mumu_choo_siow_no_singles","title":"<code>hessian_mumu_choo_siow_no_singles(muhat, additional_parameters=None)</code>","text":"<p>Returns the hessian of \\(e_0\\) wrt \\((\\mu,\\mu)\\) for the Choo and Siow model w/o singles.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a <code>Matching</code></p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the three components of the hessian  of the entropy wrt \\((\\mu,\\mu)\\)</p> Source code in <code>cupid_matching/choo_siow_no_singles.py</code> <pre><code>def hessian_mumu_choo_siow_no_singles(\n    muhat: Matching,\n    additional_parameters: list | None = None,\n) -&gt; ThreeArrays:\n    \"\"\"Returns the hessian of $e_0$ wrt $(\\\\mu,\\\\mu)$ for the Choo and Siow model w/o singles.\n\n    Args:\n        muhat: a `Matching`\n\n    Returns:\n        the three components of the hessian  of the entropy wrt $(\\\\mu,\\\\mu)$\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    _, _, hessmumu, _ = cast(\n        tuple[float, np.ndarray, np.ndarray, np.ndarray],\n        _entropy_choo_siow_no_singles(muhat, deriv=2),\n    )\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    hess_x = np.zeros((X, Y, Y))\n    hess_y = np.zeros((X, Y, X))\n    hess_xy = np.zeros((X, Y))\n    for x in range(X):\n        d2x = hessmumu[x, :, x, :]\n        for y in range(Y):\n            hess_xy[x, y] = d2x[y, y]\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow_no_singles/#cupid_matching.choo_siow_no_singles.hessian_mumu_choo_siow_no_singles_corrected","title":"<code>hessian_mumu_choo_siow_no_singles_corrected(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the hessian of \\(e_0\\) wrt \\((\\mu,\\mu)\\)     for the Choo and Siow model w/o singles, with the small sample correction</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a <code>Matching</code></p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the three components of the hessian of the entropy wrt \\((\\mu,\\mu)\\)</p> Source code in <code>cupid_matching/choo_siow_no_singles.py</code> <pre><code>def hessian_mumu_choo_siow_no_singles_corrected(\n    muhat: Matching,\n    additional_parameters: list | None = None,\n) -&gt; ThreeArrays:\n    \"\"\"Returns the derivatives of the hessian of $e_0$ wrt $(\\\\mu,\\\\mu)$\n        for the Choo and Siow model w/o singles, with the small sample correction\n\n    Args:\n        muhat: a `Matching`\n\n    Returns:\n        the three components of the hessian of the entropy wrt $(\\\\mu,\\\\mu)$\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    _, hessmumu, _ = cast(\n        tuple[np.ndarray, np.ndarray, np.ndarray],\n        _der_entropy_choo_siow_no_singles_corrected(muhat, hessian=True),\n    )\n    X, Y = muhat.muxy.shape\n    hess_x = np.zeros((X, Y, Y))\n    hess_y = np.zeros((X, Y, X))\n    hess_xy = np.zeros((X, Y))\n    for x in range(X):\n        d2x = hessmumu[x, :, x, :]\n        for y in range(Y):\n            hess_xy[x, y] = d2x[y, y]\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow_no_singles/#cupid_matching.choo_siow_no_singles.hessian_mur_choo_siow_no_singles","title":"<code>hessian_mur_choo_siow_no_singles(muhat, additional_parameters=None)</code>","text":"<p>Returns the hessian of \\(e_0\\) wrt \\((\\mu,r)\\) for the Choo and Siow model w/o singles.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the two components of the hessian of the entropy wrt \\((\\mu,r)\\)</p> Source code in <code>cupid_matching/choo_siow_no_singles.py</code> <pre><code>def hessian_mur_choo_siow_no_singles(\n    muhat: Matching,\n    additional_parameters: list | None = None,\n) -&gt; TwoArrays:\n    \"\"\"Returns the hessian of $e_0$ wrt $(\\\\mu,r)$ for the Choo and Siow model w/o singles.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the two components of the hessian of the entropy wrt $(\\\\mu,r)$\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    X, Y = muhat.muxy.shape\n    hess_nx = np.zeros((X, Y))\n    hess_my = np.zeros((X, Y))\n    return hess_nx, hess_my\n</code></pre>"},{"location":"choo_siow_no_singles/#cupid_matching.choo_siow_no_singles.hessian_mur_choo_siow_no_singles_corrected","title":"<code>hessian_mur_choo_siow_no_singles_corrected(muhat, additional_parameters=None)</code>","text":"<p>Returns the hessian of \\(e_0\\) wrt \\((\\mu,r)\\) for the Choo and Siow model w/o singles, with the small sample correction</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a <code>Matching</code></p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the two components of the hessian  of the entropy wrt \\((\\mu,r)\\)</p> Source code in <code>cupid_matching/choo_siow_no_singles.py</code> <pre><code>def hessian_mur_choo_siow_no_singles_corrected(\n    muhat: Matching,\n    additional_parameters: list | None = None,\n) -&gt; TwoArrays:\n    \"\"\"Returns the hessian of $e_0$ wrt $(\\\\mu,r)$ for the Choo and Siow model w/o singles, with the small sample correction\n\n    Args:\n        muhat: a `Matching`\n\n    Returns:\n        the two components of the hessian  of the entropy wrt $(\\\\mu,r)$\n    \"\"\"\n    check_additional_parameters(0, additional_parameters)\n    X, Y = muhat.muxy.shape\n    hess_nx = np.zeros((X, Y))\n    hess_my = np.zeros((X, Y))\n    return hess_nx, hess_my\n</code></pre>"},{"location":"cupid_streamlit/","title":"<code>cupid_streamlit</code> module","text":"<p>An interactive Streamlit application that solves for the stable matching and estimates the parameters of the joint surplus in a Choo and Siow 2006 homoskedastic model.</p>"},{"location":"cupid_streamlit_utils/","title":"<code>cupid_streamlit_utils</code> module","text":"<p>Utility code for the Streamlit app in <code>cupid_streamlit.py</code>.</p>"},{"location":"cupid_streamlit_utils/#cupid_matching.cupid_streamlit_utils.download_parameters_results","title":"<code>download_parameters_results(file_name, do_estimates, pars_res)</code>","text":"<p>formats the summary of the simulation (parameters and results) and offers to download the summary as a text file.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>the summary will be downloaded in file_name</p> required <code>do_estimates</code> <code>bool</code> <p>if True, the two estimators were run and we also give the estimation results</p> required <code>pars_res</code> <code>Any</code> <p>a tuple with what we need to format the summary</p> required <p>Returns:</p> Type Description <code>None</code> <p>nothing</p> Source code in <code>cupid_matching/cupid_streamlit_utils.py</code> <pre><code>def download_parameters_results(\n    file_name: str, do_estimates: bool, pars_res: Any\n) -&gt; None:\n    \"\"\"formats the summary of the simulation (parameters and results) and offers to download\n    the summary as a text file.\n\n    Args:\n        file_name: the summary will be downloaded in file_name\n        do_estimates: if True, the two estimators were run and we also give the estimation results\n        pars_res: a tuple with what we need to format the summary\n\n    Returns:\n        nothing\n    \"\"\"\n    if do_estimates:\n        (\n            n_households,\n            ncat_men,\n            ncat_women,\n            proportion_men,\n            scenario_men,\n            scenario_women,\n            true_coeffs,\n            coeff_names,\n            muxy_sim,\n            mux0_sim,\n            mu0y_sim,\n            n_sim,\n            m_sim,\n            df_mde,\n            mde_test_results,\n            df_poisson,\n            df_u_estimates,\n            df_v_estimates,\n        ) = pars_res\n        n_sim = cast(np.ndarray, n_sim)\n        m_sim = cast(np.ndarray, m_sim)\n        muxy_sim = cast(np.ndarray, muxy_sim)\n        mux0_sim = cast(np.ndarray, mux0_sim)\n        mu0y_sim = cast(np.ndarray, mu0y_sim)\n        results_str = (\n            f\"You chose a model with {ncat_men} types of men and {ncat_women} types of\"\n            \" women,\\n\"\n        )\n        results_str += (\n            f\"   with the number of men {scenario_men} and a number of wwomen\"\n            f\" {scenario_women},\\n\"\n        )\n        results_str += (\n            f\"    and {n_households} households with a proportion of\"\n            f\" {100 * proportion_men:.1f} percent of men.\\n\\n\"\n        )\n        results_str += \"The numbers of men in each category are:\\n\"\n        for x in range(ncat_men):\n            results_str += f\"{x + 1}: {n_sim[x]: d}\\n\"\n        results_str += \"\\n  the numbers of women in each category are:\\n\"\n        for y in range(ncat_women):\n            results_str += f\"{y + 1}: {m_sim[y]: d}\\n\"\n        results_str += \"\\nYou chose the following coefficients:\\n\"\n        for coeff, value in zip(coeff_names, true_coeffs, strict=True):\n            results_str += f\"{coeff}:  {value: &gt;10.3f}\\n\"\n        results_str += \"\\n\\n\"\n        results_str += \"This gives the following numbers of marriages:\\n\"\n        for x in range(ncat_men):\n            for y in range(ncat_women):\n                results_str += f\"{muxy_sim[x, y]: d}   \"\n            results_str += \"\\n\"\n        results_str += \"\\n\\n\"\n        results_str += \"The numbers of single men are:\\n\"\n        for x in range(ncat_men):\n            results_str += f\"{x + 1}: {mux0_sim[x]: d}\\n\"\n        results_str += \"\\n\\n\"\n        results_str += \"The numbers of single women are:\\n\"\n        for y in range(ncat_women):\n            results_str += f\"{y + 1}: {mu0y_sim[y]: d}\\n\"\n        results_str += \"\\n\\n Minimum distance estimation gives\\n\"\n        results_str += df_mde.to_string()\n        specif_test_ndf, specif_test_stat, specif_test_pval = mde_test_results\n        results_str += (\n            f\"\\n\\nSpecification test statistic: chi2({specif_test_ndf}) =\"\n            f\" {specif_test_stat}\\n\"\n        )\n        results_str += f\"     with  p-value {specif_test_pval}\\n\\n\"\n        results_str += \"\\n\\n Poisson-GLM estimation gives\\n\"\n        results_str += df_poisson.to_string()\n        results_str += \"\\n\\n  the expected utilities of men are:\\n\"\n        results_str += df_u_estimates.to_string()\n        results_str += \"\\n\\n  the expected utilities of women are:\\n\"\n        results_str += df_v_estimates.to_string()\n    else:\n        ncat_men, ncat_women, n_sim, m_sim, Phi, muxy_sim, mux0_sim, mu0y_sim = pars_res\n        n_sim = cast(np.ndarray, n_sim)\n        m_sim = cast(np.ndarray, m_sim)\n        muxy_sim = cast(np.ndarray, muxy_sim)\n        mux0_sim = cast(np.ndarray, mux0_sim)\n        mu0y_sim = cast(np.ndarray, mu0y_sim)\n        results_str = (\n            f\"You chose a model with {ncat_men} types of men and {ncat_women} types of\"\n            \" women;\\n\"\n        )\n        results_str += \"\\n  the numbers of men in each category are:\\n\"\n        for x in range(ncat_men):\n            results_str += f\"{x + 1}: {n_sim[x]: d}\\n\"\n        results_str += \"\\n  the numbers of women in each category are:\\n\"\n        for y in range(ncat_women):\n            results_str += f\"{y + 1}: {m_sim[y]: d}\\n\"\n        results_str += \"\\nYou chose the following joint surplus matrix:\\n\"\n        for x in range(ncat_men):\n            for y in range(ncat_women):\n                results_str += f\"{Phi[x, y]: 10.2f} \"\n            results_str += \"\\n\"\n        results_str += \"\\n\\n\"\n        results_str += \"This gives the following numbers of marriages:\\n\"\n        for x in range(ncat_men):\n            for y in range(ncat_women):\n                results_str += f\"{muxy_sim[x, y]: d}   \"\n            results_str += \"\\n\"\n        results_str += \"\\n\\n\"\n        results_str += \"The numbers of single men are:\\n\"\n        for x in range(ncat_men):\n            results_str += f\"{x + 1}: {mux0_sim[x]: d}\\n\"\n        results_str += \"\\n\\n\"\n        results_str += \"The numbers of single women are:\\n\"\n        for y in range(ncat_women):\n            results_str += f\"{y + 1}: {mu0y_sim[y]: d}\\n\"\n\n    _ = st.download_button(\n        label=f\"Download summary to {file_name}\",\n        data=results_str,\n        file_name=f\"{file_name}\",\n        mime=\"text/csv\",\n    )\n</code></pre>"},{"location":"cupid_streamlit_utils/#cupid_matching.cupid_streamlit_utils.make_margins","title":"<code>make_margins(n, ncat, scenario='Constant')</code>","text":"<p>generates the numbers by type on one side of the market</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>float</code> <p>the total number of individuals on that side of the market</p> required <code>ncat</code> <code>int</code> <p>the number of types on that side of the market</p> required <code>scenario</code> <code>str</code> <p>\"Constant\", \"Increasing\", or \"Decreasing\" numbers as a function of type</p> <code>'Constant'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>the numbers by type on this side</p> Source code in <code>cupid_matching/cupid_streamlit_utils.py</code> <pre><code>def make_margins(n: float, ncat: int, scenario: str = \"Constant\") -&gt; np.ndarray:\n    \"\"\"generates the numbers by type on one side of the market\n\n    Args:\n        n: the total number of individuals on that side of the market\n        ncat: the number of types on that side of the market\n        scenario: \"Constant\", \"Increasing\", or \"Decreasing\" numbers as a function of type\n\n    Returns:\n        the numbers by type on this side\n    \"\"\"\n    n_constant = n / ncat\n    if scenario == \"Constant\":\n        n_types = np.full(ncat, n_constant)\n        return n_types\n    elif scenario == \"Increasing\":\n        lambda_val = pow(2.0, 1.0 / (ncat - 1))\n    elif scenario == \"Decreasing\":\n        lambda_val = pow(2.0, -1.0 / (ncat - 1))\n    else:\n        bs_error_abort(f\"Unknown scenario {scenario}\")\n    n_types = _make_profile(lambda_val, n, ncat)\n    return n_types\n</code></pre>"},{"location":"cupid_streamlit_utils/#cupid_matching.cupid_streamlit_utils.plot_heatmap","title":"<code>plot_heatmap(mat, str_format, str_tit=None)</code>","text":"<p>Plots a heatmap of the matrix</p> <p>Parameters:</p> Name Type Description Default <code>mat</code> <code>ndarray</code> <p>the matrix to plot</p> required <code>str_tit</code> <code>str | None</code> <p>a title, if any</p> <code>None</code> <p>Returns:</p> Type Description <code>LayerChart</code> <p>the heatmap</p> Source code in <code>cupid_matching/cupid_streamlit_utils.py</code> <pre><code>def plot_heatmap(\n    mat: np.ndarray, str_format: str, str_tit: str | None = None\n) -&gt; LayerChart:\n    \"\"\"Plots a heatmap of the matrix\n\n    Args:\n        mat: the matrix to plot\n        str_tit: a title, if any\n\n    Returns:\n        the heatmap\n    \"\"\"\n    ncat_men, ncat_women = check_matrix(mat)\n    mat_arr = np.empty((mat.size, 4), dtype=int)\n    imat = np.round(mat)\n    mat_min = np.min(imat)\n    i = 0\n    for ix in range(ncat_men):\n        for iy in range(ncat_women):\n            m = imat[ix, iy]\n            s = m - mat_min + 1\n            mat_arr[i, :] = np.array([ix, iy, m, s])\n            i += 1\n\n    mat_df = pd.DataFrame(mat_arr, columns=[\"Men\", \"Women\", \"Value\", \"Size\"])\n    mat_df = mat_df.astype(\n        dtype={\"Men\": int, \"Women\": int, \"Value\": int, \"Size\": float}\n    )\n    base = alt.Chart(mat_df).encode(x=\"Men:O\", y=alt.Y(\"Women:O\", sort=\"descending\"))\n    mat_map = base.mark_circle(opacity=0.4).encode(\n        size=alt.Size(\"Size:Q\", legend=None, scale=alt.Scale(range=[1000, 10000])),\n        # color=alt.Color(\"Value:Q\"),\n        # tooltip=alt.Tooltip('Value', format=\".2f\")\n    )\n    text = base.mark_text(baseline=\"middle\", fontSize=16).encode(\n        text=alt.Text(\"Value:Q\", format=str_format),\n    )\n    if str_tit is None:\n        both = (mat_map + text).properties(width=500, height=500)\n    else:\n        both = (mat_map + text).properties(title=str_tit, width=400, height=400)\n    return cast(LayerChart, both)\n</code></pre>"},{"location":"cupid_streamlit_utils/#cupid_matching.cupid_streamlit_utils.plot_matching","title":"<code>plot_matching(mus)</code>","text":"<p>generates the complete plot of matching patterns</p> <p>Parameters:</p> Name Type Description Default <code>mus</code> <code>Matching</code> <p>the matching patterns</p> required <p>Returns:</p> Type Description <code>ConcatChart</code> <p>the plot</p> Source code in <code>cupid_matching/cupid_streamlit_utils.py</code> <pre><code>def plot_matching(mus: Matching) -&gt; ConcatChart:\n    \"\"\"generates the complete plot of matching patterns\n\n    Args:\n        mus: the matching patterns\n\n    Returns:\n        the plot\n    \"\"\"\n    muxy, mux0, mu0y, _, _ = mus.unpack()\n    plotxy = plot_heatmap(muxy, \"d\", str_tit=\"Marriages\")\n    plotsingles = _plot_bars(mux0, mu0y)\n    return cast(ConcatChart, plotxy | plotsingles)\n</code></pre>"},{"location":"cupid_streamlit_utils/#cupid_matching.cupid_streamlit_utils.table_estimates","title":"<code>table_estimates(coeff_names, true_coeffs, estimates, stderrs)</code>","text":"<p>returns a table of the estimates</p> <p>Parameters:</p> Name Type Description Default <code>coeff_names</code> <code>list[str]</code> <p>the names of the coefficients</p> required <code>true_coeffs</code> <code>ndarray</code> <p>the true values of the coefficients</p> required <code>estimates</code> <code>ndarray</code> <p>the estimated values of the coefficients</p> required <code>stderrs</code> <code>ndarray</code> <p>the standard errors of the estimates</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>the table</p> Source code in <code>cupid_matching/cupid_streamlit_utils.py</code> <pre><code>def table_estimates(\n    coeff_names: list[str],\n    true_coeffs: np.ndarray,\n    estimates: np.ndarray,\n    stderrs: np.ndarray,\n) -&gt; pd.DataFrame:\n    \"\"\"returns a table of the estimates\n\n    Args:\n        coeff_names: the names of the coefficients\n        true_coeffs: the true values of the coefficients\n        estimates: the estimated values of the coefficients\n        stderrs: the standard errors of the estimates\n\n    Returns:\n        the table\n    \"\"\"\n    st.write(\"The coefficients are:\")\n    df_coeffs_estimates = pd.DataFrame(\n        {\n            \"True\": true_coeffs,\n            \"Estimated\": estimates,\n            \"Standard errors\": stderrs,\n        },\n        index=coeff_names,\n    )\n    return df_coeffs_estimates\n</code></pre>"},{"location":"entropy/","title":"<code>entropy</code> module","text":"<p>Entropies and their derivatives.</p>"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianComponents","title":"<code>EntropyHessianComponents = tuple[ThreeArrays, TwoArrays]</code>  <code>module-attribute</code>","text":"<p>combines the tuples of the values of the components of the hessians.</p>"},{"location":"entropy/#cupid_matching.entropy.EntropyHessians","title":"<code>EntropyHessians = tuple[EntropyHessianMuMu, EntropyHessianMuR]</code>  <code>module-attribute</code>","text":"<p>combines the hessian functions.</p>"},{"location":"entropy/#cupid_matching.entropy.EntropyFunctions","title":"<code>EntropyFunctions</code>  <code>dataclass</code>","text":"<p>Defines the entropy used, via the derivative \\(e_0 + e \\cdot \\alpha\\)</p> <p>Attributes:</p> Name Type Description <code>e0_fun</code> <code>MatchingFunction</code> <p>required</p> <code>parameter_dependent</code> <code>bool</code> <p>if <code>True</code>, the entropy depends on parameters. Defaults to <code>False</code></p> <code>e_fun</code> <code>MatchingFunction | None</code> <p>only in entropies that depend on parameters. Defaults to <code>None</code></p> <code>hessian</code> <code>str | None</code> <p>defaults to <code>\"numeric\"</code> * if <code>\"provided\"</code>, we provide the hessian of the entropy. * if <code>\"numerical\"</code>, it is compute_d by central differences.</p> <code>e0_derivative</code> <code>EntropyHessians | None</code> <p>the derivative of <code>e0_fun</code>, if available. Defaults to <code>None</code></p> <code>e_derivative</code> <code>EntropyHessians | None</code> <p>the derivative of <code>e_fun</code>, if available. Defaults to <code>None</code></p> <code>additional_parameters</code> <code>list | None</code> <p>additional parameters that define the distribution of errors. Defaults to <code>None</code></p> <code>description</code> <code>str | None</code> <p>some text describing the model. Defaults to <code>None</code></p> <p>Examples:</p> <p>See <code>entropy_choo_siow</code> in <code>choo_siow.py</code></p> Source code in <code>cupid_matching/entropy.py</code> <pre><code>@dataclass\nclass EntropyFunctions:\n    \"\"\"Defines the entropy used, via the derivative $e_0 + e \\\\cdot \\\\alpha$\n\n    Attributes:\n        e0_fun: required\n        parameter_dependent:  if `True`, the entropy depends on parameters.\n            Defaults to `False`\n        e_fun: only in entropies that depend on parameters.\n            Defaults to `None`\n        hessian: defaults to `\"numeric\"`\n            * if `\"provided\"`, we provide the hessian of the entropy.\n            * if `\"numerical\"`, it is compute_d by central differences.\n        e0_derivative: the derivative of `e0_fun`, if available.\n            Defaults to `None`\n        e_derivative: the derivative of `e_fun`, if available.\n            Defaults to `None`\n        additional_parameters: additional parameters\n            that define the distribution of errors.\n            Defaults to `None`\n        description: some text describing the model.\n            Defaults to `None`\n\n    Examples:\n        See `entropy_choo_siow` in `choo_siow.py`\n    \"\"\"\n\n    e0_fun: MatchingFunction  # | MatchingFunctionParam\n    e0_derivative: EntropyHessians | None = None\n    additional_parameters: list | None = None\n    description: str | None = None\n    # e_fun: MatchingFunction | MatchingFunctionParam | None = None\n    e_fun: MatchingFunction | None = None\n    e_derivative: EntropyHessians | None = None\n    hessian: str | None = \"numerical\"\n    parameter_dependent: bool = False\n\n    def __post_init__(self):\n        if (\n            (not self.parameter_dependent)\n            and self.hessian == \"provided\"\n            and self.e0_derivative is None\n        ):\n            bs_error_abort(\n                \"You claim to provide the hessian \"\n                + \"but you did not provide the e0_derivative.\"\n            )\n        if self.parameter_dependent:\n            if self.e_fun is None:\n                bs_error_abort(\n                    \"Your entropy is parameter dependent \"\n                    + \" but you did not provide the e_fun.\"\n                )\n            if self.hessian == \"provided\" and self.e_derivative is None:\n                bs_error_abort(\n                    \"Your entropy is parameter dependent, \"\n                    + \"you claim to provide the hessian,\\n\"\n                    + \" but I do not see the e_derivative.\"\n                )\n</code></pre>"},{"location":"entropy/#cupid_matching.entropy.check_additional_parameters","title":"<code>check_additional_parameters(number_required, additional_parameters)</code>","text":"<p>checks that the correct number of additional parameters is passed in</p> <p>Parameters:</p> Name Type Description Default <code>number_required</code> <code>int</code> <p>number we want</p> required <code>additional_parameters</code> <code>list | None</code> <p>the list of additional parameters passed in, if any</p> required Source code in <code>cupid_matching/entropy.py</code> <pre><code>def check_additional_parameters(\n    number_required: int, additional_parameters: list | None\n) -&gt; None:\n    \"\"\"checks that the correct number of additional parameters is passed in\n\n    Args:\n        number_required: number we want\n        additional_parameters: the list of additional parameters passed in, if any\n    \"\"\"\n    if number_required == 0:\n        if additional_parameters is not None:\n            bs_error_abort(\"no additional parameters should be passed.\")\n    else:\n        if additional_parameters is None:\n            bs_error_abort(\"additional parameters should be passed.\")\n        additional_parameters = cast(list, additional_parameters)\n        if len(additional_parameters) != number_required:\n            bs_error_abort(\n                f\"additional parameters should be a list of {number_required} elements.\"\n            )\n</code></pre>"},{"location":"entropy/#cupid_matching.entropy.entropy_gradient","title":"<code>entropy_gradient(entropy, muhat, alpha=None, additional_parameters=None)</code>","text":"<p>Computes the derivative of the entropy wrt \\(\\mu\\)  at \\((\\mu, n, m, \\alpha, p)\\)</p> <p>Parameters:</p> Name Type Description Default <code>entropy</code> <code>EntropyFunctions</code> <p>the <code>EntropyFunctions</code> object</p> required <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>alpha</code> <code>ndarray | None</code> <p>a vector of parameters of the derivative of the entropy, if any</p> <code>None</code> <code>additional_parameters</code> <code>list | None</code> <p>a list of additional parameters <code>p</code>, if any</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>the derivative of the entropy wrt \\(\\mu\\)</p> <code>ndarray</code> <p>at \\((\\mu, n, m, \\alpha, p)\\).</p> Source code in <code>cupid_matching/entropy.py</code> <pre><code>def entropy_gradient(\n    entropy: EntropyFunctions,\n    muhat: Matching,\n    alpha: np.ndarray | None = None,\n    additional_parameters: list | None = None,\n) -&gt; np.ndarray:\n    \"\"\"Computes the derivative of the entropy wrt $\\\\mu$\n     at $(\\\\mu, n, m, \\\\alpha, p)$\n\n    Args:\n        entropy: the `EntropyFunctions` object\n        muhat: a Matching\n        alpha: a vector of parameters of the derivative of the entropy, if any\n        additional_parameters: a list of additional parameters `p`, if any\n\n    Returns:\n        the derivative of the entropy wrt $\\\\mu$\n        at $(\\\\mu, n, m, \\\\alpha, p)$.\n    \"\"\"\n    e0_vals = get_evals(entropy.e0_fun, muhat, additional_parameters)\n    parameter_dependent = entropy.parameter_dependent\n    if parameter_dependent:\n        if alpha is None:\n            bs_error_abort(\"alpha should be specified for this model\")\n        elif entropy.e_fun is None:\n            bs_error_abort(\"we should have an e_fun in this model\")\n        else:\n            e_vals = get_evals(entropy.e_fun, muhat, additional_parameters)\n        return cast(np.ndarray, e0_vals + e_vals @ alpha)\n    else:\n        return cast(np.ndarray, e0_vals)\n</code></pre>"},{"location":"entropy/#cupid_matching.entropy.fill_hessianMuMu_from_components","title":"<code>fill_hessianMuMu_from_components(hessian_components)</code>","text":"<p>Fills the hessian of the entropy wrt \\((\\mu,\\mu)\\)</p> <p>Parameters:</p> Name Type Description Default <code>hessian_components</code> <code>ThreeArrays</code> <p>the three components of the hessian</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the (XY,XY) matrix of the hessian</p> Source code in <code>cupid_matching/entropy.py</code> <pre><code>def fill_hessianMuMu_from_components(\n    hessian_components: ThreeArrays,\n) -&gt; np.ndarray:\n    \"\"\"Fills the hessian of the entropy wrt $(\\\\mu,\\\\mu)$\n\n    Args:\n        hessian_components: the three components of the hessian\n\n    Returns:\n        the (XY,XY) matrix of the hessian\n    \"\"\"\n    hess_x, hess_y, hess_xy = hessian_components\n    X, Y = hess_xy.shape\n    XY = X * Y\n    hessian = np.zeros((XY, XY))\n\n    i = 0\n    ix = 0\n    for x in range(X):\n        for y in range(Y):\n            hessian[i, ix : (ix + Y)] = hess_x[x, y, :]\n            slice_y = slice(y, XY, Y)\n            hessian[i, slice_y] = hess_y[x, y, :]\n            hessian[i, i] = hess_xy[x, y]\n            i += 1\n        ix += Y\n\n    return hessian\n</code></pre>"},{"location":"entropy/#cupid_matching.entropy.fill_hessianMuR_from_components","title":"<code>fill_hessianMuR_from_components(hessian_components)</code>","text":"<p>Fills the hessian of the entropy wrt \\((\\mu,(n,m))\\)</p> <p>Parameters:</p> Name Type Description Default <code>hessian_components</code> <code>TwoArrays</code> <p>the two components of the hessian</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the (XY,X+Y) matrix of the hessian</p> Source code in <code>cupid_matching/entropy.py</code> <pre><code>def fill_hessianMuR_from_components(\n    hessian_components: TwoArrays,\n) -&gt; np.ndarray:\n    \"\"\"Fills the hessian of the entropy wrt $(\\\\mu,(n,m))$\n\n    Args:\n        hessian_components: the two components of the hessian\n\n    Returns:\n        the (XY,X+Y) matrix of the hessian\n    \"\"\"\n    hess_nx, hess_my = hessian_components\n    X, Y = hess_nx.shape[:2]\n    XY = X * Y\n    hessian = np.zeros((XY, X + Y))\n\n    i = 0\n    for x in range(X):\n        iy = X\n        for y in range(Y):\n            hessian[i, x] = hess_nx[x, y]\n            hessian[i, iy] = hess_my[x, y]\n            i += 1\n            iy += 1\n\n    return hessian\n</code></pre>"},{"location":"entropy/#cupid_matching.entropy.numeric_hessian","title":"<code>numeric_hessian(entropy, muhat, alpha=None, additional_parameters=None)</code>","text":"<p>Evaluates numerically the components of the hessians of the entropy wrt \\((\\mu,\\mu)\\) and \\((\\mu,(n,m))\\)</p> <p>Parameters:</p> Name Type Description Default <code>entropy</code> <code>EntropyFunctions</code> <p>the <code>EntropyFunctions</code> object</p> required <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>alpha</code> <code>ndarray | None</code> <p>a vector of parameters of the derivative of the entropy, if any</p> <code>None</code> <code>additional_parameters</code> <code>list | None</code> <p>a list of additional parameters, if any</p> <code>None</code> <p>Returns:</p> Type Description <code>EntropyHessianComponents</code> <p>the hessians of the entropy wrt \\((\\mu,\\mu)\\) and \\((\\mu,(n,m))\\).</p> Source code in <code>cupid_matching/entropy.py</code> <pre><code>def numeric_hessian(\n    entropy: EntropyFunctions,\n    muhat: Matching,\n    alpha: np.ndarray | None = None,\n    additional_parameters: list | None = None,\n) -&gt; EntropyHessianComponents:\n    \"\"\"Evaluates numerically the components of the hessians of the entropy\n    wrt $(\\\\mu,\\\\mu)$ and $(\\\\mu,(n,m))$\n\n    Args:\n        entropy: the `EntropyFunctions` object\n        muhat: a Matching\n        alpha: a vector of parameters of the derivative of the entropy, if any\n        additional_parameters: a list of additional parameters, if any\n\n    Returns:\n        the hessians of the entropy wrt $(\\\\mu,\\\\mu)$ and $(\\\\mu,(n,m))$.\n    \"\"\"\n    parameter_dependent = entropy.parameter_dependent\n    # we create a derivative of entropy that is only a function of the Matching and the additional parameters\n    if not parameter_dependent:\n        entropy_deriv = partial(\n            entropy_gradient,\n            entropy,\n        )\n    else:\n        entropy_deriv = partial(\n            entropy_gradient,\n            entropy,\n            alpha=alpha,\n        )\n    muxyhat, _, _, n, m = muhat.unpack()\n    X, Y = muxyhat.shape\n\n    # make sure everything is floating point\n    muxyhatf = muxyhat.copy().astype(float)\n    nf = n.copy().astype(float)\n    mf = m.copy().astype(float)\n    muhatf = Matching(muxyhatf, nf, mf)\n\n    # start with the hessian wrt (mu, mu)\n    hessian_x = np.zeros((X, Y, Y))\n    hessian_y = np.zeros((X, Y, X))\n    hessian_xy = np.zeros((X, Y))\n    for x in range(X):\n        for y in range(Y):\n            for t in range(Y):\n                hessian_x[x, y, t] = _numeric_component(\n                    muhatf,\n                    x,\n                    y,\n                    t,\n                    entropy_deriv,\n                    additional_parameters,\n                    direction=\"y\",\n                )\n            for z in range(X):\n                hessian_y[x, y, z] = _numeric_component(\n                    muhatf, x, y, z, entropy_deriv, additional_parameters, direction=\"x\"\n                )\n            hessian_xy[x, y] = _numeric_component(\n                muhatf, x, y, 0, entropy_deriv, additional_parameters, direction=\"d\"\n            )\n    components_mumu = (hessian_x, hessian_y, hessian_xy)\n\n    # now the hessian wrt (mu, r)\n    hessian_n = np.zeros((X, Y))\n    hessian_m = np.zeros((X, Y))\n    for x in range(X):\n        for y in range(Y):\n            hessian_n[x, y] = _numeric_component(\n                muhatf, x, y, 0, entropy_deriv, additional_parameters, direction=\"n\"\n            )\n            hessian_m[x, y] = _numeric_component(\n                muhatf, x, y, 0, entropy_deriv, additional_parameters, direction=\"m\"\n            )\n\n    components_mur = (hessian_n, hessian_m)\n\n    return components_mumu, components_mur\n</code></pre>"},{"location":"example_choo_siow/","title":"<code>examples/example_choosiow</code> module","text":"<p>example using the Choo and Siow homoskedastic model</p>"},{"location":"example_choo_siow/#cupid_matching.examples.example_choo_siow.create_choosiow_population","title":"<code>create_choosiow_population(X, Y, K, std_betas)</code>","text":"<p>we simulate a Choo and Siow population with equal numbers of men and women of each type and random bases functions and coefficients</p> <pre><code>Args:\n X: number of types of men\n Y: number of types of women\n K: random basis functions\n std_betas: the coefficients are drawn from a centered normal\n             with this standard deviation\n\nReturns:\n    a `ChooSiowPrimitives` instance, the basis functions, and the coefficients\n</code></pre> Source code in <code>cupid_matching/examples/example_choo_siow.py</code> <pre><code>def create_choosiow_population(\n    X: int, Y: int, K: int, std_betas: float\n) -&gt; tuple[ChooSiowPrimitives, np.ndarray, np.ndarray]:\n    \"\"\"\n    we simulate a Choo and Siow population\n    with equal numbers of men and women of each type\n    and random bases functions and coefficients\n\n        Args:\n         X: number of types of men\n         Y: number of types of women\n         K: random basis functions\n         std_betas: the coefficients are drawn from a centered normal\n                     with this standard deviation\n\n        Returns:\n            a `ChooSiowPrimitives` instance, the basis functions, and the coefficients\n    \"\"\"\n    betas_true = std_betas * np.random.randn(K)\n    phi_bases = np.random.randn(X, Y, K)\n    n = np.ones(X)\n    m = np.ones(Y)\n    Phi = phi_bases @ betas_true\n    choo_siow_instance = ChooSiowPrimitives(Phi, n, m)\n    return choo_siow_instance, phi_bases, betas_true\n</code></pre>"},{"location":"example_choo_siow/#cupid_matching.examples.example_choo_siow.demo_choo_siow","title":"<code>demo_choo_siow(n_households, X, Y, K, std_betas=1.0)</code>","text":"<p>run four MDE estimators and the Poisson estimator on randomly generated data</p> <p>Parameters:</p> Name Type Description Default <code>n_households</code> <code>int</code> <p>number of households</p> required <code>X</code> <code>int</code> <p>number of types of men</p> required <code>Y</code> <code>int</code> <p>number of types of women</p> required <code>K</code> <code>int</code> <p>number of basis functions</p> required <code>std_betas</code> <code>float</code> <p>the standard errors of their coefficients</p> <code>1.0</code> <p>Returns:</p> Type Description <code>tuple[float, float, float, float, float]</code> <p>the discrepancies of the five estimators</p> Source code in <code>cupid_matching/examples/example_choo_siow.py</code> <pre><code>def demo_choo_siow(\n    n_households: int, X: int, Y: int, K: int, std_betas: float = 1.0\n) -&gt; tuple[float, float, float, float, float]:\n    \"\"\"run four MDE estimators and the Poisson estimator\n    on randomly generated data\n\n    Args:\n        n_households: number of households\n        X: number of types of men\n        Y: number of types of women\n        K: number of basis functions\n        std_betas: the standard errors of their coefficients\n\n    Returns:\n        the discrepancies of the five estimators\n    \"\"\"\n    choo_siow_instance, phi_bases, betas_true = create_choosiow_population(\n        X, Y, K, std_betas\n    )\n    mus_sim = choo_siow_instance.simulate(n_households)\n\n    # we estimate using four variants of the minimum distance estimator\n    mde_discrepancy = mde_estimate(\n        mus_sim,\n        phi_bases,\n        betas_true,\n        entropy_choo_siow,\n        title=\"RESULTS FOR MDE WITH ANALYTICAL GRADIENT\",\n    )\n    mde_discrepancy_numeric = mde_estimate(\n        mus_sim,\n        phi_bases,\n        betas_true,\n        entropy_choo_siow_numeric,\n        title=\"RESULTS FOR MDE WITH NUMERICAL GRADIENT\",\n    )\n    mde_discrepancy_corrected = mde_estimate(\n        mus_sim,\n        phi_bases,\n        betas_true,\n        entropy_choo_siow_corrected,\n        title=\"RESULTS FOR THE CORRECTED MDE WITH ANALYTICAL GRADIENT\",\n    )\n    mde_discrepancy_corrected_numeric = mde_estimate(\n        mus_sim,\n        phi_bases,\n        betas_true,\n        entropy_choo_siow_corrected_numeric,\n        title=\"RESULTS FOR THE CORRECTED MDE WITH NUMERICAL GRADIENT\",\n    )\n\n    # we also estimate using Poisson GLM\n    print_stars(\"    RESULTS FOR POISSON   \")\n    poisson_results = choo_siow_poisson_glm(mus_sim, phi_bases)\n    _, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack()\n    poisson_discrepancy = poisson_results.print_results(\n        betas_true,\n        u_true=-np.log(mux0_sim / n_sim),\n        v_true=-np.log(mu0y_sim / m_sim),\n    )\n    return (\n        mde_discrepancy,\n        mde_discrepancy_numeric,\n        mde_discrepancy_corrected,\n        mde_discrepancy_corrected_numeric,\n        cast(float, poisson_discrepancy),\n    )\n</code></pre>"},{"location":"example_choo_siow/#cupid_matching.examples.example_choo_siow.mde_estimate","title":"<code>mde_estimate(mus_sim, phi_bases, betas_true, entropy, no_singles=False, title=None, verbose=False)</code>","text":"<p>we estimate the parameters using the minimum distance estimator</p> <p>Parameters:</p> Name Type Description Default <code>mus_sim</code> <code>Matching</code> <p>a Choo and Siow Matching</p> required <code>phi_bases</code> <code>ndarray</code> <p>the basis functions</p> required <code>betas_true</code> <code>ndarray</code> <p>their true coefficients</p> required <code>entropy</code> <code>EntropyFunctions</code> <p>the entropy functions we use</p> required <code>no_singles</code> <code>bool</code> <p>if <code>True</code>, we use the no-singles version of the model</p> <code>False</code> <code>title</code> <code>str | None</code> <p>the name of the estimator</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>the largest absolute difference between the true and estimated coefficients</p> Source code in <code>cupid_matching/examples/example_choo_siow.py</code> <pre><code>def mde_estimate(\n    mus_sim: Matching,\n    phi_bases: np.ndarray,\n    betas_true: np.ndarray,\n    entropy: EntropyFunctions,\n    no_singles: bool = False,\n    title: str | None = None,\n    verbose: bool = False,\n) -&gt; float:\n    \"\"\"we estimate the parameters using the minimum distance estimator\n\n    Args:\n        mus_sim: a Choo and Siow Matching\n        phi_bases: the basis functions\n        betas_true: their true coefficients\n        entropy: the entropy functions we use\n        no_singles: if `True`, we use the no-singles version of the model\n        title: the name of the estimator\n\n    Returns:\n        the largest absolute difference between the true and estimated coefficients\n    \"\"\"\n    print_stars(f\"    {title}\")\n    mde_results = estimate_semilinear_mde(\n        mus_sim,\n        phi_bases,\n        entropy,\n        no_singles=no_singles,\n        verbose=verbose,\n    )\n    mde_discrepancy = mde_results.print_results(true_coeffs=betas_true)\n    return cast(float, mde_discrepancy)\n</code></pre>"},{"location":"example_choo_siow_no_singles/","title":"<code>examples/example_choo_siow_no_singles</code> module","text":"<p>example using the Choo and Siow homoskedastic model without singles</p>"},{"location":"example_choo_siow_no_singles/#cupid_matching.examples.example_choo_siow_no_singles.create_choosiow_no_singles_population","title":"<code>create_choosiow_no_singles_population(X, Y, K, std_betas)</code>","text":"<p>we simulate a Choo and Siow population with equal numbers of men and women of each type and random bases functions and coefficients</p> <pre><code>Args:\n X: number of types of men\n Y: number of types of women\n K: random basis functions\n std_betas: the coefficients are drawn from a centered normal\n             with this standard deviation\n\nReturns:\n    a `ChooSiowPrimitivesNoSingles` instance, the basis functions, and the coefficients\n</code></pre> Source code in <code>cupid_matching/examples/example_choo_siow_no_singles.py</code> <pre><code>def create_choosiow_no_singles_population(\n    X: int, Y: int, K: int, std_betas: float\n) -&gt; tuple[ChooSiowPrimitives, np.ndarray, np.ndarray]:\n    \"\"\"\n    we simulate a Choo and Siow population\n    with equal numbers of men and women of each type\n    and random bases functions and coefficients\n\n        Args:\n         X: number of types of men\n         Y: number of types of women\n         K: random basis functions\n         std_betas: the coefficients are drawn from a centered normal\n                     with this standard deviation\n\n        Returns:\n            a `ChooSiowPrimitivesNoSingles` instance, the basis functions, and the coefficients\n    \"\"\"\n    betas_true = std_betas * np.random.randn(K)\n    phi_bases = np.random.randn(X, Y, K)\n    n = np.ones(X)\n    m = np.full(Y, X / Y)  # we need as many women as men overall\n    Phi = phi_bases @ betas_true\n    choo_siow_instance = ChooSiowPrimitives(Phi, n, m)\n    return choo_siow_instance, phi_bases, betas_true\n</code></pre>"},{"location":"example_choo_siow_no_singles/#cupid_matching.examples.example_choo_siow_no_singles.demo_choo_siow_no_singles","title":"<code>demo_choo_siow_no_singles(n_households, X, Y, K, std_betas=1.0)</code>","text":"<p>run four MDE estimators and the Poisson estimator on randomly generated data</p> <p>Parameters:</p> Name Type Description Default <code>n_households</code> <code>int</code> <p>number of households</p> required <code>X</code> <code>int</code> <p>number of types of men</p> required <code>Y</code> <code>int</code> <p>number of types of women</p> required <code>K</code> <code>int</code> <p>number of basis functions</p> required <code>std_betas</code> <code>float</code> <p>the standard errors of their coefficients</p> <code>1.0</code> <p>Returns:</p> Type Description <code>tuple[float, float, float, float, float]</code> <p>the discrepancies of the five estimators</p> Source code in <code>cupid_matching/examples/example_choo_siow_no_singles.py</code> <pre><code>def demo_choo_siow_no_singles(\n    n_households: int, X: int, Y: int, K: int, std_betas: float = 1.0\n) -&gt; tuple[float, float, float, float, float]:\n    \"\"\"run four MDE estimators and the Poisson estimator\n    on randomly generated data\n\n    Args:\n        n_households: number of households\n        X: number of types of men\n        Y: number of types of women\n        K: number of basis functions\n        std_betas: the standard errors of their coefficients\n\n    Returns:\n        the discrepancies of the five estimators\n    \"\"\"\n    choo_siow_instance, phi_bases, betas_true = create_choosiow_no_singles_population(\n        X, Y, K, std_betas\n    )\n    mus_sim = choo_siow_instance.simulate(n_households)\n\n    # we estimate using four variants of the minimum distance estimator\n    mde_discrepancy = mde_estimate(\n        mus_sim,\n        phi_bases,\n        betas_true,\n        entropy_choo_siow_no_singles,\n        no_singles=True,\n        title=\"RESULTS FOR MDE WITH ANALYTICAL GRADIENT\",\n    )\n    mde_discrepancy_numeric = mde_estimate(\n        mus_sim,\n        phi_bases,\n        betas_true,\n        entropy_choo_siow_no_singles_numeric,\n        no_singles=True,\n        title=\"RESULTS FOR MDE WITH NUMERICAL GRADIENT\",\n    )\n    mde_discrepancy_corrected = mde_estimate(\n        mus_sim,\n        phi_bases,\n        betas_true,\n        entropy_choo_siow_no_singles_corrected,\n        no_singles=True,\n        title=\"RESULTS FOR THE CORRECTED MDE WITH ANALYTICAL GRADIENT\",\n    )\n    mde_discrepancy_corrected_numeric = mde_estimate(\n        mus_sim,\n        phi_bases,\n        betas_true,\n        entropy_choo_siow_no_singles_corrected_numeric,\n        no_singles=True,\n        title=\"RESULTS FOR THE CORRECTED MDE WITH NUMERICAL GRADIENT\",\n    )\n\n    # we also estimate using Poisson GLM\n    print_stars(\"    RESULTS FOR POISSON   \")\n    poisson_results = choo_siow_poisson_glm(mus_sim, phi_bases, no_singles=True)\n    _, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack()\n    # we normalize u_1 = 0\n    u_true = -np.log(mux0_sim / n_sim)\n    v_true = -np.log(mu0y_sim / m_sim) + u_true[0]\n    u_true -= u_true[0]\n    poisson_discrepancy = poisson_results.print_results(\n        betas_true,\n        u_true,\n        v_true,\n    )\n    print(\"\\n   (we normalized the utility u_1 at 0)\\n\")\n    return (\n        mde_discrepancy,\n        mde_discrepancy_numeric,\n        mde_discrepancy_corrected,\n        mde_discrepancy_corrected_numeric,\n        cast(float, poisson_discrepancy),\n    )\n</code></pre>"},{"location":"example_nested_logit/","title":"<code>examples/example_nestedlogit</code> module","text":"<p>example using a simple two-layer nested logit model One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters.</p>"},{"location":"example_nested_logit/#cupid_matching.examples.example_nested_logit.create_nestedlogit_population","title":"<code>create_nestedlogit_population(X, Y, K, std_alphas=0.5, std_betas=1.0)</code>","text":"<p>we simulate a nested logit population with equal numbers of men and women of each type and random bases dunctions and coefficients</p> <pre><code>Args:\n X: number of types of men\n Y: number of types of women\n K: random basis functions\n std_alphas: the nest parameters are drawn from a U[0, std_alphas] distribution\n std_betas: the coefficients of the bases are drawn from a centered normal\n             with this standard deviation\n\nReturns:\n    a NestedLogitPrimitives instance, the basis functions, the true coefficients,\n    and the entropy functions\n</code></pre> Source code in <code>cupid_matching/examples/example_nested_logit.py</code> <pre><code>def create_nestedlogit_population(\n    X: int,\n    Y: int,\n    K: int,\n    std_alphas: float = 0.5,\n    std_betas: float = 1.0,\n) -&gt; tuple[\n    NestedLogitPrimitives,\n    np.ndarray,\n    np.ndarray,\n    EntropyFunctions,\n    EntropyFunctions,\n]:\n    \"\"\"\n    we simulate a nested logit population\n    with equal numbers of men and women of each type\n    and random bases dunctions and coefficients\n\n        Args:\n         X: number of types of men\n         Y: number of types of women\n         K: random basis functions\n         std_alphas: the nest parameters are drawn from a U[0, std_alphas] distribution\n         std_betas: the coefficients of the bases are drawn from a centered normal\n                     with this standard deviation\n\n        Returns:\n            a NestedLogitPrimitives instance, the basis functions, the true coefficients,\n            and the entropy functions\n    \"\"\"\n    X, Y, K = 10, 12, 5\n    nests_for_each_x = [\n        list(range(1, Y // 2 + 1)),\n        list(range(Y // 2 + 1, Y + 1)),\n    ]\n    nests_for_each_y = [\n        list(range(1, X // 2 + 1)),\n        list(range(X // 2 + 1, X + 1)),\n    ]\n\n    n = np.ones(X)\n    m = np.ones(Y)\n    phi_bases = np.random.randn(X, Y, K)\n\n    (\n        entropy_nested_logit,\n        entropy_nested_logit_numeric,\n    ) = setup_standard_nested_logit(nests_for_each_x, nests_for_each_y)\n    n_rhos, n_deltas = len(nests_for_each_x), len(nests_for_each_y)\n    n_alphas = n_rhos + n_deltas\n\n    betas_true = std_betas * np.random.randn(K)\n    alphas_true = std_alphas * np.random.uniform(size=n_alphas)\n\n    Phi = phi_bases @ betas_true\n    nested_logit_instance = NestedLogitPrimitives(\n        Phi, n, m, nests_for_each_x, nests_for_each_y, alphas_true\n    )\n    true_coeffs = np.concatenate((alphas_true, betas_true))\n    return (\n        nested_logit_instance,\n        phi_bases,\n        true_coeffs,\n        entropy_nested_logit,\n        entropy_nested_logit_numeric,\n    )\n</code></pre>"},{"location":"example_nested_logit/#cupid_matching.examples.example_nested_logit.mde_estimate","title":"<code>mde_estimate(mus_sim, phi_bases, true_coeffs, entropy, title)</code>","text":"<p>we estimate the parameters using the minimum distance estimator</p> <p>Parameters:</p> Name Type Description Default <code>mus_sim</code> <code>Matching</code> <p>a Choo and Siow Matching</p> required <code>phi_bases</code> <code>ndarray</code> <p>the basis functions</p> required <code>true_coeffs</code> <code>ndarray</code> <p>their true coefficients and  the nesting parameters</p> required <code>entropy</code> <code>EntropyFunctions</code> <p>the entropy functions we use</p> required <code>title</code> <code>str</code> <p>the name of the estimator</p> required <p>Returns:</p> Type Description <code>float</code> <p>the largest absolute difference between the true and estimated coefficients</p> Source code in <code>cupid_matching/examples/example_nested_logit.py</code> <pre><code>def mde_estimate(\n    mus_sim: Matching,\n    phi_bases: np.ndarray,\n    true_coeffs: np.ndarray,\n    entropy: EntropyFunctions,\n    title: str,\n) -&gt; float:\n    \"\"\"we estimate the parameters using the minimum distance estimator\n\n    Args:\n        mus_sim: a Choo and Siow Matching\n        phi_bases: the basis functions\n        true_coeffs: their true coefficients and  the nesting parameters\n        entropy: the entropy functions we use\n        title: the name of the estimator\n\n    Returns:\n        the largest absolute difference between the true and estimated coefficients\n    \"\"\"\n    print_stars(f\"    {title}\")\n    mde_results = estimate_semilinear_mde(\n        mus_sim,\n        phi_bases,\n        entropy,\n        additional_parameters=entropy.additional_parameters,\n    )\n    mde_discrepancy = mde_results.print_results(true_coeffs=true_coeffs)\n    return cast(float, mde_discrepancy)\n</code></pre>"},{"location":"ipfp_solvers/","title":"<code>ipfp_solvers</code> module","text":"<p>Implementations of the IPFP algorithm to solve for equilibrium and do comparative statics in several variants of the <code>Choo and Siow 2006 &lt;https://www.jstor.org/stable/10.1086/498585?seq=1&gt;</code>_ model:</p> <ul> <li>homoskedastic with singles (as in Choo and Siow 2006)</li> <li>homoskedastic without singles</li> <li>gender-heteroskedastic: with a scale parameter on the error term for women</li> <li>gender- and type-heteroskedastic: with a scale parameter on the error term    for each gender and type</li> <li>two-level nested logit, with nests and nest parameters that do not depend on the type,    and {0} as the first nest</li> </ul> <p>Each solver, when fed the joint surplus and margins, returns the equilibrium matching patterns, the adding-up errors on the margins, and if requested (using <code>gr=True</code>) the derivatives of the matching patterns in all primitives.</p>"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_gender_heteroskedastic_solver","title":"<code>ipfp_gender_heteroskedastic_solver(Phi, men_margins, women_margins, tau, tol=1e-09, gr=False, verbose=False, maxiter=1000)</code>","text":"<pre><code>ipfp_gender_heteroskedastic_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    tau: float,\n    tol: float,\n    gr: Literal[False],\n    verbose: bool,\n    maxiter: int,\n) -&gt; IPFPNoGradientResults\n</code></pre><pre><code>ipfp_gender_heteroskedastic_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    tau: float,\n    tol: float,\n    gr: Literal[True],\n    verbose: bool,\n    maxiter: int,\n) -&gt; IPFPGradientResults\n</code></pre> <p>Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter <code>tau</code></p> <p>Parameters:</p> Name Type Description Default <code>Phi</code> <code>ndarray</code> <p>matrix of systematic surplus, shape (X, Y)</p> required <code>men_margins</code> <code>ndarray</code> <p>vector of men margins, shape (X)</p> required <code>women_margins</code> <code>ndarray</code> <p>vector of women margins, shape (Y)</p> required <code>tau</code> <code>float</code> <p>the standard error for all women</p> required <code>tol</code> <code>float</code> <p>tolerance on change in solution</p> <code>1e-09</code> <code>gr</code> <code>bool</code> <p>if <code>True</code>, also evaluate derivatives of the matching patterns</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>if <code>True</code>, prints information</p> <code>False</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations</p> <code>1000</code> <p>Returns:</p> Type Description <code>(muxy, mux0, mu0y)</code> <p>the matching patterns</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>marg_err_x, marg_err_y: the errors on the margins</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>and the gradients of the matching patterns</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>wrt (men_margins, women_margins, Phi, tau) if <code>gr</code> is <code>True</code></p> Source code in <code>cupid_matching/ipfp_solvers.py</code> <pre><code>def ipfp_gender_heteroskedastic_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    tau: float,\n    tol: float = 1e-9,\n    gr: bool = False,\n    verbose: bool = False,\n    maxiter: int = 1000,\n) -&gt; IPFPNoGradientResults | IPFPGradientResults:\n    \"\"\"Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market\n    given systematic surplus and margins and a scale parameter `tau`\n\n    Args:\n        Phi: matrix of systematic surplus, shape (X, Y)\n        men_margins: vector of men margins, shape (X)\n        women_margins: vector of women margins, shape (Y)\n        tau: the standard error for all women\n        tol: tolerance on change in solution\n        gr: if `True`, also evaluate derivatives of the matching patterns\n        verbose: if `True`, prints information\n        maxiter: maximum number of iterations\n\n    Returns:\n         (muxy, mux0, mu0y): the matching patterns\n         marg_err_x, marg_err_y: the errors on the margins\n         and the gradients of the matching patterns\n         wrt (men_margins, women_margins, Phi, tau) if `gr` is `True`\n    \"\"\"\n    X, Y = _ipfp_check_sizes(men_margins, women_margins, Phi)\n\n    if tau &lt;= 0:\n        bs_error_abort(f\"We need a positive tau, not {tau}\")\n\n    #############################################################################\n    # we use ipfp_heteroxy_solver with sigma_x = 1 and tau_y = tau\n    #############################################################################\n\n    sigma_x = np.ones(X)\n    tau_y = np.full(Y, tau)\n\n    if gr:\n        (\n            mus_hxy,\n            marg_err_x,\n            marg_err_y,\n            dmus_xy,\n            dmus_x0,\n            dmus_0y,\n        ) = ipfp_heteroskedastic_solver(\n            Phi,\n            men_margins,\n            women_margins,\n            sigma_x,\n            tau_y,\n            tol=tol,\n            gr=True,\n            maxiter=maxiter,\n            verbose=verbose,\n        )\n        muxy, _, _, _, _ = mus_hxy.unpack()\n        n_sum_categories = X + Y\n        n_prod_categories = X * Y\n        n_cols = n_sum_categories + n_prod_categories\n        itau_y = n_cols + X\n        dmuxy = np.zeros((n_prod_categories, n_cols + 1))\n        dmuxy[:, :n_cols] = dmus_xy[:, :n_cols]\n        dmuxy[:, -1] = np.sum(dmus_xy[:, itau_y:], 1)\n        dmux0 = np.zeros((X, n_cols + 1))\n        dmux0[:, :n_cols] = dmus_x0[:, :n_cols]\n        dmux0[:, -1] = np.sum(dmus_x0[:, itau_y:], 1)\n        dmu0y = np.zeros((Y, n_cols + 1))\n        dmu0y[:, :n_cols] = dmus_0y[:, :n_cols]\n        dmu0y[:, -1] = np.sum(dmus_0y[:, itau_y:], 1)\n        return (\n            Matching(muxy, men_margins, women_margins),\n            marg_err_x,\n            marg_err_y,\n            dmuxy,\n            dmux0,\n            dmu0y,\n        )\n\n    else:\n        return ipfp_heteroskedastic_solver(\n            Phi,\n            men_margins,\n            women_margins,\n            sigma_x,\n            tau_y,\n            tol=tol,\n            gr=False,\n            maxiter=maxiter,\n            verbose=verbose,\n        )\n</code></pre>"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_heteroskedastic_solver","title":"<code>ipfp_heteroskedastic_solver(Phi, men_margins, women_margins, sigma_x, tau_y, tol=1e-09, gr=False, verbose=False, maxiter=1000)</code>","text":"<pre><code>ipfp_heteroskedastic_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    sigma_x: np.ndarray,\n    tau_y: np.ndarray,\n    tol: float,\n    gr: Literal[False],\n    verbose: bool,\n    maxiter: int,\n) -&gt; IPFPNoGradientResults\n</code></pre><pre><code>ipfp_heteroskedastic_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    sigma_x: np.ndarray,\n    tau_y: np.ndarray,\n    tol: float,\n    gr: Literal[True],\n    verbose: bool,\n    maxiter: int,\n) -&gt; IPFPGradientResults\n</code></pre> <p>Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors <code>sigma_x</code> and <code>tau_y</code></p> <p>Parameters:</p> Name Type Description Default <code>Phi</code> <code>ndarray</code> <p>matrix of systematic surplus, shape (X, Y)</p> required <code>men_margins</code> <code>ndarray</code> <p>vector of men margins, shape (X)</p> required <code>women_margins</code> <code>ndarray</code> <p>vector of women margins, shape (Y)</p> required <code>sigma_x</code> <code>ndarray</code> <p>the vector of standard errors for the X types of men</p> required <code>sigma_x</code> <code>ndarray</code> <p>the vector of standard errors for Y types of women</p> required <code>tol</code> <code>float</code> <p>tolerance on change in solution</p> <code>1e-09</code> <code>gr</code> <code>bool</code> <p>if <code>True</code>, also evaluate derivatives of the matching patterns</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>if <code>True</code>, prints information</p> <code>False</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations</p> <code>1000</code> <p>Returns:</p> Type Description <code>(muxy, mux0, mu0y)</code> <p>the matching patterns</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>marg_err_x, marg_err_y: the errors on the margins</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>and the gradients of the matching patterns</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>wrt (men_margins, women_margins, Phi, sigma_x, tau_y)</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>if <code>gr</code> is <code>True</code></p> Source code in <code>cupid_matching/ipfp_solvers.py</code> <pre><code>def ipfp_heteroskedastic_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    sigma_x: np.ndarray,\n    tau_y: np.ndarray,\n    tol: float = 1e-9,\n    gr: bool = False,\n    verbose: bool = False,\n    maxiter: int = 1000,\n) -&gt; IPFPNoGradientResults | IPFPGradientResults:\n    \"\"\"Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market\n    given systematic surplus and margins\n    and standard errors `sigma_x` and `tau_y`\n\n    Args:\n        Phi: matrix of systematic surplus, shape (X, Y)\n        men_margins: vector of men margins, shape (X)\n        women_margins: vector of women margins, shape (Y)\n        sigma_x: the vector of standard errors for the X types of men\n        sigma_x: the vector of standard errors for Y types of women\n        tol: tolerance on change in solution\n        gr: if `True`, also evaluate derivatives of the matching patterns\n        verbose: if `True`, prints information\n        maxiter: maximum number of iterations\n\n    Returns:\n         (muxy, mux0, mu0y): the matching patterns\n         marg_err_x, marg_err_y: the errors on the margins\n         and the gradients of the matching patterns\n         wrt (men_margins, women_margins, Phi, sigma_x, tau_y)\n         if `gr` is `True`\n    \"\"\"\n\n    X, Y = _ipfp_check_sizes(men_margins, women_margins, Phi)\n\n    if np.min(sigma_x) &lt;= 0.0:\n        bs_error_abort(\"All elements of sigma_x must be positive\")\n    if np.min(tau_y) &lt;= 0.0:\n        bs_error_abort(\"All elements of tau_y must be positive\")\n\n    sumxy1 = 1.0 / np.add.outer(sigma_x, tau_y)\n    ephi2, der_ephi2 = npexp(Phi * sumxy1, deriv=1)\n\n    #############################################################################\n    # we solve the equilibrium equations muxy = ephi2 * tx * ty\n    #   with tx = mux0^(sigma_x/(sigma_x + tau_max))\n    #   and ty = mu0y^(tau_y/(sigma_max + tau_y))\n    #   starting with a reasonable initial point for tx and ty: tx = ty = bigc\n    #   it is important that it fit the number of individuals\n    #############################################################################\n\n    nindivs = np.sum(men_margins) + np.sum(women_margins)\n    bigc = nindivs / (X + Y + 2.0 * np.sum(ephi2))\n    # we find the largest values of sigma_x and tau_y\n    xmax = np.argmax(sigma_x)\n    sigma_max = sigma_x[xmax]\n    ymax = np.argmax(tau_y)\n    tau_max = tau_y[ymax]\n    # we use tx = mux0^(sigma_x/(sigma_x + tau_max))\n    #    and ty = mu0y^(tau_y/(sigma_max + tau_y))\n    sig_taumax = sigma_x + tau_max\n    txi = np.power(bigc, sigma_x / sig_taumax)\n    sigmax_tau = tau_y + sigma_max\n    tyi = np.power(bigc, tau_y / sigmax_tau)\n    err_diff = bigc\n    tol_diff = tol * bigc\n    tol_newton = tol\n    niter = 0\n    while (err_diff &gt; tol_diff) and (niter &lt; maxiter):  # IPFP main loop\n        # Newton iterates for men\n        err_newton = bigc\n        txin = txi.copy()\n        mu0y_in = np.power(np.power(tyi, sigmax_tau), 1.0 / tau_y)\n        while err_newton &gt; tol_newton:\n            txit = np.power(txin, sig_taumax)\n            mux0_in = np.power(txit, 1.0 / sigma_x)\n            out_xy = np.outer(np.power(mux0_in, sigma_x), np.power(mu0y_in, tau_y))\n            muxy_in = ephi2 * np.power(out_xy, sumxy1)\n            errxi = mux0_in + np.sum(muxy_in, 1) - men_margins\n            err_newton = npmaxabs(errxi)\n            txin -= errxi / (\n                sig_taumax * (mux0_in / sigma_x + np.sum(sumxy1 * muxy_in, 1)) / txin\n            )\n        tx = txin\n\n        # Newton iterates for women\n        err_newton = bigc\n        tyin = tyi.copy()\n        mux0_in = np.power(np.power(tx, sig_taumax), 1.0 / sigma_x)\n        while err_newton &gt; tol_newton:\n            tyit = np.power(tyin, sigmax_tau)\n            mu0y_in = np.power(tyit, 1.0 / tau_y)\n            out_xy = np.outer(np.power(mux0_in, sigma_x), np.power(mu0y_in, tau_y))\n            muxy_in = ephi2 * np.power(out_xy, sumxy1)\n            erryi = mu0y_in + np.sum(muxy_in, 0) - women_margins\n            err_newton = npmaxabs(erryi)\n            tyin -= erryi / (\n                sigmax_tau * (mu0y_in / tau_y + np.sum(sumxy1 * muxy_in, 0)) / tyin\n            )\n\n        ty = tyin\n\n        err_x = npmaxabs(tx - txi)\n        err_y = npmaxabs(ty - tyi)\n        err_diff = err_x + err_y\n\n        txi = tx\n        tyi = ty\n\n        niter += 1\n\n    mux0 = mux0_in\n    mu0y = mu0y_in\n    muxy = muxy_in\n    marg_err_x = mux0 + np.sum(muxy, 1) - men_margins\n    marg_err_y = mu0y + np.sum(muxy, 0) - women_margins\n\n    if verbose:\n        print(f\"After {niter} iterations:\")\n        print(f\"\\tMargin error on x: {npmaxabs(marg_err_x)}\")\n        print(f\"\\tMargin error on y: {npmaxabs(marg_err_y)}\")\n    if not gr:\n        return (\n            Matching(muxy, men_margins, women_margins),\n            marg_err_x,\n            marg_err_y,\n        )\n    else:  # we compute_ the derivatives\n        n_sum_categories = X + Y\n        n_prod_categories = X * Y\n        # we work directly with (mux0, mu0y)\n        sigrat_xy = sumxy1 * sigma_x.reshape((-1, 1))\n        taurat_xy = 1.0 - sigrat_xy\n        mux0_mat = nprepeat_col(mux0, Y)\n        mu0y_mat = nprepeat_row(mu0y, X)\n        # muxy = axy * bxy * ephi2\n        axy = nppow(mux0_mat, sigrat_xy)\n        bxy = nppow(mu0y_mat, taurat_xy)\n        der_axy1, der_axy2 = nppow(mux0_mat, sigrat_xy, deriv=1)\n        der_bxy1, der_bxy2 = nppow(mu0y_mat, taurat_xy, deriv=1)\n        der_axy1_rat, der_axy2_rat = der_axy1 / axy, der_axy2 / axy\n        der_bxy1_rat, der_bxy2_rat = der_bxy1 / bxy, der_bxy2 / bxy\n\n        # start with the LHS of the linear system on (dmux0, dmu0y)\n        lhs = np.zeros((n_sum_categories, n_sum_categories))\n        lhs[:X, :X] = np.diag(1.0 + np.sum(muxy * der_axy1_rat, 1))\n        lhs[:X, X:] = muxy * der_bxy1_rat\n        lhs[X:, X:] = np.diag(1.0 + np.sum(muxy * der_bxy1_rat, 0))\n        lhs[X:, :X] = (muxy * der_axy1_rat).T\n\n        # now fill the RHS (derivatives wrt men_margins, then men_margins,\n        #    then Phi, then sigma_x and tau_y)\n        n_cols_rhs = n_sum_categories + n_prod_categories + X + Y\n        rhs = np.zeros((n_sum_categories, n_cols_rhs))\n\n        #  to compute_ derivatives of (mux0, mu0y) wrt men_margins\n        rhs[:X, :X] = np.eye(X)\n        #  to compute_ derivatives of (mux0, mu0y) wrt women_margins\n        rhs[X:, X:n_sum_categories] = np.eye(Y)\n\n        #   the next line is sumxy1 with safeguards\n        sumxy1_safe = sumxy1 * der_ephi2 / ephi2\n\n        big_a = muxy * sumxy1_safe\n        big_b = der_axy2_rat - der_bxy2_rat\n        b_mu_s = big_b * muxy * sumxy1\n        a_phi = Phi * big_a\n        big_c = sumxy1 * (a_phi - b_mu_s * tau_y)\n        big_d = sumxy1 * (a_phi + b_mu_s * sigma_x.reshape((-1, 1)))\n\n        #  to compute_ derivatives of (mux0, mu0y) wrt Phi\n        ivar = n_sum_categories\n        for iman in range(X):\n            rhs[iman, ivar : (ivar + Y)] = -big_a[iman, :]\n            ivar += Y\n        ivar1 = X\n        ivar2 = n_sum_categories\n        iend_phi = n_sum_categories + n_prod_categories\n        for iwoman in range(Y):\n            rhs[ivar1, ivar2:iend_phi:Y] = -big_a[:, iwoman]\n            ivar1 += 1\n            ivar2 += 1\n\n        #  to compute_ derivatives of (mux0, mu0y) wrt sigma_x\n        iend_sig = iend_phi + X\n        der_sigx = np.sum(big_c, 1)\n        rhs[:X, iend_phi:iend_sig] = np.diag(der_sigx)\n        rhs[X:, iend_phi:iend_sig] = big_c.T\n        #  to compute_ derivatives of (mux0, mu0y) wrt tau_y\n        der_tauy = np.sum(big_d, 0)\n        rhs[X:, iend_sig:] = np.diag(der_tauy)\n        rhs[:X, iend_sig:] = big_d\n\n        # solve for the derivatives of mux0 and mu0y\n        dmu0 = spla.solve(lhs, rhs)\n        dmux0 = dmu0[:X, :]\n        dmu0y = dmu0[X:, :]\n\n        # now construct the derivatives of muxy\n        dmuxy = np.zeros((n_prod_categories, n_cols_rhs))\n        der1 = ephi2 * der_axy1 * bxy\n        ivar = 0\n        for iman in range(X):\n            dmuxy[ivar : (ivar + Y), :] = np.outer(der1[iman, :], dmux0[iman, :])\n            ivar += Y\n        der2 = ephi2 * der_bxy1 * axy\n        for iwoman in range(Y):\n            dmuxy[iwoman:n_prod_categories:Y, :] += np.outer(\n                der2[:, iwoman], dmu0y[iwoman, :]\n            )\n\n        # add the terms that comes from differentiating ephi2\n        #  on the derivative wrt Phi\n        i = 0\n        j = n_sum_categories\n        for iman in range(X):\n            for iwoman in range(Y):\n                dmuxy[i, j] += big_a[iman, iwoman]\n                i += 1\n                j += 1\n        #  on the derivative wrt sigma_x\n        ivar = 0\n        ix = iend_phi\n        for iman in range(X):\n            dmuxy[ivar : (ivar + Y), ix] -= big_c[iman, :]\n            ivar += Y\n            ix += 1\n        # on the derivative wrt tau_y\n        iy = iend_sig\n        for iwoman in range(Y):\n            dmuxy[iwoman:n_prod_categories:Y, iy] -= big_d[:, iwoman]\n            iy += 1\n\n        return (\n            Matching(muxy, men_margins, women_margins),\n            marg_err_x,\n            marg_err_y,\n            dmuxy,\n            dmux0,\n            dmu0y,\n        )\n</code></pre>"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_homoskedastic_no_singles_solver","title":"<code>ipfp_homoskedastic_no_singles_solver(Phi, men_margins, women_margins, tol=1e-09, gr=False, verbose=False, maxiter=1000)</code>","text":"<p>Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins</p> <p>Parameters:</p> Name Type Description Default <code>Phi</code> <code>ndarray</code> <p>matrix of systematic surplus, shape (X, Y)</p> required <code>men_margins</code> <code>ndarray</code> <p>vector of men margins, shape (X)</p> required <code>women_margins</code> <code>ndarray</code> <p>vector of women margins, shape (Y)</p> required <code>tol</code> <code>float</code> <p>tolerance on change in solution</p> <code>1e-09</code> <code>gr</code> <code>bool</code> <p>if <code>True</code>, also evaluate derivatives of \\((\\mu_{xy})\\) wrt \\(\\Phi\\)</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>if <code>True</code>, prints information</p> <code>False</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations</p> <code>1000</code> <p>Returns:</p> Name Type Description <code>muxy</code> <code>ThreeArrays | FourArrays</code> <p>the matching patterns, shape (X, Y)</p> <code>ThreeArrays | FourArrays</code> <p>marg_err_x, marg_err_y: the errors on the margins</p> <code>ThreeArrays | FourArrays</code> <p>and the gradients of \\((\\mu_{xy})\\) wrt \\(\\Phi\\) if <code>gr</code> is <code>True</code></p> Source code in <code>cupid_matching/ipfp_solvers.py</code> <pre><code>def ipfp_homoskedastic_no_singles_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    tol: float = 1e-9,\n    gr: bool = False,\n    verbose: bool = False,\n    maxiter: int = 1000,\n) -&gt; ThreeArrays | FourArrays:\n    \"\"\"Solves for equilibrium in a Choo and Siow market without singles,\n    given systematic surplus and margins\n\n    Args:\n        Phi: matrix of systematic surplus, shape (X, Y)\n        men_margins: vector of men margins, shape (X)\n        women_margins: vector of women margins, shape (Y)\n        tol: tolerance on change in solution\n        gr: if `True`, also evaluate derivatives of $(\\\\mu_{xy})$ wrt $\\\\Phi$\n        verbose: if `True`, prints information\n        maxiter: maximum number of iterations\n\n    Returns:\n         muxy: the matching patterns, shape (X, Y)\n         marg_err_x, marg_err_y: the errors on the margins\n         and the gradients of $(\\\\mu_{xy})$ wrt $\\\\Phi$ if `gr` is `True`\n    \"\"\"\n    X, Y = _ipfp_check_sizes(men_margins, women_margins, Phi)\n    n_couples = np.sum(men_margins)\n\n    # check that there are as many men as women\n    if np.abs(np.sum(women_margins) - n_couples) &gt; n_couples * tol:\n        bs_error_abort(\"There should be as many men as women\")\n\n    ephi2, der_ephi2 = npexp(Phi / 2.0, deriv=1)\n    ephi2T = ephi2.T\n\n    #############################################################################\n    # we solve the equilibrium equations muxy = ephi2 * tx * ty\n    #   starting with a reasonable initial point for tx and ty: : tx = ty = bigc\n    #   it is important that it fit the number of individuals\n    #############################################################################\n    bigc = sqrt(n_couples / np.sum(ephi2))\n    txi = np.full(X, bigc)\n    tyi = np.full(Y, bigc)\n\n    err_diff = bigc\n    tol_diff = tol * err_diff\n    niter = 0\n    while (err_diff &gt; tol_diff) and (niter &lt; maxiter):\n        sx = ephi2 @ tyi\n        tx = men_margins / sx\n        sy = ephi2T @ tx\n        ty = women_margins / sy\n        err_x = npmaxabs(tx - txi)\n        err_y = npmaxabs(ty - tyi)\n        err_diff = err_x + err_y\n        txi, tyi = tx, ty\n        niter += 1\n    muxy = ephi2 * np.outer(txi, tyi)\n    marg_err_x = np.sum(muxy, 1) - men_margins\n    marg_err_y = np.sum(muxy, 0) - women_margins\n    if verbose:\n        print(f\"After {niter} iterations:\")\n        print(f\"\\tMargin error on x: {npmaxabs(marg_err_x)}\")\n        print(f\"\\tMargin error on y: {npmaxabs(marg_err_y)}\")\n    if not gr:\n        return muxy, marg_err_x, marg_err_y\n    else:\n        sxi = ephi2 @ tyi\n        syi = ephi2T @ txi\n        n_sum_categories = X + Y\n        n_prod_categories = X * Y\n\n        # start with the LHS of the linear system\n        lhs = np.zeros((n_sum_categories, n_sum_categories))\n        lhs[:X, :X] = np.diag(sxi)\n        lhs[:X, X:] = ephi2 * txi.reshape((-1, 1))\n        lhs[X:, X:] = np.diag(syi)\n        lhs[X:, :X] = ephi2T * tyi.reshape((-1, 1))\n\n        # now fill the RHS\n        n_cols_rhs = n_prod_categories\n        rhs = np.zeros((n_sum_categories, n_cols_rhs))\n\n        #  to compute_ derivatives of (txi, tyi) wrt Phi\n        der_ephi2 /= 2.0 * ephi2  # 1/2 with safeguards\n        ivar = 0\n        for iman in range(X):\n            rhs[iman, ivar : (ivar + Y)] = -muxy[iman, :] * der_ephi2[iman, :]\n            ivar += Y\n        ivar1 = X\n        ivar2 = 0\n        for iwoman in range(Y):\n            rhs[ivar1, ivar2:n_cols_rhs:Y] = -muxy[:, iwoman] * der_ephi2[:, iwoman]\n            ivar1 += 1\n            ivar2 += 1\n        # solve for the derivatives of txi and tyi\n        dt_dT = spla.solve(lhs, rhs)\n        dt = dt_dT[:X, :]\n        dT = dt_dT[X:, :]\n        # now construct the derivatives of muxy\n        dmuxy = np.zeros((n_prod_categories, n_cols_rhs))\n        ivar = 0\n        for iman in range(X):\n            dt_man = dt[iman, :]\n            dmuxy[ivar : (ivar + Y), :] = np.outer((ephi2[iman, :] * tyi), dt_man)\n            ivar += Y\n        for iwoman in range(Y):\n            dT_woman = dT[iwoman, :]\n            dmuxy[iwoman:n_prod_categories:Y, :] += np.outer(\n                (ephi2[:, iwoman] * txi), dT_woman\n            )\n        # add the term that comes from differentiating ephi2\n        muxy_vec2 = (muxy * der_ephi2).reshape(n_prod_categories)\n        dmuxy += np.diag(muxy_vec2)\n        return muxy, marg_err_x, marg_err_y, dmuxy\n</code></pre>"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_homoskedastic_solver","title":"<code>ipfp_homoskedastic_solver(Phi, men_margins, women_margins, tol=1e-09, gr=False, verbose=False, maxiter=1000)</code>","text":"<p>Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins</p> <p>Parameters:</p> Name Type Description Default <code>Phi</code> <code>ndarray</code> <p>matrix of systematic surplus, shape (X, Y)</p> required <code>men_margins</code> <code>ndarray</code> <p>vector of men margins, shape (X)</p> required <code>women_margins</code> <code>ndarray</code> <p>vector of women margins, shape (Y)</p> required <code>tol</code> <code>float</code> <p>tolerance on change in solution</p> <code>1e-09</code> <code>gr</code> <code>bool</code> <p>if <code>True</code>, also evaluate derivatives of the matching patterns</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>if <code>True</code>, prints information</p> <code>False</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations</p> <code>1000</code> <p>Returns:</p> Type Description <code>(muxy, mux0, mu0y)</code> <p>the matching patterns</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>marg_err_x, marg_err_y: the errors on the margins</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>and the gradients of the matching patterns wrt (men_margins, women_margins, Phi)</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>if <code>gr</code> is <code>True</code></p> Example <pre><code># we generate a Choo and Siow homoskedastic matching\nX = Y = 20\nn_sum_categories = X + Y\nn_prod_categories = X * Y\n\nmu, sigma = 0.0, 1.0\nn_bases = 4\nbases_surplus = np.zeros((X, Y, n_bases))\nx_men = (np.arange(X) - X / 2.0) / X\ny_women = (np.arange(Y) - Y / 2.0) / Y\n\nbases_surplus[:, :, 0] = 1\nfor iy in range(Y):\n    bases_surplus[:, iy, 1] = x_men\nfor ix in range(X):\n    bases_surplus[ix, :, 2] = y_women\nfor ix in range(X):\n    for iy in range(Y):\n        bases_surplus[ix, iy, 3] = (x_men[ix] - y_women[iy]) * (\n            x_men[ix] - y_women[iy]\n        )\n\nmen_margins = np.random.uniform(1.0, 10.0, size=X)\nwomen_margins = np.random.uniform(1.0, 10.0, size=Y)\n\n# np.random.normal(mu, sigma, size=n_bases)\ntrue_surplus_params = np.array([3.0, -1.0, -1.0, -2.0])\ntrue_surplus_matrix = bases_surplus @ true_surplus_params\n\nmus, marg_err_x, marg_err_y = ipfp_homoskedastic_solver(\n    true_surplus_matrix, men_margins, women_margins, tol=1e-12\n)\n</code></pre> Source code in <code>cupid_matching/ipfp_solvers.py</code> <pre><code>def ipfp_homoskedastic_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    tol: float = 1e-9,\n    gr: bool = False,\n    verbose: bool = False,\n    maxiter: int = 1000,\n) -&gt; IPFPNoGradientResults | IPFPGradientResults:\n    \"\"\"Solves for equilibrium in a Choo and Siow market with singles,\n    given systematic surplus and margins\n\n    Args:\n        Phi: matrix of systematic surplus, shape (X, Y)\n        men_margins: vector of men margins, shape (X)\n        women_margins: vector of women margins, shape (Y)\n        tol: tolerance on change in solution\n        gr: if `True`, also evaluate derivatives of the matching patterns\n        verbose: if `True`, prints information\n        maxiter: maximum number of iterations\n\n    Returns:\n         (muxy, mux0, mu0y): the matching patterns\n         marg_err_x, marg_err_y: the errors on the margins\n         and the gradients of the matching patterns wrt (men_margins, women_margins, Phi)\n         if `gr` is `True`\n\n\n    Example:\n        ```py\n        # we generate a Choo and Siow homoskedastic matching\n        X = Y = 20\n        n_sum_categories = X + Y\n        n_prod_categories = X * Y\n\n        mu, sigma = 0.0, 1.0\n        n_bases = 4\n        bases_surplus = np.zeros((X, Y, n_bases))\n        x_men = (np.arange(X) - X / 2.0) / X\n        y_women = (np.arange(Y) - Y / 2.0) / Y\n\n        bases_surplus[:, :, 0] = 1\n        for iy in range(Y):\n            bases_surplus[:, iy, 1] = x_men\n        for ix in range(X):\n            bases_surplus[ix, :, 2] = y_women\n        for ix in range(X):\n            for iy in range(Y):\n                bases_surplus[ix, iy, 3] = (x_men[ix] - y_women[iy]) * (\n                    x_men[ix] - y_women[iy]\n                )\n\n        men_margins = np.random.uniform(1.0, 10.0, size=X)\n        women_margins = np.random.uniform(1.0, 10.0, size=Y)\n\n        # np.random.normal(mu, sigma, size=n_bases)\n        true_surplus_params = np.array([3.0, -1.0, -1.0, -2.0])\n        true_surplus_matrix = bases_surplus @ true_surplus_params\n\n        mus, marg_err_x, marg_err_y = ipfp_homoskedastic_solver(\n            true_surplus_matrix, men_margins, women_margins, tol=1e-12\n        )\n        ```\n    \"\"\"\n    X, Y = _ipfp_check_sizes(men_margins, women_margins, Phi)\n\n    ephi2, der_ephi2 = npexp(Phi / 2.0, deriv=1)\n\n    #############################################################################\n    # we solve the equilibrium equations muxy = ephi2 * tx * ty\n    #   where mux0=tx**2  and mu0y=ty**2\n    #   starting with a reasonable initial point for tx and ty: tx = ty = bigc\n    #   it is important that it fit the number of individuals\n    #############################################################################\n\n    ephi2T = ephi2.T\n    nindivs = np.sum(men_margins) + np.sum(women_margins)\n    bigc = sqrt(nindivs / (X + Y + 2.0 * np.sum(ephi2)))\n    txi = np.full(X, bigc)\n    tyi = np.full(Y, bigc)\n\n    err_diff = bigc\n    tol_diff = tol * bigc\n    niter = 0\n    while (err_diff &gt; tol_diff) and (niter &lt; maxiter):\n        sx = ephi2 @ tyi\n        tx = (np.sqrt(sx * sx + 4.0 * men_margins) - sx) / 2.0\n        sy = ephi2T @ tx\n        ty = (np.sqrt(sy * sy + 4.0 * women_margins) - sy) / 2.0\n        err_x = npmaxabs(tx - txi)\n        err_y = npmaxabs(ty - tyi)\n        err_diff = err_x + err_y\n        txi = tx\n        tyi = ty\n        niter += 1\n    mux0 = txi * txi\n    mu0y = tyi * tyi\n    muxy = ephi2 * np.outer(txi, tyi)\n    marg_err_x = mux0 + np.sum(muxy, 1) - men_margins\n    marg_err_y = mu0y + np.sum(muxy, 0) - women_margins\n    if verbose:\n        print(f\"After {niter} iterations:\")\n        print(f\"\\tMargin error on x: {npmaxabs(marg_err_x)}\")\n        print(f\"\\tMargin error on y: {npmaxabs(marg_err_y)}\")\n    if not gr:\n        return (\n            Matching(muxy, men_margins, women_margins),\n            marg_err_x,\n            marg_err_y,\n        )\n    else:  # we compute_ the derivatives\n        sxi = ephi2 @ tyi\n        syi = ephi2T @ txi\n        n_sum_categories = X + Y\n        n_prod_categories = X * Y\n        # start with the LHS of the linear system\n        lhs = np.zeros((n_sum_categories, n_sum_categories))\n        lhs[:X, :X] = np.diag(2.0 * txi + sxi)\n        lhs[:X, X:] = ephi2 * txi.reshape((-1, 1))\n        lhs[X:, X:] = np.diag(2.0 * tyi + syi)\n        lhs[X:, :X] = ephi2T * tyi.reshape((-1, 1))\n        # now fill the RHS\n        n_cols_rhs = n_sum_categories + n_prod_categories\n        rhs = np.zeros((n_sum_categories, n_cols_rhs))\n        #  to compute_ derivatives of (txi, tyi) wrt men_margins\n        rhs[:X, :X] = np.eye(X)\n        #  to compute_ derivatives of (txi, tyi) wrt women_margins\n        rhs[X:n_sum_categories, X:n_sum_categories] = np.eye(Y)\n        #  to compute_ derivatives of (txi, tyi) wrt Phi\n        der_ephi2 /= 2.0 * ephi2  # 1/2 with safeguards\n        ivar = n_sum_categories\n        for iman in range(X):\n            rhs[iman, ivar : (ivar + Y)] = -muxy[iman, :] * der_ephi2[iman, :]\n            ivar += Y\n        ivar1 = X\n        ivar2 = n_sum_categories\n        for iwoman in range(Y):\n            rhs[ivar1, ivar2:n_cols_rhs:Y] = -muxy[:, iwoman] * der_ephi2[:, iwoman]\n            ivar1 += 1\n            ivar2 += 1\n        # solve for the derivatives of txi and tyi\n        dt_dT = spla.solve(lhs, rhs)\n        dt = dt_dT[:X, :]\n        dT = dt_dT[X:, :]\n        # now construct the derivatives of the mus\n        dmux0 = 2.0 * (dt * txi.reshape((-1, 1)))\n        dmu0y = 2.0 * (dT * tyi.reshape((-1, 1)))\n        dmuxy = np.zeros((n_prod_categories, n_cols_rhs))\n        ivar = 0\n        for iman in range(X):\n            dt_man = dt[iman, :]\n            dmuxy[ivar : (ivar + Y), :] = np.outer((ephi2[iman, :] * tyi), dt_man)\n            ivar += Y\n        for iwoman in range(Y):\n            dT_woman = dT[iwoman, :]\n            dmuxy[iwoman:n_prod_categories:Y, :] += np.outer(\n                (ephi2[:, iwoman] * txi), dT_woman\n            )\n        # add the term that comes from differentiating ephi2\n        muxy_vec2 = (muxy * der_ephi2).reshape(n_prod_categories)\n        dmuxy[:, n_sum_categories:] += np.diag(muxy_vec2)\n        return (\n            Matching(muxy, men_margins, women_margins),\n            marg_err_x,\n            marg_err_y,\n            dmuxy,\n            dmux0,\n            dmu0y,\n        )\n</code></pre>"},{"location":"matching_utils/","title":"<code>matching_utils</code> module","text":"<p>matching-related utilities</p>"},{"location":"matching_utils/#cupid_matching.matching_utils.Matching","title":"<code>Matching</code>  <code>dataclass</code>","text":"<p>stores the numbers of couples and singles of every type;</p> <p><code>muxy</code> is an (X,Y)-matrix <code>n</code> is an X-vector <code>m</code> is an Y-vector</p> <p><code>no_singles</code>: if <code>True</code>, this is a model w/o singles</p> <p><code>mux0</code> and <code>mu0y</code> are generated as the corresponding numbers of singles as well as the total number of households <code>n_households</code> and the total number of individuals <code>n_individuals</code></p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>@dataclass\nclass Matching:\n    \"\"\"stores the numbers of couples and singles of every type;\n\n    `muxy` is an (X,Y)-matrix\n    `n` is an X-vector\n    `m` is an Y-vector\n\n    `no_singles`: if `True`, this is a model w/o singles\n\n    `mux0` and `mu0y` are generated as the corresponding numbers of singles\n    as well as the total number of households `n_households`\n    and the total number of individuals `n_individuals`\n    \"\"\"\n\n    muxy: np.ndarray\n    n: np.ndarray\n    m: np.ndarray\n    no_singles: bool = False\n\n    mux0: np.ndarray = field(init=False)\n    mu0y: np.ndarray = field(init=False)\n    n_households: float = field(init=False)\n    n_individuals: float = field(init=False)\n\n    def __str__(self):\n        X, Y = self.muxy.shape\n        n_couples = np.sum(self.muxy)\n        n_men, n_women = np.sum(self.n), np.sum(self.m)\n        repr_str = f\"This is a matching with {n_men} men and {n_women} women.\\n\"\n        repr_str += f\"   with {n_couples} couples,\\n\"\n        if self.no_singles:\n            repr_str += \"     and no singles.\\n\"\n        repr_str += f\"\\n We have {X} types of men and {Y} of women.\"\n        return repr_str\n\n    def __post_init__(self):\n        X, Y = check_matrix(self.muxy)\n        Xn = check_vector(self.n)\n        Ym = check_vector(self.m)\n        if Xn != X:\n            bs_error_abort(f\"muxy is a ({X}, {Y}) matrix but n has {Xn} elements.\")\n        if Ym != Y:\n            bs_error_abort(f\"muxy is a ({X}, {Y}) matrix but m has {Ym} elements.\")\n        self.mux0, self.mu0y = get_singles(self.muxy, self.n, self.m)\n        self.n_households = np.sum(self.muxy) + np.sum(self.mux0) + np.sum(self.mu0y)\n        if self.no_singles:\n            _check_no_singles(self.mux0, self.n_households, \"men\")\n            _check_no_singles(self.mu0y, self.n_households, \"women\")\n        self.n_individuals = (\n            2.0 * np.sum(self.muxy) + np.sum(self.mux0) + np.sum(self.mu0y)\n        )\n\n    def unpack(self):\n        muxy, mux0, mu0y = self.muxy, self.mux0, self.mu0y\n        min_xy, min_x0, min_0y = np.min(muxy), np.min(mux0), np.min(mu0y)\n        if min_xy &lt; 0.0:\n            bs_error_abort(f\"The smallest muxy is {min_xy}\")\n        if not self.no_singles:\n            if min_x0 &lt; 0.0:\n                bs_error_abort(f\"The smallest mux0 is {min_x0}\")\n            if min_0y &lt; 0.0:\n                bs_error_abort(f\"The smallest mux0 is {min_0y}\")\n        return muxy, mux0, mu0y, self.n, self.m\n</code></pre>"},{"location":"matching_utils/#cupid_matching.matching_utils.VarianceMatching","title":"<code>VarianceMatching</code>  <code>dataclass</code>","text":"<p>initialized with the six matrix components of the variance of a `Matching;  computes five more components.</p> <p><code>var_xyzt</code> is the (XY, XY) var-cov matrix of <code>muxy</code> <code>var_xyz0</code> is the (XY, X) covariance matrix of <code>muxy</code> and <code>mux0</code> <code>var_xy0t</code> is the (XY, Y) covariance matrix of <code>muxy</code> and <code>mu0y</code> <code>var_x0z0</code> is the (X, X) var-cov matrix of <code>mux0</code> <code>var_x00t</code> is the (X, Y) covariance matrix of <code>mux0</code> and <code>mu0y</code> <code>var_0y0t</code> is the (Y, Y) var-cov matrix of <code>mu0y</code></p> <p><code>var_xyn</code> is the (XY, X) covariance matrix of <code>muxy</code> and <code>nx</code> <code>var_xym</code> is the (XY, Y) covariance matrix of <code>muxy</code> and <code>my</code> <code>var_nn</code> is the (X, X) var-cov matrix of <code>nx</code> <code>var_nm</code> is the (X, Y) covariance matrix of <code>nx</code> and <code>my</code> <code>var_mm</code> is the (Y, Y) var-cov matrix of <code>my</code></p> <p><code>var_allmus</code> is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, mux0, mu0y) <code>var_munm</code> is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, n, m)</p> <p><code>no_singles</code>: if <code>True</code>, this is a model w/o singles;     then <code>var_allmus</code> and <code>var_munm</code> are <code>(XY, XY)</code> and <code>(XY, XY+X+Y)</code>matrices</p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>@dataclass\nclass VarianceMatching:\n    \"\"\"initialized with the six matrix components of the variance of a `Matching;  computes five more components.\n\n    `var_xyzt` is the (XY, XY) var-cov matrix of `muxy`\n    `var_xyz0` is the (XY, X) covariance matrix of `muxy` and `mux0`\n    `var_xy0t` is the (XY, Y) covariance matrix of `muxy` and `mu0y`\n    `var_x0z0` is the (X, X) var-cov matrix of `mux0`\n    `var_x00t` is the (X, Y) covariance matrix of `mux0` and `mu0y`\n    `var_0y0t` is the (Y, Y) var-cov matrix of `mu0y`\n\n    `var_xyn` is the (XY, X) covariance matrix of `muxy` and `nx`\n    `var_xym` is the (XY, Y) covariance matrix of `muxy` and `my`\n    `var_nn` is the (X, X) var-cov matrix of `nx`\n    `var_nm` is the (X, Y) covariance matrix of `nx` and `my`\n    `var_mm` is the (Y, Y) var-cov matrix of `my`\n\n    `var_allmus` is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, mux0, mu0y)\n    `var_munm` is the (XY+X+Y, XY+X+Y) var-cov matrix of (muxy, n, m)\n\n    `no_singles`: if `True`, this is a model w/o singles;\n        then `var_allmus` and `var_munm` are `(XY, XY)` and `(XY, XY+X+Y)`matrices\n    \"\"\"\n\n    var_xyzt: np.ndarray\n    var_xyz0: np.ndarray\n    var_xy0t: np.ndarray\n    var_x0z0: np.ndarray\n    var_x00t: np.ndarray\n    var_0y0t: np.ndarray\n\n    no_singles: bool = False\n\n    var_xyn: np.ndarray = field(init=False)\n    var_xym: np.ndarray = field(init=False)\n    var_nn: np.ndarray = field(init=False)\n    var_nm: np.ndarray = field(init=False)\n    var_mm: np.ndarray = field(init=False)\n\n    var_allmus: np.ndarray = field(init=False)\n    var_munm: np.ndarray = field(init=False)\n\n    def __str__(self):\n        n_men = self.var_xyz0.shape[1]\n        n_women = self.var_xy0t.shape[1]\n        repr_str = f\"This is a VarianceMatching with {n_men}  men, {n_women} women.\\n\"\n        if self.no_singles:\n            repr_str += \"    we have  no singles.\\n\\n\"\n        return repr_str\n\n    def __post_init__(self):\n        v_xyzt = self.var_xyzt\n        XY, XY2 = check_matrix(v_xyzt)\n        if XY2 != XY:\n            bs_error_abort(f\"var_xyzt should be a square matrix, not ({XY}, {XY2})\")\n        v_xyz0 = self.var_xyz0\n        XY3, X = check_matrix(v_xyz0)\n        if XY3 != XY:\n            bs_error_abort(f\"var_xyz0 should have {XY} rows, not {XY3})\")\n        v_xy0t = self.var_xy0t\n        XY4, Y = check_matrix(v_xy0t)\n        if XY4 != XY:\n            bs_error_abort(f\"var_xy0t should have {XY} rows, not {XY4})\")\n        if X * Y != XY:\n            bs_error_abort(\n                f\"var_xyzt has {XY} rows, but varxyz0 has {X} columns and varxy0t\"\n                f\" has {Y}\"\n            )\n        v_x0z0 = self.var_x0z0\n        X2, X3 = check_matrix(v_x0z0)\n        if X2 != X:\n            bs_error_abort(f\"var_x0z0 has {X2} rows, it should have {X}\")\n        if X3 != X:\n            bs_error_abort(f\"var_x0z0 has {X3} columns, it should have {X}\")\n        v_x00t = self.var_x00t\n        X4, Y2 = check_matrix(v_x00t)\n        if X4 != X:\n            bs_error_abort(f\"var_x00t has {X4} rows, it should have {X}\")\n        if Y2 != Y:\n            bs_error_abort(f\"var_x00t has {Y2} columns, it should have {Y}\")\n        v_0y0t = self.var_0y0t\n        Y3, Y4 = check_matrix(v_0y0t)\n        if Y3 != Y:\n            bs_error_abort(f\"var_x00t has {Y3} rows, it should have {Y}\")\n        if Y4 != Y:\n            bs_error_abort(f\"var_x00t has {Y4} columns, it should have {Y}\")\n\n        # now we compute the additional components\n        if self.no_singles:\n            v_xyn = np.zeros_like(v_xyz0)\n            iz = 0\n            for z in range(X):\n                v_xyn[:, z] += np.sum(v_xyzt[:, iz : (iz + Y)], 1)\n                iz += Y\n            self.var_xyn = v_xyn\n            v_xym = np.zeros_like(v_xy0t)\n            for t in range(Y):\n                slice_t = slice(t, XY, Y)\n                v_xym[:, t] += np.sum(v_xyzt[:, slice_t], 1)\n            self.var_xym = v_xym\n            v_nn = np.zeros_like(v_x0z0)\n            ix = 0\n            for x in range(X):\n                v_nn[x, :] += np.sum(v_xyn[ix : (ix + Y), :], 0)\n                ix += Y\n            self.var_nn = v_nn\n            v_nm = np.zeros_like(v_x00t)\n            v_mm = np.zeros_like(v_0y0t)\n            for y in range(Y):\n                slice_y = slice(y, XY, Y)\n                v_nm[:, y] += np.sum(v_xyn[slice_y, :], 0)\n                v_mm[y, :] += np.sum(v_xym[slice_y, :], 0)\n            self.var_nm = v_nm\n            self.var_mm = v_mm\n        else:\n            v_xyn = v_xyz0.copy()\n            sumt_covx0_zt = np.zeros((X, X))\n            iz = 0\n            for z in range(X):\n                v_xyn[:, z] += np.sum(v_xyzt[:, iz : (iz + Y)], 1)\n                sumt_covx0_zt[:, z] = np.sum(v_xyz0[iz : (iz + Y), :], 0)\n                iz += Y\n            self.var_xyn = v_xyn\n            v_xym = v_xy0t.copy()\n            v_0ym = v_0y0t.copy()\n            for t in range(Y):\n                slice_t = slice(t, XY, Y)\n                v_xym[:, t] += np.sum(v_xyzt[:, slice_t], 1)\n                v_0ym[:, t] += np.sum(v_xy0t[slice_t, :], 0)\n            self.var_xym = v_xym\n            v_x0n = v_x0z0 + sumt_covx0_zt\n            v_nn = v_x0n\n            v_0yn = v_x00t.copy().T\n            ix = 0\n            for x in range(X):\n                v_nn[x, :] += np.sum(v_xyn[ix : (ix + Y), :], 0)\n                v_0yn[:, x] += np.sum(v_xy0t[ix : (ix + Y), :], 0)\n                ix += Y\n            self.var_nn = v_nn\n            v_nm = v_0yn.T\n            v_mm = v_0ym\n            for y in range(Y):\n                slice_y = slice(y, XY, Y)\n                v_nm[:, y] += np.sum(v_xyn[slice_y, :], 0)\n                v_mm[y, :] += np.sum(v_xym[slice_y, :], 0)\n            self.var_nm = v_nm\n            self.var_mm = v_mm\n\n        self.var_allmus = self.make_var_allmus()\n        self.var_munm = self.make_var_munm()\n\n    def unpack(self):\n        \"\"\"return a tuple of all members of this `VarianceMatching`\"\"\"\n        return (\n            self.var_xyzt,\n            self.var_xyz0,\n            self.var_xy0t,\n            self.var_x0z0,\n            self.var_x00t,\n            self.var_0y0t,\n            self.var_xyn,\n            self.var_xym,\n            self.var_nn,\n            self.var_nm,\n            self.var_mm,\n        )\n\n    def make_var_allmus(self: Any) -&gt; np.ndarray:\n        \"\"\"create the variance-covariance of `(muxy, mux0, mu0y)`\n\n        Args:\n            self:  the `VarianceMatching` object\n\n        Returns:\n            an `(XY+X+Y, XY+X+Y)` symmetric positive matrix if there are singles; otherwise `(XY, XY)`\n        \"\"\"\n        v_xyzt, v_xyz0, v_xy0t, v_x0z0, v_x00t, v_0y0t, *_ = self.unpack()\n        X, Y = v_x0z0.shape[0], v_0y0t.shape[0]\n        XY = X * Y\n\n        if not self.no_singles:\n            sz = XY + X + Y\n            v_allmus = np.zeros((sz, sz))\n            v_allmus[:XY, :XY] = v_xyzt\n            v_allmus[:XY, XY : (XY + X)] = v_xyz0\n            v_allmus[XY : (XY + X), :XY] = v_xyz0.T\n            v_allmus[:XY, (XY + X) :] = v_xy0t\n            v_allmus[(XY + X) :, :XY] = v_xy0t.T\n            v_allmus[XY : (XY + X), XY : (XY + X)] = v_x0z0\n            v_allmus[XY : (XY + X), (XY + X) :] = v_x00t\n            v_allmus[(XY + X) :, XY : (XY + X)] = v_x00t.T\n            v_allmus[(XY + X) :, (XY + X) :] = v_0y0t\n        else:\n            v_allmus = v_xyzt\n\n        return v_allmus\n\n    def make_var_munm(self: Any) -&gt; np.ndarray:\n        \"\"\"create the variance-covariance of `(muxy, n, m)`\n\n        Args:\n            self:  this `VarianceMatching` object\n\n        Returns:\n            an `(XY+X+Y, XY+X+Y)` symmetric positive matrix.\n        \"\"\"\n        v_xyzt, *_, v_xyn, v_xym, v_nn, v_nm, v_mm = self.unpack()\n        X, Y = v_nn.shape[0], v_mm.shape[0]\n        XY = X * Y\n        sz = XY + X + Y\n        v_munm = np.zeros((sz, sz))\n        v_munm[:XY, :XY] = v_xyzt\n        v_munm[:XY, XY : (XY + X)] = v_xyn\n        v_munm[XY : (XY + X), :XY] = v_xyn.T\n        v_munm[:XY, (XY + X) :] = v_xym\n        v_munm[(XY + X) :, :XY] = v_xym.T\n        v_munm[XY : (XY + X), XY : (XY + X)] = v_nn\n        v_munm[XY : (XY + X), (XY + X) :] = v_nm\n        v_munm[(XY + X) :, XY : (XY + X)] = v_nm.T\n        v_munm[(XY + X) :, (XY + X) :] = v_mm\n\n        return v_munm\n</code></pre>"},{"location":"matching_utils/#cupid_matching.matching_utils.VarianceMatching.make_var_allmus","title":"<code>make_var_allmus()</code>","text":"<p>create the variance-covariance of <code>(muxy, mux0, mu0y)</code></p> <p>Parameters:</p> Name Type Description Default <code>self</code> <code>Any</code> <p>the <code>VarianceMatching</code> object</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>an <code>(XY+X+Y, XY+X+Y)</code> symmetric positive matrix if there are singles; otherwise <code>(XY, XY)</code></p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>def make_var_allmus(self: Any) -&gt; np.ndarray:\n    \"\"\"create the variance-covariance of `(muxy, mux0, mu0y)`\n\n    Args:\n        self:  the `VarianceMatching` object\n\n    Returns:\n        an `(XY+X+Y, XY+X+Y)` symmetric positive matrix if there are singles; otherwise `(XY, XY)`\n    \"\"\"\n    v_xyzt, v_xyz0, v_xy0t, v_x0z0, v_x00t, v_0y0t, *_ = self.unpack()\n    X, Y = v_x0z0.shape[0], v_0y0t.shape[0]\n    XY = X * Y\n\n    if not self.no_singles:\n        sz = XY + X + Y\n        v_allmus = np.zeros((sz, sz))\n        v_allmus[:XY, :XY] = v_xyzt\n        v_allmus[:XY, XY : (XY + X)] = v_xyz0\n        v_allmus[XY : (XY + X), :XY] = v_xyz0.T\n        v_allmus[:XY, (XY + X) :] = v_xy0t\n        v_allmus[(XY + X) :, :XY] = v_xy0t.T\n        v_allmus[XY : (XY + X), XY : (XY + X)] = v_x0z0\n        v_allmus[XY : (XY + X), (XY + X) :] = v_x00t\n        v_allmus[(XY + X) :, XY : (XY + X)] = v_x00t.T\n        v_allmus[(XY + X) :, (XY + X) :] = v_0y0t\n    else:\n        v_allmus = v_xyzt\n\n    return v_allmus\n</code></pre>"},{"location":"matching_utils/#cupid_matching.matching_utils.VarianceMatching.make_var_munm","title":"<code>make_var_munm()</code>","text":"<p>create the variance-covariance of <code>(muxy, n, m)</code></p> <p>Parameters:</p> Name Type Description Default <code>self</code> <code>Any</code> <p>this <code>VarianceMatching</code> object</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>an <code>(XY+X+Y, XY+X+Y)</code> symmetric positive matrix.</p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>def make_var_munm(self: Any) -&gt; np.ndarray:\n    \"\"\"create the variance-covariance of `(muxy, n, m)`\n\n    Args:\n        self:  this `VarianceMatching` object\n\n    Returns:\n        an `(XY+X+Y, XY+X+Y)` symmetric positive matrix.\n    \"\"\"\n    v_xyzt, *_, v_xyn, v_xym, v_nn, v_nm, v_mm = self.unpack()\n    X, Y = v_nn.shape[0], v_mm.shape[0]\n    XY = X * Y\n    sz = XY + X + Y\n    v_munm = np.zeros((sz, sz))\n    v_munm[:XY, :XY] = v_xyzt\n    v_munm[:XY, XY : (XY + X)] = v_xyn\n    v_munm[XY : (XY + X), :XY] = v_xyn.T\n    v_munm[:XY, (XY + X) :] = v_xym\n    v_munm[(XY + X) :, :XY] = v_xym.T\n    v_munm[XY : (XY + X), XY : (XY + X)] = v_nn\n    v_munm[XY : (XY + X), (XY + X) :] = v_nm\n    v_munm[(XY + X) :, XY : (XY + X)] = v_nm.T\n    v_munm[(XY + X) :, (XY + X) :] = v_mm\n\n    return v_munm\n</code></pre>"},{"location":"matching_utils/#cupid_matching.matching_utils.VarianceMatching.unpack","title":"<code>unpack()</code>","text":"<p>return a tuple of all members of this <code>VarianceMatching</code></p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>def unpack(self):\n    \"\"\"return a tuple of all members of this `VarianceMatching`\"\"\"\n    return (\n        self.var_xyzt,\n        self.var_xyz0,\n        self.var_xy0t,\n        self.var_x0z0,\n        self.var_x00t,\n        self.var_0y0t,\n        self.var_xyn,\n        self.var_xym,\n        self.var_nn,\n        self.var_nm,\n        self.var_mm,\n    )\n</code></pre>"},{"location":"matching_utils/#cupid_matching.matching_utils.compute_margins","title":"<code>compute_margins(muxy, mux0, mu0y)</code>","text":"<p>Computes the margins from the matches and the singles.</p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>def compute_margins(muxy: np.ndarray, mux0: np.ndarray, mu0y: np.ndarray) -&gt; TwoArrays:\n    \"\"\"Computes the margins from the matches and the singles.\"\"\"\n    n = np.sum(muxy, 1) + mux0\n    m = np.sum(muxy, 0) + mu0y\n    return n, m\n</code></pre>"},{"location":"matching_utils/#cupid_matching.matching_utils.get_evals","title":"<code>get_evals(fun, mus, additional_parameters=None)</code>","text":"<p>evaluates fun(mus, additional_parameters)</p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>def get_evals(\n    fun: MatchingFunction, mus: Matching, additional_parameters: list | None = None\n) -&gt; np.ndarray:\n    \"\"\"evaluates fun(mus, additional_parameters)\"\"\"\n    vals = fun(mus, additional_parameters)\n    return cast(np.ndarray, vals)\n</code></pre>"},{"location":"matching_utils/#cupid_matching.matching_utils.get_margins","title":"<code>get_margins(mus)</code>","text":"<p>computes the numbers of each type from the matching patterns</p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>def get_margins(mus: Matching) -&gt; TwoArrays:\n    \"\"\"computes the numbers of each type from the matching patterns\"\"\"\n    _, _, _, n, m = mus.unpack()\n    return n, m\n</code></pre>"},{"location":"matching_utils/#cupid_matching.matching_utils.get_singles","title":"<code>get_singles(muxy, n, m)</code>","text":"<p>Computes the numbers of singles from the matches and the margins.</p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>def get_singles(muxy: np.ndarray, n: np.ndarray, m: np.ndarray) -&gt; TwoArrays:\n    \"\"\"Computes the numbers of singles from the matches and the margins.\"\"\"\n    mux0 = n - np.sum(muxy, 1)\n    mu0y = m - np.sum(muxy, 0)\n    return mux0, mu0y\n</code></pre>"},{"location":"matching_utils/#cupid_matching.matching_utils.simulate_sample_from_mus","title":"<code>simulate_sample_from_mus(mus, n_households, no_singles=False, seed=None)</code>","text":"<p>Draw a sample of <code>n_households</code> from the matching patterns in <code>mus</code></p> <p>Parameters:</p> Name Type Description Default <code>mus</code> <code>Matching</code> <p>the matching patterns</p> required <code>n_households</code> <code>int</code> <p>the number of households requested</p> required <code>no_singles</code> <code>bool</code> <p>if <code>True</code>, this is a model w/o singles</p> <code>False</code> <code>seed</code> <code>int | None</code> <p>an integer seed for the random number generator</p> <code>None</code> <p>Returns:</p> Type Description <code>Matching</code> <p>the sample matching patterns</p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>def simulate_sample_from_mus(\n    mus: Matching, n_households: int, no_singles: bool = False, seed: int | None = None\n) -&gt; Matching:\n    \"\"\"Draw a sample of `n_households` from the matching patterns in `mus`\n\n    Args:\n        mus: the matching patterns\n        n_households: the number of households requested\n        no_singles: if `True`, this is a model w/o singles\n        seed: an integer seed for the random number generator\n\n    Returns:\n        the sample matching patterns\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    muxy, mux0, mu0y, _, _ = mus.unpack()\n    X, Y = muxy.shape\n    # stack all probabilities\n    XY = X * Y\n    # make sure we have no zeros\n    _MU_EPS = min(1, int(1e-3 * n_households))\n    if no_singles:\n        pvec = muxy.reshape(XY)\n        pvec /= np.sum(pvec)\n        matches = rng.multinomial(n_households, pvec)\n        muxy_sim = matches.reshape((X, Y))\n        mux0_sim = np.full(X, _MU_EPS)\n        mu0y_sim = np.full(Y, _MU_EPS)\n    else:\n        num_choices = XY + X + Y\n        pvec = np.zeros(num_choices)\n        pvec[:XY] = muxy.reshape(XY)\n        pvec[XY : (XY + X)] = mux0\n        pvec[(XY + X) :] = mu0y\n        pvec /= np.sum(pvec)\n        matches = rng.multinomial(n_households, pvec)\n        muxy_sim = matches[:XY].reshape((X, Y))\n        mux0_sim = matches[XY : (XY + X)]\n        mu0y_sim = matches[(XY + X) :]\n        muxy_sim += _MU_EPS\n        mux0_sim += _MU_EPS\n        mu0y_sim += _MU_EPS\n    n_sim, m_sim = compute_margins(muxy_sim, mux0_sim, mu0y_sim)\n    mus_sim = Matching(muxy=muxy_sim, n=n_sim, m=m_sim, no_singles=no_singles)\n    return mus_sim\n</code></pre>"},{"location":"matching_utils/#cupid_matching.matching_utils.var_divide","title":"<code>var_divide(varmus, d)</code>","text":"<p>divide all members by the same number</p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>def var_divide(varmus: VarianceMatching, d: float) -&gt; VarianceMatching:\n    \"\"\"divide all members by the same number\"\"\"\n    vardiv = VarianceMatching(\n        varmus.var_xyzt / d,\n        varmus.var_xyz0 / d,\n        varmus.var_xy0t / d,\n        varmus.var_x0z0 / d,\n        varmus.var_x00t / d,\n        varmus.var_0y0t / d,\n    )\n    return vardiv\n</code></pre>"},{"location":"matching_utils/#cupid_matching.matching_utils.variance_muhat","title":"<code>variance_muhat(muhat)</code>","text":"<p>Computes the unweighted variance-covariance matrix of the observed matching patterns</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a <code>Matching</code> object</p> required <p>Returns:</p> Type Description <code>VarianceMatching</code> <p>the corresponding <code>VarianceMatching</code> object</p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>def variance_muhat(muhat: Matching) -&gt; VarianceMatching:\n    \"\"\"\n    Computes the unweighted variance-covariance matrix of the observed matching patterns\n\n    Args:\n        muhat: a `Matching` object\n\n    Returns:\n        the corresponding `VarianceMatching` object\n    \"\"\"\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    XY = X * Y\n\n    # normalize all proportions\n    n_households = muhat.n_households\n    muxy_norm = (muxy / n_households).ravel()\n    mux0_norm = mux0 / n_households\n    mu0y_norm = mu0y / n_households\n\n    # we construct the variance of (muxy, mux0, mu0y)\n    # variance of muxy\n    v_xyzt = np.diag(muxy_norm) - np.outer(muxy_norm, muxy_norm)\n    if muhat.no_singles:\n        v_xyz0 = np.zeros((XY, X))\n        v_xy0t = np.zeros((XY, Y))\n        v_x0z0 = np.zeros((X, X))\n        v_x00t = np.zeros((X, Y))\n        v_0y0t = np.zeros((Y, Y))\n    else:\n        # covariance of muxy and mux0\n        v_xyz0 = -np.outer(muxy_norm, mux0_norm)\n        # covariance of muxy and mu0y\n        v_xy0t = -np.outer(muxy_norm, mu0y_norm)\n        # variance of mux0\n        v_x0z0 = np.diag(mux0_norm) - np.outer(mux0_norm, mux0_norm)\n        # covariance of mux0 and mu0y\n        v_x00t = -np.outer(mux0_norm, mu0y_norm)\n        # variance of mu0y\n        v_0y0t = np.diag(mu0y_norm) - np.outer(mu0y_norm, mu0y_norm)\n\n    v_xyzt *= n_households\n    v_xyz0 *= n_households\n    v_xy0t *= n_households\n    v_x0z0 *= n_households\n    v_x00t *= n_households\n    v_0y0t *= n_households\n\n    varmus = VarianceMatching(\n        var_xyzt=v_xyzt,\n        var_xyz0=v_xyz0,\n        var_xy0t=v_xy0t,\n        var_x0z0=v_x0z0,\n        var_x00t=v_x00t,\n        var_0y0t=v_0y0t,\n    )\n    return varmus\n</code></pre>"},{"location":"min_distance/","title":"<code>min_distance</code> module","text":"<p>Estimates semilinear separable models with a given entropy function. The entropy function and the surplus matrix must both be linear in the parameters.</p>"},{"location":"min_distance/#cupid_matching.min_distance.estimate_semilinear_mde","title":"<code>estimate_semilinear_mde(muhat, phi_bases, entropy, no_singles=False, additional_parameters=None, initial_weighting_matrix=None, verbose=False)</code>","text":"<p>Estimates the parameters of the distributions and of the base functions.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>the observed <code>Matching</code></p> required <code>phi_bases</code> <code>ndarray</code> <p>an (X, Y, K) array of bases</p> required <code>entropy</code> <code>EntropyFunctions</code> <p>an <code>EntropyFunctions</code> object</p> required <code>no_singles</code> <code>bool</code> <p>if <code>True</code>, only couples are observed</p> <code>False</code> <code>additional_parameters</code> <code>list | None</code> <p>additional parameters of the distribution of errors, if any</p> <code>None</code> <code>initial_weighting_matrix</code> <code>ndarray | None</code> <p>if specified, used as the weighting matrix for the first step when <code>entropy.param_dependent</code> is <code>True</code></p> <code>None</code> <code>verbose</code> <code>bool</code> <p>prints stuff if <code>True</code></p> <code>False</code> <p>Returns:</p> Type Description <code>MDEResults</code> <p>an <code>MDEResults</code> instance</p> Example <pre><code># We simulate a Choo and Siow homoskedastic marriage market\n#  and we estimate a gender-heteroskedastic model on the simulated data.\nX, Y, K = 10, 20, 2\nn_households = int(1e6)\nlambda_true = np.random.randn(K)\nphi_bases = np.random.randn(X, Y, K)\nn = np.ones(X)\nm = np.ones(Y)\nPhi = phi_bases @ lambda_true\nchoo_siow_instance = ChooSiowPrimitives(Phi, n, m)\nmus_sim = choo_siow_instance.simulate(n_households)\nchoo_siow_instance.describe()\n\nentropy_model =  entropy_choo_siow_gender_heteroskedastic_numeric\nn_alpha = 1\ntrue_alpha = np.ones(n_alpha)\ntrue_coeffs = np.concatenate((true_alpha, lambda_true))\n\nprint_stars(entropy_model.description)\n\nmde_results = estimate_semilinear_mde(\n    mus_sim, phi_bases, entropy_model)\n\nmde_results.print_results(true_coeffs=true_coeffs, n_alpha=1)\n</code></pre> Source code in <code>cupid_matching/min_distance.py</code> <pre><code>def estimate_semilinear_mde(\n    muhat: Matching,\n    phi_bases: np.ndarray,\n    entropy: EntropyFunctions,\n    no_singles: bool = False,\n    additional_parameters: list | None = None,\n    initial_weighting_matrix: np.ndarray | None = None,\n    verbose: bool = False,\n) -&gt; MDEResults:\n    \"\"\"\n    Estimates the parameters of the distributions and of the base functions.\n\n    Args:\n        muhat: the observed `Matching`\n        phi_bases: an (X, Y, K) array of bases\n        entropy: an `EntropyFunctions` object\n        no_singles: if `True`, only couples are observed\n        additional_parameters: additional parameters of the distribution of errors,\n            if any\n        initial_weighting_matrix: if specified, used as the weighting matrix\n            for the first step when `entropy.param_dependent` is `True`\n        verbose: prints stuff if `True`\n\n    Returns:\n        an `MDEResults` instance\n\n    Example:\n        ```py\n        # We simulate a Choo and Siow homoskedastic marriage market\n        #  and we estimate a gender-heteroskedastic model on the simulated data.\n        X, Y, K = 10, 20, 2\n        n_households = int(1e6)\n        lambda_true = np.random.randn(K)\n        phi_bases = np.random.randn(X, Y, K)\n        n = np.ones(X)\n        m = np.ones(Y)\n        Phi = phi_bases @ lambda_true\n        choo_siow_instance = ChooSiowPrimitives(Phi, n, m)\n        mus_sim = choo_siow_instance.simulate(n_households)\n        choo_siow_instance.describe()\n\n        entropy_model =  entropy_choo_siow_gender_heteroskedastic_numeric\n        n_alpha = 1\n        true_alpha = np.ones(n_alpha)\n        true_coeffs = np.concatenate((true_alpha, lambda_true))\n\n        print_stars(entropy_model.description)\n\n        mde_results = estimate_semilinear_mde(\n            mus_sim, phi_bases, entropy_model)\n\n        mde_results.print_results(true_coeffs=true_coeffs, n_alpha=1)\n        ```\n\n    \"\"\"\n    X, Y, K = check_args_mde(muhat, phi_bases)\n    XY = X * Y\n    X1Y1 = (X - 1) * (Y - 1)\n    parameterized_entropy = entropy.parameter_dependent\n    S_mat = get_initial_weighting_matrix(\n        parameterized_entropy, initial_weighting_matrix, XY\n    )\n\n    phi_mat = make_XY_K_mat(phi_bases)\n\n    # if there are no singles, we need to premultiply by the randomized double differencing matrix $D_2$\n    if no_singles:\n        D2_mat, rank_D2 = make_D2_matrix(X, Y)\n        if rank_D2 != X1Y1:\n            bs_error_abort(f\"The D2 matrix should have rank {X1Y1} not {rank_D2}\")\n        phi_mat = D2_mat @ phi_mat\n        check_indep_phi_no_singles(phi_mat, X, Y)\n\n    e0_vals = entropy.e0_fun(muhat, additional_parameters)\n    e0_hat = e0_vals.ravel()\n\n    # if there are no singles, we need to premultiply by the randomized double differencing matrix $D_2$\n    if no_singles:\n        e0_hat = D2_mat @ e0_hat\n\n    if not parameterized_entropy:  # we only have e0(mu,r)\n        n_pars = K\n        hessian = entropy.hessian\n        if hessian == \"provided\":  # we have the analytical hessian\n            e0_derivative = cast(EntropyHessians, entropy.e0_derivative)\n            hessian_components_mumu = e0_derivative[0](muhat, additional_parameters)\n            hessian_components_mur = e0_derivative[1](muhat, additional_parameters)\n        else:  # we use a numerical hessian\n            hessian_components_mumu, hessian_components_mur = numeric_hessian(\n                entropy,\n                muhat,\n                additional_parameters=additional_parameters,\n            )\n\n        hessians_both = make_hessian_mde(\n            hessian_components_mumu, hessian_components_mur\n        )\n\n        # if there are no singles, we need to premultiply by the randomized double differencing matrix $D_2$\n        if no_singles:\n            S_mat = get_optimal_weighting_matrix(\n                muhat, hessians_both, no_singles, D2_mat\n            )\n        else:\n            S_mat = get_optimal_weighting_matrix(muhat, hessians_both)\n\n        estimated_coefficients, varcov_coefficients = compute_estimates(\n            phi_mat, S_mat, e0_hat\n        )\n        stderrs_coefficients = np.sqrt(np.diag(varcov_coefficients))\n        est_Phi = phi_mat @ estimated_coefficients\n        residuals = est_Phi + e0_hat\n    else:  # parameterized entropy: e0(mu,r) + e(mu,r) . alpha\n        e_fun = cast(MatchingFunction, entropy.e_fun)\n        e_vals = e_fun(muhat, additional_parameters)\n        e_hat = make_XY_K_mat(e_vals)\n\n        # if there are no singles, we need to premultiply by the randomized double differencing matrix $D_2$\n        if no_singles:\n            e0_hat = D2_mat @ e0_hat\n\n        F_hat = np.column_stack((e_hat, phi_mat))\n        n_pars = e_hat.shape[1] + K\n\n        # first pass with an initial weighting matrix\n        first_coeffs, _ = compute_estimates(F_hat, cast(np.ndarray, S_mat), e0_hat)\n        first_alpha = first_coeffs[:-K]\n\n        if verbose:\n            print_stars(\"First-stage estimates:\")\n            print(first_coeffs)\n\n        # compute the efficient weighting matrix\n        hessian = entropy.hessian\n        if hessian == \"provided\":  # we have the analytical hessian\n            e0_derivative = cast(EntropyHessians, entropy.e0_derivative)\n            e_derivative = cast(EntropyHessians, entropy.e_derivative)\n            e0_derivative_mumu = cast(EntropyHessianMuMu, e0_derivative[0])\n            e0_derivative_mur = cast(EntropyHessianMuR, e0_derivative[1])\n            e_derivative_mumu = cast(EntropyHessianMuMu, e_derivative[0])\n            e_derivative_mur = cast(EntropyHessianMuR, e_derivative[1])\n            hessian_components_mumu_e0 = e0_derivative_mumu(\n                muhat, additional_parameters\n            )\n            hessian_components_mur_e0 = e0_derivative_mur(muhat, additional_parameters)\n            hessian_components_mumu_e = e_derivative_mumu(muhat, additional_parameters)\n            hessian_components_mur_e = e_derivative_mur(muhat, additional_parameters)\n\n            if verbose:\n                print_stars(\"First-stage estimates:\")\n                print(first_coeffs)\n\n            hessian_components_mumu = (\n                hessian_components_mumu_e0[i]\n                + hessian_components_mumu_e[i] @ first_alpha\n                for i in range(3)\n            )\n            hessian_components_mur = (\n                hessian_components_mur_e0[i] + hessian_components_mur_e[i] @ first_alpha\n                for i in range(3)\n            )\n        else:  # we use a numeric hessian\n            hessian_components_mumu, hessian_components_mur = numeric_hessian(\n                entropy,\n                muhat,\n                alpha=first_alpha,\n                additional_parameters=additional_parameters,\n            )\n        hessians_both = make_hessian_mde(\n            hessian_components_mumu, hessian_components_mur\n        )\n\n        # if there are no singles, we need to premultiply by the randomized double differencing matrix $D_2$\n        if no_singles:\n            S_mat = get_optimal_weighting_matrix(\n                muhat, hessians_both, no_singles, D2_mat\n            )\n        else:\n            S_mat = get_optimal_weighting_matrix(muhat, hessians_both)\n\n        # second pass with the efficient weighting matrix\n        estimated_coefficients, varcov_coefficients = compute_estimates(\n            F_hat, S_mat, e0_hat\n        )\n        est_alpha, est_beta = (\n            estimated_coefficients[:-K],\n            estimated_coefficients[-K:],\n        )\n        stderrs_coefficients = np.sqrt(np.diag(varcov_coefficients))\n        est_Phi = phi_mat @ est_beta\n        residuals = est_Phi + e0_hat + e_hat @ est_alpha\n\n    value_obj = residuals.T @ S_mat @ residuals\n    ndf = X1Y1 - n_pars if no_singles else XY - n_pars\n    test_stat = value_obj\n    muxyhat, *_, nhat, mhat = muhat.unpack()\n    n_individuals = np.sum(nhat) + np.sum(mhat)\n    n_households = n_individuals - np.sum(muxyhat)\n\n    est_Phi = est_Phi.reshape((X - 1, Y - 1)) if no_singles else est_Phi.reshape((X, Y))\n\n    results = MDEResults(\n        X=X,\n        Y=Y,\n        K=K,\n        number_households=n_households,\n        estimated_coefficients=estimated_coefficients,\n        varcov_coefficients=varcov_coefficients,\n        stderrs_coefficients=stderrs_coefficients,\n        estimated_Phi=est_Phi,\n        test_statistic=test_stat,\n        ndf=ndf,\n        test_pvalue=sts.chi2.sf(test_stat, ndf),\n        parameterized_entropy=parameterized_entropy,\n    )\n    return results\n</code></pre>"},{"location":"min_distance_utils/","title":"<code>min_distance_utils</code> module","text":"<p>Utility programs used in <code>min_distance.py</code>.</p>"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.MDEResults","title":"<code>MDEResults</code>  <code>dataclass</code>","text":"<p>The results from minimum-distance estimation and testing.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>int</code> <p>the number of types of men</p> required <code>Y</code> <code>int</code> <p>the number of types of women</p> required <code>K</code> <code>int</code> <p>the number of bases</p> required <code>number_households</code> <code>int</code> <p>the number of households in the sample</p> required <code>estimated_coefficients</code> <code>ndarray</code> <p>the estimated coefficients</p> required <code>varcov_coefficients</code> <code>ndarray</code> <p>their eetimated var-covar</p> required <code>stderrs_coefficients</code> <code>ndarray</code> <p>their estimated stderrs</p> required <code>estimated_Phi</code> <code>ndarray</code> <p>the estimated joint surplus</p> required <code>test_statistic</code> <code>float</code> <p>the value of the misspecification statistic</p> required <code>test_pvalue</code> <code>float</code> <p>the p-value of the test</p> required <code>ndf</code> <code>int</code> <p>the number of degrees of freedom</p> required <code>parameterized_entropy</code> <code>bool | None</code> <p>True if the derivative of the entropy has unknown parameters</p> <code>False</code> Source code in <code>cupid_matching/min_distance_utils.py</code> <pre><code>@dataclass\nclass MDEResults:\n    \"\"\"\n    The results from minimum-distance estimation and testing.\n\n    Args:\n        X: the number of types of men\n        Y: the number of types of women\n        K: the number of bases\n        number_households: the number of households in the sample\n        estimated_coefficients: the estimated coefficients\n        varcov_coefficients: their eetimated var-covar\n        stderrs_coefficients: their estimated stderrs\n        estimated_Phi: the estimated joint surplus\n        test_statistic: the value of the misspecification statistic\n        test_pvalue: the p-value of the test\n        ndf: the number of degrees of freedom\n        parameterized_entropy: True if the derivative of the entropy has unknown parameters\n    \"\"\"\n\n    X: int\n    Y: int\n    K: int\n    number_households: int\n    estimated_coefficients: np.ndarray\n    varcov_coefficients: np.ndarray\n    stderrs_coefficients: np.ndarray\n    estimated_Phi: np.ndarray\n    test_statistic: float\n    test_pvalue: float\n    ndf: int\n    parameterized_entropy: bool | None = False\n\n    def __str__(self):\n        line_stars = \"*\" * 80 + \"\\n\"\n        if self.parameterized_entropy:\n            n_alpha = self.estimated_coefficients.size - self.K\n            entropy_str = f\"     The entropy has {n_alpha} parameters.\"\n        else:\n            entropy_str = \"     The entropy is parameter-free.\"\n            n_alpha = 0\n        model_str = f\"The data has {self.number_households} households\\n\\n\"\n        model_str += f\"The model has {self.X}x{self.Y} margins\\n {entropy_str} \\n\"\n        model_str += f\"We use {self.K} basis functions.\\n\\n\"\n        repr_str = line_stars + model_str\n        repr_str += \"The estimated coefficients (and their standard errors) are\\n\\n\"\n        if self.parameterized_entropy:\n            for i, coeff in enumerate(self.estimated_coefficients[:n_alpha]):\n                repr_str += (\n                    f\"   alpha({i + 1}): {coeff: &gt; 10.3f}  \"\n                    + f\"({self.stderrs_coefficients[i]: .3f})\\n\"\n                )\n            repr_str += \"\\n\"\n        for i, coeff in enumerate(self.estimated_coefficients[n_alpha:]):\n            repr_str += (\n                f\"   base {i + 1}: {coeff: &gt; 10.3f} \"\n                + f\"({self.stderrs_coefficients[n_alpha + i]: .3f})\\n\"\n            )\n        repr_str += \"\\nSpecification test:\\n\"\n        repr_str += (\n            f\"   the value of the test statistic is {self.test_statistic: &gt; 10.3f}\\n\"\n        )\n        repr_str += (\n            f\"     for a chi2({self.ndf}), the p-value is {self.test_pvalue: &gt; 10.3f}\\n\"\n        )\n        return repr_str + line_stars\n\n    def print_results(\n        self, true_coeffs: np.ndarray | None = None, n_alpha: int = 0\n    ) -&gt; None | float:\n        estimates = self.estimated_coefficients\n        stderrs = self.stderrs_coefficients\n\n        if true_coeffs is not None:\n            repr_str = (\n                \"The true and estimated coefficients \"\n                + \"(and their standard errors) are\\n\\n\"\n            )\n            for i, coeff in enumerate(estimates[:n_alpha]):\n                repr_str += f\"   alpha({i + 1}): {true_coeffs[i]: &gt; 10.3f}\"\n                repr_str += f\"{coeff: &gt; 10.3f}  ({stderrs[i]: &gt; 10.3f})\\n\"\n                repr_str += \"\\n\"\n            for i, coeff in enumerate(estimates[n_alpha:]):\n                j = n_alpha + i\n                repr_str += (\n                    f\"   base {i + 1}: {true_coeffs[j]: &gt; 10.3f}  \"\n                    + f\"{coeff: &gt; 10.3f}  ({stderrs[j]: &gt; 10.3f})\\n\"\n                )\n            print_stars(repr_str)\n            discrepancy = npmaxabs(true_coeffs - estimates)\n            print_stars(\n                \"The largest difference between true and estimated coefficients is\"\n                f\" {discrepancy: .2e}\"\n            )\n        else:\n            repr_str = (\n                \"The estimated coefficients \" + \"(and their standard errors) are\\n\\n\"\n            )\n            for i, coeff in enumerate(estimates[:n_alpha]):\n                repr_str + f\"{coeff: &gt; 10.3f}  ({stderrs[i]: &gt; 10.3f})\\n\"\n                repr_str += \"\\n\"\n            for i, coeff in enumerate(estimates[n_alpha:]):\n                j = n_alpha + i\n                repr_str += f\"{coeff: &gt; 10.3f}  ({stderrs[j]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n\n        repr_str = \"\\nSpecification test:\\n\"\n        repr_str += (\n            \"   the value of the test statistic is \"\n            + f\"{self.test_statistic: &gt; 10.3f}\\n\"\n        )\n        repr_str += (\n            f\"     for a chi2({self.ndf}), \"\n            + f\"the p-value is {self.test_pvalue: &gt; 10.3f}\\n\"\n        )\n        print_stars(repr_str)\n        if true_coeffs is not None:\n            return cast(float, discrepancy)\n        return None\n</code></pre>"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.check_args_mde","title":"<code>check_args_mde(muhat, phi_bases)</code>","text":"<p>check that the arguments to the MDE are consistent</p> Source code in <code>cupid_matching/min_distance_utils.py</code> <pre><code>def check_args_mde(muhat: Matching, phi_bases: np.ndarray) -&gt; tuple[int, int, int]:\n    \"\"\"check that the arguments to the MDE are consistent\"\"\"\n    muxyhat, *_ = muhat.unpack()\n    X, Y = muxyhat.shape\n    ndims_phi = phi_bases.ndim\n    if ndims_phi != 3:\n        bs_error_abort(f\"phi_bases should have 3 dimensions, not {ndims_phi}\")\n    Xp, Yp, K = phi_bases.shape\n    if Xp != X or Yp != Y:\n        bs_error_abort(\n            f\"phi_bases should have shape ({X}, {Y}, {K}) not ({Xp}, {Yp}, {K})\"\n        )\n    return X, Y, K\n</code></pre>"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.check_indep_phi_no_singles","title":"<code>check_indep_phi_no_singles(D2_phi, X, Y)</code>","text":"<p>check that the double difference of the phi matrix has full column rank;     if so, return it</p> <p>Parameters:</p> Name Type Description Default <code>D2_phi</code> <code>ndarray</code> <p>an \\((X*Y, K)\\) matrix of double differences</p> required <code>X</code> <code>int</code> <p>number of types of men</p> required <code>Y</code> <code>int</code> <p>number of types of women</p> required <p>Returns:</p> Type Description <code>None</code> <p>nothing</p> Source code in <code>cupid_matching/min_distance_utils.py</code> <pre><code>def check_indep_phi_no_singles(D2_phi: np.ndarray, X: int, Y: int) -&gt; None:\n    \"\"\"check that the double difference of the phi matrix has full column rank;\n        if so, return it\n\n    Args:\n        D2_phi: an $(X*Y, K)$ matrix of double differences\n        X: number of types of men\n        Y: number of types of women\n\n    Returns:\n        nothing\n    \"\"\"\n    K = D2_phi.shape[1]\n    actual_rank = np.linalg.matrix_rank(D2_phi)  # Compute the matrix rank\n    if actual_rank != D2_phi.shape[1]:\n        bs_error_abort(\n            f\"We have {K} basis functions but phi_mat only has rank {actual_rank}.\"\n        )\n</code></pre>"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.compute_estimates","title":"<code>compute_estimates(M, S_mat, d)</code>","text":"<p>Returns the QGLS estimates and their variance-covariance.</p> <p>Parameters:</p> Name Type Description Default <code>M</code> <code>ndarray</code> <p>an (XY,p) matrix</p> required <code>S_mat</code> <code>ndarray</code> <p>an (XY, XY) weighting matrix</p> required <code>d</code> <code>ndarray</code> <p>an XY-vector</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>the p-vector of estimates and their estimated (p,p) variance</p> Source code in <code>cupid_matching/min_distance_utils.py</code> <pre><code>def compute_estimates(\n    M: np.ndarray, S_mat: np.ndarray, d: np.ndarray\n) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Returns the QGLS estimates and their variance-covariance.\n\n    Args:\n        M: an (XY,p) matrix\n        S_mat: an (XY, XY) weighting matrix\n        d: an XY-vector\n\n    Returns:\n        the p-vector of estimates and their estimated (p,p) variance\n    \"\"\"\n    M_T = M.T\n    M_S_d = M_T @ S_mat @ d\n    M_S_M = M_T @ S_mat @ M\n    est_coeffs = -spla.solve(M_S_M, M_S_d)\n    varcov_coeffs = spla.inv(M_S_M)\n    return est_coeffs, varcov_coeffs\n</code></pre>"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.get_initial_weighting_matrix","title":"<code>get_initial_weighting_matrix(parameterized_entropy, initial_weighting_matrix, XY)</code>","text":"<p>returns the initial weighting matrix for the MDE when the entropy is parameterized</p> <p>Parameters:</p> Name Type Description Default <code>parameterized_entropy</code> <code>bool</code> <p>if <code>True</code>, the entropy has unknown parameters</p> required <code>initial_weighting_matrix</code> <code>ndarray | None</code> <p>the initial weighting matrix, if provided</p> required <code>XY</code> <code>int</code> <p>= X*Y</p> required <p>Returns:</p> Type Description <code>ndarray | None</code> <p>the initial_weighting_matrix, or None if the entropy is not parameterized.</p> Source code in <code>cupid_matching/min_distance_utils.py</code> <pre><code>def get_initial_weighting_matrix(\n    parameterized_entropy: bool, initial_weighting_matrix: np.ndarray | None, XY: int\n) -&gt; np.ndarray | None:\n    \"\"\"returns the initial weighting matrix for the MDE when the entropy is parameterized\n\n    Args:\n        parameterized_entropy: if `True`, the entropy has unknown parameters\n        initial_weighting_matrix: the initial weighting matrix, if provided\n        XY: = X*Y\n\n    Returns:\n        the initial_weighting_matrix, or None if the entropy is not parameterized.\n    \"\"\"\n    if parameterized_entropy:\n        if initial_weighting_matrix is None:\n            print_stars(\n                \"Using the identity matrix as weighting matrix in the first step.\"\n            )\n            S_mat = np.eye(XY)\n        else:\n            S_mat = initial_weighting_matrix\n        return S_mat\n    else:\n        return None\n</code></pre>"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.get_optimal_weighting_matrix","title":"<code>get_optimal_weighting_matrix(muhat, hessians_both, no_singles=False, D2_mat=None)</code>","text":"<p>compute the \\(S^\u0007st\\) matrix used in the second step of the MDE</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>the observed <code>Matching</code></p> required <code>hessians_both</code> <code>ndarray</code> <p>the Hessian of the entropy function</p> required Source code in <code>cupid_matching/min_distance_utils.py</code> <pre><code>def get_optimal_weighting_matrix(\n    muhat: Matching,\n    hessians_both: np.ndarray,\n    no_singles: bool = False,\n    D2_mat: np.ndarray | None = None,\n) -&gt; np.ndarray:\n    \"\"\"compute the $S^\\ast$ matrix used in the second step of the MDE\n\n    Args:\n        muhat: the observed `Matching`\n        hessians_both: the Hessian of the entropy function\n    \"\"\"\n    var_muhat = variance_muhat(muhat)\n    var_munm = var_muhat.var_munm\n    var_entropy_gradient = hessians_both @ var_munm @ hessians_both.T\n    if no_singles:\n        if D2_mat is None:\n            bs_error_abort(\"D2_mat should not be None when no_singles is True\")\n        else:\n            var_entropy_gradient = D2_mat @ var_entropy_gradient @ D2_mat.T\n    S_mat = spla.inv(var_entropy_gradient)\n    return cast(np.ndarray, S_mat)\n</code></pre>"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.make_D2_matrix","title":"<code>make_D2_matrix(X, Y)</code>","text":"<p>create the double difference matrix for use w/o singles</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>int</code> <p>number of types of men</p> required <code>Y</code> <code>int</code> <p>number of types of women</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, int]</code> <p>an (r, XY) matrix and  its rank r</p> Source code in <code>cupid_matching/min_distance_utils.py</code> <pre><code>def make_D2_matrix(X: int, Y: int) -&gt; tuple[np.ndarray, int]:\n    \"\"\"create the double difference matrix for use w/o singles\n\n    Args:\n        X: number of types of men\n        Y: number of types of women\n\n    Returns:\n        an (r, XY) matrix and  its rank r\n    \"\"\"\n    XY = X * Y\n    D2_mat = np.ones((XY, XY)) / XY + np.eye(XY)\n    for x in range(X):\n        slice_x = slice(x * Y, x * Y + Y)\n        D2_mat[slice_x, slice_x] -= 1.0 / Y\n    for y in range(Y):\n        slice_y = slice(y, XY, Y)\n        D2_mat[slice_y, slice_y] -= 1.0 / X\n    rank_D2 = np.linalg.matrix_rank(D2_mat)\n    rng = np.random.default_rng(453)\n    A_mat = rng.uniform(size=(rank_D2, XY))\n    D2_mat = A_mat @ D2_mat\n    rank_D2 = np.linalg.matrix_rank(D2_mat)\n    print(f\"\\nThe rank of the double difference matrix D2 is {rank_D2}.\\n\")\n    return D2_mat, rank_D2\n</code></pre>"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.make_hessian_mde","title":"<code>make_hessian_mde(hessian_components_mumu, hessian_components_mur)</code>","text":"<p>reconstitute the Hessian of the entropy function from its components</p> <p>Parameters:</p> Name Type Description Default <code>hessian_components_mumu</code> <code>ThreeArrays</code> <p>the components of the Hesssian wrt \\((\\mu,\\mu)\\)</p> required <code>hessian_components_mur</code> <code>TwoArrays</code> <p>the components of the Hesssian wrt \\((\\mu,r)\\)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: description</p> Source code in <code>cupid_matching/min_distance_utils.py</code> <pre><code>def make_hessian_mde(\n    hessian_components_mumu: ThreeArrays, hessian_components_mur: TwoArrays\n) -&gt; np.ndarray:\n    \"\"\"reconstitute the Hessian of the entropy function from its components\n\n    Args:\n        hessian_components_mumu:  the components of the Hesssian wrt $(\\\\mu,\\\\mu)$\n        hessian_components_mur: the components of the Hesssian wrt $(\\\\mu,r)$\n\n    Returns:\n        np.ndarray: _description_\n    \"\"\"\n    hessian_mumu = fill_hessianMuMu_from_components(hessian_components_mumu)\n    hessian_mur = fill_hessianMuR_from_components(hessian_components_mur)\n    hessians_both = np.concatenate((hessian_mumu, hessian_mur), axis=1)\n    return cast(np.ndarray, hessians_both)\n</code></pre>"},{"location":"model_classes/","title":"<code>model_classes</code> module","text":""},{"location":"model_classes/#cupid_matching.model_classes.NestedLogitPrimitives","title":"<code>NestedLogitPrimitives</code>  <code>dataclass</code>","text":"Source code in <code>cupid_matching/model_classes.py</code> <pre><code>@dataclass\nclass NestedLogitPrimitives:\n    Phi: np.ndarray\n    n: np.ndarray\n    m: np.ndarray\n    nests_for_each_x: (\n        NestsList  # given by user, e.g. [[1, 3], [2,4]] has y=1 and y=3 in first nest\n    )\n    nests_for_each_y: NestsList\n    nests_over_Y: (\n        NestsList  # rebased to zero: the above example becomes [[0, 2], [1,3]]\n    )\n    nests_over_X: NestsList\n    i_nest_of_x: Nest  # mapping x -&gt; n'\n    i_nest_of_y: Nest  # mapping y -&gt; n\n    n_alphas: int\n    mus: Matching | None = None\n    true_alphas: np.ndarray | None = None\n\n    def __init__(\n        self,\n        Phi: np.ndarray,\n        n: np.ndarray,\n        m: np.ndarray,\n        nests_for_each_x: NestsList,\n        nests_for_each_y: NestsList,\n        true_alphas: np.ndarray | None = None,\n    ):\n        \"\"\"\n        We only model two-level nested logit, with {0} as the first nest,\n        and nests and nests parameters that do not depend on the type.\n\n        Args:\n            Phi: the (X,Y) joint surplus matrix\n            n: the X-vector of men margins\n            m: the X-vector of women margins\n            nests_for_each_x: the composition of the nests over 1...Y, a list of r lists\n            nests_for_each_y: the composition of the nests over 1...X, a list of d lists\n            true_alphas: the true nest parameters, if any; should be an (r+d)-vector\n        \"\"\"\n        X, Y = check_matrix(Phi)\n        Xn = check_vector(n)\n        Ym = check_vector(m)\n\n        # we need to rebase the indices to zero\n        self.nests_over_X = change_indices(nests_for_each_y)\n        self.nests_over_Y = change_indices(nests_for_each_x)\n\n        self.n_alphas = len(nests_for_each_y) + len(nests_for_each_x)\n\n        if Xn != X:\n            bs_error_abort(f\"Phi is a ({X}, {Y}) matrix but n has {Xn} elements.\")\n        if Ym != Y:\n            bs_error_abort(f\"Phi is a ({X}, {Y}) matrix but m has {Ym} elements.\")\n\n        if true_alphas is not None:\n            alpha_size = check_vector(true_alphas)\n            if alpha_size != self.n_alphas:\n                bs_error_abort(\n                    f\"true_alphas shoud have {self.n_alphas} elements, not {alpha_size}\"\n                )\n\n        self.Phi = Phi\n        self.n = n\n        self.m = m\n        self.true_alphas = true_alphas\n        self.nests_for_each_x = nests_for_each_x\n        self.nests_for_each_y = nests_for_each_y\n\n        # check that every x is in a nest, and just once\n        nests_check = []\n        i_nest_of_x = np.zeros(X, int)\n        for x in range(X):\n            i_nest_of_x[x] = find_nest_of(self.nests_over_X, x)\n            nests_check.append(i_nest_of_x[x])\n        if -1 in nests_check or len(set(nests_check)) != len(nests_for_each_y):\n            bs_error_abort(\"Check your nests_for_each_y\")\n        # check that every y is in a nest, and just once\n        nests_check = []\n        i_nest_of_y = np.zeros(Y, int)\n        for y in range(Y):\n            i_nest_of_y[y] = find_nest_of(self.nests_over_Y, y)\n            nests_check.append(i_nest_of_y[y])\n        if -1 in nests_check or len(set(nests_check)) != len(nests_for_each_x):\n            bs_error_abort(\"Check your nests_for_each_x\")\n\n        self.i_nest_of_x = i_nest_of_x.tolist()\n        self.i_nest_of_y = i_nest_of_y.tolist()\n\n    def __str__(self):\n        X, Y = self.Phi.shape\n        nmen, nwomen = np.sum(self.n), np.sum(self.m)\n        repr_str = (\n            f\"This is a 2-level nested logit with {nmen} men of {X} types\"\n            + f\" and {nwomen} women of {Y} types.\\n\"\n        )\n        repr_str += (\n            f\" We have {self.n_nests_over_Y} nests over 1...Y \"\n            + f\" and {self.n_nests_over_X} nests over 1...X,\\n\"\n        )\n        if self.true_alphas is None:\n            repr_str += \"     with unspecified nests parameters.\"\n        else:\n            alpha_vals = self.true_alphas\n            repr_str += \"     with respective nests parameters:\\n\"\n            repr_str += f\"    {alpha_vals[: self.n_nests_over_Y]}\\n\"\n            repr_str += f\" and {alpha_vals[self.n_nests_over_Y :]}\\n\"\n        print_stars(repr_str)\n\n    def ipfp_nested_logit_solver(\n        self, tol: float = 1e-9, verbose: bool = False, maxiter: int = 1000\n    ) -&gt; tuple[Matching, np.ndarray, np.ndarray]:\n        \"\"\"Solves for equilibrium in a two-level nested logit market\n        given systematic surplus and margins and nests parameters;\n        does not compute_ the gradient of the matching patterns\n\n        Args:\n            tol: tolerance on change in solution\n            verbose: if `True`, prints information\n            maxiter: maximum number of iterations\n\n        Returns:\n             the matching patterns\n             marg_err_x, marg_err_y: the errors on the margins\n        \"\"\"\n        alphas = self.true_alphas\n        if alphas is None:\n            bs_error_abort(\"cannot solve without nest parameters\")\n        else:\n            alphas = cast(np.ndarray, alphas)\n            n_rhos = len(self.nests_over_Y)\n            n_deltas = len(self.nests_over_X)\n            rhos = alphas[:n_rhos]\n            deltas = alphas[n_rhos:]\n\n        #############################################################################\n        # we solve the equilibrium equations\n        #   starting with a reasonable initial point  muxy, mux0, mu0y = bigc\n        #   it is important that it fit the number of individuals\n        #############################################################################\n\n        n, m = self.n, self.m\n        X, Y = n.size, m.size\n\n        nests_over_X, nests_over_Y = self.nests_over_X, self.nests_over_Y\n        i_nest_of_x, i_nest_of_y = self.i_nest_of_x, self.i_nest_of_y\n\n        rho_vals = rhos[i_nest_of_y]  # rho(n) for y in n in the paper\n        delta_vals = deltas[i_nest_of_x]  # delta(n') for x in n' in the paper\n\n        ephi = npexp(self.Phi / np.add.outer(delta_vals, rho_vals))\n\n        # initial values\n        nindivs = np.sum(n) + np.sum(m)\n        bigc = nindivs / (X + Y + 2.0 * np.sum(ephi))\n\n        mux0, mu0y, muxy = (\n            np.full(X, bigc),\n            np.full(Y, bigc),\n            np.full((X, Y), bigc),\n        )\n        muxn = np.zeros((X, n_rhos))\n        for i_nest_y, nest_y in enumerate(nests_over_Y):\n            muxn[:, i_nest_y] = np.sum(muxy[:, nest_y], 1)\n        muny = np.zeros((n_deltas, Y))\n        for i_nest_x, nest_x in enumerate(nests_over_X):\n            muny[i_nest_x, :] = np.sum(muxy[nest_x, :], 0)\n\n        err_diff = bigc\n        tol_diff = tol * bigc\n        tol_newton = tol\n        max_newton = 2000\n        MIN_REST = 1e-4 * bigc  # used to bound mus below in the Newton iterations\n\n        niter = 0\n        while (err_diff &gt; tol_diff) and (niter &lt; maxiter):  # IPFP main loop\n            # Newton iterates for men\n            err_newton = bigc\n            i_newton = 0\n            while err_newton &gt; tol_newton:\n                gbar = np.zeros(\n                    (X, n_rhos)\n                )  # this will be the $\\bar{G}^x_n$ of the note\n                gbar_pow = np.zeros((X, n_rhos))\n                biga = np.zeros(X)  # this will be the $A_x$ of the note\n                for i_nest_x, nest_x in enumerate(nests_over_X):\n                    # i_nest_x is n' in the paper\n                    delta_x = deltas[i_nest_x]\n                    muny_x = muny[i_nest_x, :]  # mu(n', :)\n                    for x in nest_x:\n                        ephi_x = ephi[x, :]\n                        for i_nest_y, nest_y in enumerate(nests_over_Y):\n                            # i_nest_y is n in the paper\n                            mu_n = muny_x[nest_y]\n                            mu0_n = mu0y[nest_y]\n                            evec_n = ephi_x[nest_y]\n                            rho_n = rhos[i_nest_y]\n                            sum_rd = rho_n + delta_x\n                            mun_term = nppow(mu_n, (delta_x - 1.0) / sum_rd)\n                            mu0_term = nppow(mu0_n, 1.0 / sum_rd)\n                            gbar[x, i_nest_y] = np.sum(mun_term * mu0_term * evec_n)\n                            gbar_pow[x, i_nest_y] = nppow(\n                                gbar[x, i_nest_y], sum_rd / (delta_x + 1.0)\n                            )\n                            biga[x] += gbar_pow[x, i_nest_y]\n\n                # now we take one Newton step for all types of men\n                delta_vals1 = 1.0 + delta_vals\n                mux0_term = nppow(mux0, 1.0 / delta_vals1)\n                bigb = mux0_term * biga  # this is the $B_x$ of the note\n                numer = n * delta_vals1 - delta_vals * bigb\n                lower_bound = np.full(X, MIN_REST)\n                mux0_new = mux0 * np.maximum(\n                    numer / (delta_vals1 * mux0 + bigb), lower_bound\n                )\n                muxn_new = gbar_pow * mux0_term.reshape((-1, 1))\n\n                mux0 = mux0_new\n                muxn = muxn_new\n                errxi = mux0 + np.sum(muxn, 1) - n\n                err_newton = npmaxabs(errxi)\n                i_newton += 1\n                if i_newton &gt; max_newton:\n                    bs_error_abort(\n                        f\"Newton solver failed for men after {max_newton} iterations\"\n                    )\n\n            if verbose:\n                print(\n                    f\"Newton error on men is {err_newton} after {i_newton} iterations\"\n                )\n\n            # Newton iterates for women\n            err_newton = bigc\n            i_newton = 0\n            while err_newton &gt; tol_newton:\n                gbar = np.zeros((Y, n_deltas))\n                gbar_pow = np.zeros((Y, n_deltas))\n                biga = np.zeros(Y)\n                for i_nest_y, nest_y in enumerate(nests_over_Y):\n                    # i_nest_y is n in the paper\n                    rho_y = rhos[i_nest_y]\n                    muxn_y = muxn[:, i_nest_y]  # mu(:, n)\n                    for y in nest_y:\n                        ephi_y = ephi[:, y]\n                        for i_nest_x, nest_x in enumerate(nests_over_X):\n                            mu_n = muxn_y[nest_x]\n                            mu0_n = mux0[nest_x]\n                            evec_n = ephi_y[nest_x]\n                            delta_n = deltas[i_nest_x]\n                            sum_rd = rho_y + delta_n\n                            mun_term = nppow(mu_n, (rho_y - 1.0) / sum_rd)\n                            mu0_term = nppow(mu0_n, 1.0 / sum_rd)\n                            gbar[y, i_nest_x] = np.sum(mun_term * mu0_term * evec_n)\n                            gbar_pow[y, i_nest_x] = nppow(\n                                gbar[y, i_nest_x], sum_rd / (1.0 + rho_y)\n                            )\n                            biga[y] += gbar_pow[y, i_nest_x]\n\n                # now we take one Newton step for all types of women\n                rho_vals1 = 1.0 + rho_vals\n                mu0y_term = nppow(mu0y, 1.0 / rho_vals1)\n                bigb = mu0y_term * biga\n                numer = m * rho_vals1 - rho_vals * bigb\n                lower_bound = np.full(Y, MIN_REST)\n                mu0y_new = mu0y * np.maximum(\n                    numer / (rho_vals1 * mu0y + bigb), lower_bound\n                )\n                muny_new = gbar_pow.T * mu0y_term\n\n                mu0y = mu0y_new\n                muny = muny_new\n                erryi = mu0y + np.sum(muny, 0) - m\n                err_newton = npmaxabs(erryi)\n                i_newton += 1\n                if i_newton &gt; max_newton:\n                    bs_error_abort(\n                        f\"Newton solver failed for women after {max_newton} iterations\"\n                    )\n\n            if verbose:\n                print(\n                    f\"Newton error on women is {err_newton} after {i_newton} iterations\"\n                )\n\n            muxy = np.zeros((X, Y))\n            for x in range(X):\n                i_nest_x = i_nest_of_x[x]  # n'\n                ephi_x = ephi[x, :]\n                mux0_x = mux0[x]\n                muxn_x = muxn[x, :]\n                delta_x = delta_vals[x]\n                muny_x = muny[i_nest_x, :]\n                for y in range(Y):\n                    i_nest_y = i_nest_of_y[y]  # n\n                    mu0y_y = mu0y[y]\n                    rho_y = rho_vals[y]\n                    muxn_xy = muxn_x[i_nest_y]\n                    muny_xy = muny_x[y]\n                    mu_term = (\n                        mux0_x\n                        * mu0y_y\n                        * (muxn_xy ** (rho_y - 1.0))\n                        * (muny_xy ** (delta_x - 1.0))\n                    )\n                    muxy[x, y] = ephi_x[y] * (mu_term ** (1.0 / (delta_x + rho_y)))\n\n            n_sim, m_sim = compute_margins(muxy, mux0, mu0y)\n            marg_err_x, marg_err_y = n_sim - n, m_sim - m\n\n            if verbose:\n                print(\n                    f\"Margin error on men is {marg_err_x} \"\n                    f\" after {niter} IPFP iterations\"\n                )\n                print(\n                    f\"Margin error on women is {marg_err_y} \"\n                    f\" after {niter} IPFP iterations\"\n                )\n            err_diff = npmaxabs(marg_err_x) + npmaxabs(marg_err_y)\n            niter += 1\n\n        n_sim, m_sim = compute_margins(muxy, mux0, mu0y)\n        marg_err_x = n_sim - n\n        marg_err_y = m_sim - m\n\n        if verbose:\n            print(\n                f\"Margin error on men is {npmaxabs(marg_err_x)} after {niter} IPFP\"\n                \" iterations\"\n            )\n            print(\n                f\"Margin error on women is {npmaxabs(marg_err_y)} after {niter} IPFP\"\n                \" iterations\"\n            )\n\n        return Matching(muxy, n, m), marg_err_x, marg_err_y\n\n    def ipfp_solve(self) -&gt; Matching:\n        if self.true_alphas is None:\n            bs_error_abort(\n                \"true_alphas must be specified to solve the nested logit by IPFP.\"\n            )\n        self.mus, err_x, err_y = self.ipfp_nested_logit_solver(verbose=False)\n        return self.mus\n\n    def simulate(self, n_households: int, seed: int | None = None) -&gt; Matching:\n        self.mus = self.ipfp_solve()\n        mus_sim = simulate_sample_from_mus(self.mus, n_households, seed=seed)\n        return mus_sim\n</code></pre>"},{"location":"model_classes/#cupid_matching.model_classes.NestedLogitPrimitives.__init__","title":"<code>__init__(Phi, n, m, nests_for_each_x, nests_for_each_y, true_alphas=None)</code>","text":"<p>We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type.</p> <p>Parameters:</p> Name Type Description Default <code>Phi</code> <code>ndarray</code> <p>the (X,Y) joint surplus matrix</p> required <code>n</code> <code>ndarray</code> <p>the X-vector of men margins</p> required <code>m</code> <code>ndarray</code> <p>the X-vector of women margins</p> required <code>nests_for_each_x</code> <code>NestsList</code> <p>the composition of the nests over 1...Y, a list of r lists</p> required <code>nests_for_each_y</code> <code>NestsList</code> <p>the composition of the nests over 1...X, a list of d lists</p> required <code>true_alphas</code> <code>ndarray | None</code> <p>the true nest parameters, if any; should be an (r+d)-vector</p> <code>None</code> Source code in <code>cupid_matching/model_classes.py</code> <pre><code>def __init__(\n    self,\n    Phi: np.ndarray,\n    n: np.ndarray,\n    m: np.ndarray,\n    nests_for_each_x: NestsList,\n    nests_for_each_y: NestsList,\n    true_alphas: np.ndarray | None = None,\n):\n    \"\"\"\n    We only model two-level nested logit, with {0} as the first nest,\n    and nests and nests parameters that do not depend on the type.\n\n    Args:\n        Phi: the (X,Y) joint surplus matrix\n        n: the X-vector of men margins\n        m: the X-vector of women margins\n        nests_for_each_x: the composition of the nests over 1...Y, a list of r lists\n        nests_for_each_y: the composition of the nests over 1...X, a list of d lists\n        true_alphas: the true nest parameters, if any; should be an (r+d)-vector\n    \"\"\"\n    X, Y = check_matrix(Phi)\n    Xn = check_vector(n)\n    Ym = check_vector(m)\n\n    # we need to rebase the indices to zero\n    self.nests_over_X = change_indices(nests_for_each_y)\n    self.nests_over_Y = change_indices(nests_for_each_x)\n\n    self.n_alphas = len(nests_for_each_y) + len(nests_for_each_x)\n\n    if Xn != X:\n        bs_error_abort(f\"Phi is a ({X}, {Y}) matrix but n has {Xn} elements.\")\n    if Ym != Y:\n        bs_error_abort(f\"Phi is a ({X}, {Y}) matrix but m has {Ym} elements.\")\n\n    if true_alphas is not None:\n        alpha_size = check_vector(true_alphas)\n        if alpha_size != self.n_alphas:\n            bs_error_abort(\n                f\"true_alphas shoud have {self.n_alphas} elements, not {alpha_size}\"\n            )\n\n    self.Phi = Phi\n    self.n = n\n    self.m = m\n    self.true_alphas = true_alphas\n    self.nests_for_each_x = nests_for_each_x\n    self.nests_for_each_y = nests_for_each_y\n\n    # check that every x is in a nest, and just once\n    nests_check = []\n    i_nest_of_x = np.zeros(X, int)\n    for x in range(X):\n        i_nest_of_x[x] = find_nest_of(self.nests_over_X, x)\n        nests_check.append(i_nest_of_x[x])\n    if -1 in nests_check or len(set(nests_check)) != len(nests_for_each_y):\n        bs_error_abort(\"Check your nests_for_each_y\")\n    # check that every y is in a nest, and just once\n    nests_check = []\n    i_nest_of_y = np.zeros(Y, int)\n    for y in range(Y):\n        i_nest_of_y[y] = find_nest_of(self.nests_over_Y, y)\n        nests_check.append(i_nest_of_y[y])\n    if -1 in nests_check or len(set(nests_check)) != len(nests_for_each_x):\n        bs_error_abort(\"Check your nests_for_each_x\")\n\n    self.i_nest_of_x = i_nest_of_x.tolist()\n    self.i_nest_of_y = i_nest_of_y.tolist()\n</code></pre>"},{"location":"model_classes/#cupid_matching.model_classes.NestedLogitPrimitives.ipfp_nested_logit_solver","title":"<code>ipfp_nested_logit_solver(tol=1e-09, verbose=False, maxiter=1000)</code>","text":"<p>Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute_ the gradient of the matching patterns</p> <p>Parameters:</p> Name Type Description Default <code>tol</code> <code>float</code> <p>tolerance on change in solution</p> <code>1e-09</code> <code>verbose</code> <code>bool</code> <p>if <code>True</code>, prints information</p> <code>False</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations</p> <code>1000</code> <p>Returns:</p> Type Description <code>Matching</code> <p>the matching patterns</p> <code>ndarray</code> <p>marg_err_x, marg_err_y: the errors on the margins</p> Source code in <code>cupid_matching/model_classes.py</code> <pre><code>def ipfp_nested_logit_solver(\n    self, tol: float = 1e-9, verbose: bool = False, maxiter: int = 1000\n) -&gt; tuple[Matching, np.ndarray, np.ndarray]:\n    \"\"\"Solves for equilibrium in a two-level nested logit market\n    given systematic surplus and margins and nests parameters;\n    does not compute_ the gradient of the matching patterns\n\n    Args:\n        tol: tolerance on change in solution\n        verbose: if `True`, prints information\n        maxiter: maximum number of iterations\n\n    Returns:\n         the matching patterns\n         marg_err_x, marg_err_y: the errors on the margins\n    \"\"\"\n    alphas = self.true_alphas\n    if alphas is None:\n        bs_error_abort(\"cannot solve without nest parameters\")\n    else:\n        alphas = cast(np.ndarray, alphas)\n        n_rhos = len(self.nests_over_Y)\n        n_deltas = len(self.nests_over_X)\n        rhos = alphas[:n_rhos]\n        deltas = alphas[n_rhos:]\n\n    #############################################################################\n    # we solve the equilibrium equations\n    #   starting with a reasonable initial point  muxy, mux0, mu0y = bigc\n    #   it is important that it fit the number of individuals\n    #############################################################################\n\n    n, m = self.n, self.m\n    X, Y = n.size, m.size\n\n    nests_over_X, nests_over_Y = self.nests_over_X, self.nests_over_Y\n    i_nest_of_x, i_nest_of_y = self.i_nest_of_x, self.i_nest_of_y\n\n    rho_vals = rhos[i_nest_of_y]  # rho(n) for y in n in the paper\n    delta_vals = deltas[i_nest_of_x]  # delta(n') for x in n' in the paper\n\n    ephi = npexp(self.Phi / np.add.outer(delta_vals, rho_vals))\n\n    # initial values\n    nindivs = np.sum(n) + np.sum(m)\n    bigc = nindivs / (X + Y + 2.0 * np.sum(ephi))\n\n    mux0, mu0y, muxy = (\n        np.full(X, bigc),\n        np.full(Y, bigc),\n        np.full((X, Y), bigc),\n    )\n    muxn = np.zeros((X, n_rhos))\n    for i_nest_y, nest_y in enumerate(nests_over_Y):\n        muxn[:, i_nest_y] = np.sum(muxy[:, nest_y], 1)\n    muny = np.zeros((n_deltas, Y))\n    for i_nest_x, nest_x in enumerate(nests_over_X):\n        muny[i_nest_x, :] = np.sum(muxy[nest_x, :], 0)\n\n    err_diff = bigc\n    tol_diff = tol * bigc\n    tol_newton = tol\n    max_newton = 2000\n    MIN_REST = 1e-4 * bigc  # used to bound mus below in the Newton iterations\n\n    niter = 0\n    while (err_diff &gt; tol_diff) and (niter &lt; maxiter):  # IPFP main loop\n        # Newton iterates for men\n        err_newton = bigc\n        i_newton = 0\n        while err_newton &gt; tol_newton:\n            gbar = np.zeros(\n                (X, n_rhos)\n            )  # this will be the $\\bar{G}^x_n$ of the note\n            gbar_pow = np.zeros((X, n_rhos))\n            biga = np.zeros(X)  # this will be the $A_x$ of the note\n            for i_nest_x, nest_x in enumerate(nests_over_X):\n                # i_nest_x is n' in the paper\n                delta_x = deltas[i_nest_x]\n                muny_x = muny[i_nest_x, :]  # mu(n', :)\n                for x in nest_x:\n                    ephi_x = ephi[x, :]\n                    for i_nest_y, nest_y in enumerate(nests_over_Y):\n                        # i_nest_y is n in the paper\n                        mu_n = muny_x[nest_y]\n                        mu0_n = mu0y[nest_y]\n                        evec_n = ephi_x[nest_y]\n                        rho_n = rhos[i_nest_y]\n                        sum_rd = rho_n + delta_x\n                        mun_term = nppow(mu_n, (delta_x - 1.0) / sum_rd)\n                        mu0_term = nppow(mu0_n, 1.0 / sum_rd)\n                        gbar[x, i_nest_y] = np.sum(mun_term * mu0_term * evec_n)\n                        gbar_pow[x, i_nest_y] = nppow(\n                            gbar[x, i_nest_y], sum_rd / (delta_x + 1.0)\n                        )\n                        biga[x] += gbar_pow[x, i_nest_y]\n\n            # now we take one Newton step for all types of men\n            delta_vals1 = 1.0 + delta_vals\n            mux0_term = nppow(mux0, 1.0 / delta_vals1)\n            bigb = mux0_term * biga  # this is the $B_x$ of the note\n            numer = n * delta_vals1 - delta_vals * bigb\n            lower_bound = np.full(X, MIN_REST)\n            mux0_new = mux0 * np.maximum(\n                numer / (delta_vals1 * mux0 + bigb), lower_bound\n            )\n            muxn_new = gbar_pow * mux0_term.reshape((-1, 1))\n\n            mux0 = mux0_new\n            muxn = muxn_new\n            errxi = mux0 + np.sum(muxn, 1) - n\n            err_newton = npmaxabs(errxi)\n            i_newton += 1\n            if i_newton &gt; max_newton:\n                bs_error_abort(\n                    f\"Newton solver failed for men after {max_newton} iterations\"\n                )\n\n        if verbose:\n            print(\n                f\"Newton error on men is {err_newton} after {i_newton} iterations\"\n            )\n\n        # Newton iterates for women\n        err_newton = bigc\n        i_newton = 0\n        while err_newton &gt; tol_newton:\n            gbar = np.zeros((Y, n_deltas))\n            gbar_pow = np.zeros((Y, n_deltas))\n            biga = np.zeros(Y)\n            for i_nest_y, nest_y in enumerate(nests_over_Y):\n                # i_nest_y is n in the paper\n                rho_y = rhos[i_nest_y]\n                muxn_y = muxn[:, i_nest_y]  # mu(:, n)\n                for y in nest_y:\n                    ephi_y = ephi[:, y]\n                    for i_nest_x, nest_x in enumerate(nests_over_X):\n                        mu_n = muxn_y[nest_x]\n                        mu0_n = mux0[nest_x]\n                        evec_n = ephi_y[nest_x]\n                        delta_n = deltas[i_nest_x]\n                        sum_rd = rho_y + delta_n\n                        mun_term = nppow(mu_n, (rho_y - 1.0) / sum_rd)\n                        mu0_term = nppow(mu0_n, 1.0 / sum_rd)\n                        gbar[y, i_nest_x] = np.sum(mun_term * mu0_term * evec_n)\n                        gbar_pow[y, i_nest_x] = nppow(\n                            gbar[y, i_nest_x], sum_rd / (1.0 + rho_y)\n                        )\n                        biga[y] += gbar_pow[y, i_nest_x]\n\n            # now we take one Newton step for all types of women\n            rho_vals1 = 1.0 + rho_vals\n            mu0y_term = nppow(mu0y, 1.0 / rho_vals1)\n            bigb = mu0y_term * biga\n            numer = m * rho_vals1 - rho_vals * bigb\n            lower_bound = np.full(Y, MIN_REST)\n            mu0y_new = mu0y * np.maximum(\n                numer / (rho_vals1 * mu0y + bigb), lower_bound\n            )\n            muny_new = gbar_pow.T * mu0y_term\n\n            mu0y = mu0y_new\n            muny = muny_new\n            erryi = mu0y + np.sum(muny, 0) - m\n            err_newton = npmaxabs(erryi)\n            i_newton += 1\n            if i_newton &gt; max_newton:\n                bs_error_abort(\n                    f\"Newton solver failed for women after {max_newton} iterations\"\n                )\n\n        if verbose:\n            print(\n                f\"Newton error on women is {err_newton} after {i_newton} iterations\"\n            )\n\n        muxy = np.zeros((X, Y))\n        for x in range(X):\n            i_nest_x = i_nest_of_x[x]  # n'\n            ephi_x = ephi[x, :]\n            mux0_x = mux0[x]\n            muxn_x = muxn[x, :]\n            delta_x = delta_vals[x]\n            muny_x = muny[i_nest_x, :]\n            for y in range(Y):\n                i_nest_y = i_nest_of_y[y]  # n\n                mu0y_y = mu0y[y]\n                rho_y = rho_vals[y]\n                muxn_xy = muxn_x[i_nest_y]\n                muny_xy = muny_x[y]\n                mu_term = (\n                    mux0_x\n                    * mu0y_y\n                    * (muxn_xy ** (rho_y - 1.0))\n                    * (muny_xy ** (delta_x - 1.0))\n                )\n                muxy[x, y] = ephi_x[y] * (mu_term ** (1.0 / (delta_x + rho_y)))\n\n        n_sim, m_sim = compute_margins(muxy, mux0, mu0y)\n        marg_err_x, marg_err_y = n_sim - n, m_sim - m\n\n        if verbose:\n            print(\n                f\"Margin error on men is {marg_err_x} \"\n                f\" after {niter} IPFP iterations\"\n            )\n            print(\n                f\"Margin error on women is {marg_err_y} \"\n                f\" after {niter} IPFP iterations\"\n            )\n        err_diff = npmaxabs(marg_err_x) + npmaxabs(marg_err_y)\n        niter += 1\n\n    n_sim, m_sim = compute_margins(muxy, mux0, mu0y)\n    marg_err_x = n_sim - n\n    marg_err_y = m_sim - m\n\n    if verbose:\n        print(\n            f\"Margin error on men is {npmaxabs(marg_err_x)} after {niter} IPFP\"\n            \" iterations\"\n        )\n        print(\n            f\"Margin error on women is {npmaxabs(marg_err_y)} after {niter} IPFP\"\n            \" iterations\"\n        )\n\n    return Matching(muxy, n, m), marg_err_x, marg_err_y\n</code></pre>"},{"location":"nested_logit/","title":"Nested Logit","text":""},{"location":"nested_logit/#nested_logit-module","title":"<code>nested_logit</code> module","text":"<p>The components of the derivative of the entropy for a two-layer nested logit model. One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters.</p>"},{"location":"nested_logit/#cupid_matching.nested_logit.e0_derivative_mu_nested_logit","title":"<code>e0_derivative_mu_nested_logit(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(\\mu\\) for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list | None</code> <p>a list with the nest structure</p> <code>None</code> <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the parameter-independent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt \\((\\mu,\\mu)\\).</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e0_derivative_mu_nested_logit(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; ThreeArrays:\n    \"\"\"Returns the derivatives of the parameter-independent part $e_0$\n    wrt $\\\\mu$ for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu,\\\\mu)$.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = _get_params(additional_parameters)\n    nests_x = change_indices(nests_for_each_x)\n    nests_y = change_indices(nests_for_each_y)\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    hess_x = np.zeros((X, Y, Y))\n    hess_y = np.zeros((X, Y, X))\n    hess_xy = np.zeros((X, Y))\n    der_logx0 = 1.0 / mux0\n    der_log0y = 1.0 / mu0y\n\n    for x in range(X):\n        dlogx0 = der_logx0[x]\n        for nest in nests_x:\n            mu_xn = np.sum(muxy[x, nest])\n            der_logxn = 1.0 / mu_xn\n            for y in nest:\n                hess_x[x, y, :] = -dlogx0\n                hess_x[x, y, nest] -= der_logxn\n    for y in range(Y):\n        dlog0y = der_log0y[y]\n        for nest in nests_y:\n            mu_ny = np.sum(muxy[nest, y])\n            der_logny = 1.0 / mu_ny\n            for x in nest:\n                hess_y[x, y, :] = -dlog0y\n                hess_y[x, y, nest] -= der_logny\n    for x in range(X):\n        for y in range(Y):\n            hess_xy[x, y] = hess_x[x, y, y] + hess_y[x, y, x]\n\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"nested_logit/#cupid_matching.nested_logit.e0_derivative_r_nested_logit","title":"<code>e0_derivative_r_nested_logit(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-independent part \\(e_0\\) wrt \\(r\\) for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list | None</code> <p>a list with the nest structure</p> <code>None</code> <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-independent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt \\((\\mu,r)\\).</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e0_derivative_r_nested_logit(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; TwoArrays:\n    \"\"\"Returns the derivatives of the parameter-independent part $e_0$\n    wrt $r$ for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu,r)$.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = _get_params(additional_parameters)\n    nests_x = change_indices(nests_for_each_x)\n    nests_y = change_indices(nests_for_each_y)\n    muxy, mux0, mu0y, n, m = muhat.unpack()\n    X, Y = muxy.shape\n\n    hess_n = np.zeros((X, Y))\n    hess_m = np.zeros((X, Y))\n    der_logx0 = 1.0 / mux0\n    der_log0y = 1.0 / mu0y\n\n    for x in range(X):\n        dlogx0 = der_logx0[x]\n        for nest in nests_x:\n            for y in nest:\n                hess_n[x, y] = dlogx0\n    for y in range(Y):\n        dlog0y = der_log0y[y]\n        for nest in nests_y:\n            for x in nest:\n                hess_m[x, y] = dlog0y\n\n    return hess_n, hess_m\n</code></pre>"},{"location":"nested_logit/#cupid_matching.nested_logit.e0_nested_logit","title":"<code>e0_nested_logit(muhat, additional_parameters=None)</code>","text":"<p>Returns the values of the parameter-independent part \\(e_0\\) for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list | None</code> <p>a list with the nest structure</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>the (X,Y) matrix of the parameter-independent part</p> <code>ndarray</code> <p>of the first derivative of the entropy.</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e0_nested_logit(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; np.ndarray:\n    \"\"\"Returns the values of the parameter-independent part $e_0$\n    for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the (X,Y) matrix of the parameter-independent part\n        of the first derivative of the entropy.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = _get_params(additional_parameters)\n    nests_x = change_indices(nests_for_each_x)\n    nests_y = change_indices(nests_for_each_y)\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    e0_vals = np.zeros((X, Y))\n\n    for x in range(X):\n        mux0_x = mux0[x]\n        for nest in nests_x:\n            mu_xn = np.sum(muxy[x, nest])\n            e0_vals[x, nest] = -log(mu_xn / mux0_x)\n    for y in range(Y):\n        mu0y_y = mu0y[y]\n        for nest in nests_y:\n            mu_ny = np.sum(muxy[nest, y])\n            e0_vals[nest, y] -= log(mu_ny / mu0y_y)\n    return e0_vals\n</code></pre>"},{"location":"nested_logit/#cupid_matching.nested_logit.e_derivative_mu_nested_logit","title":"<code>e_derivative_mu_nested_logit(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-dependent part \\(e\\)  wrt \\(\\mu\\) for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list | None</code> <p>a list with the nest structure</p> <code>None</code> <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt \\((\\mu,\\mu)\\).</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e_derivative_mu_nested_logit(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; ThreeArrays:\n    \"\"\"Returns the derivatives of the parameter-dependent part $e$\n     wrt $\\\\mu$ for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $(\\\\mu,\\\\mu)$.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = _get_params(additional_parameters)\n    nests_x = change_indices(nests_for_each_x)\n    nests_y = change_indices(nests_for_each_y)\n    n_rhos = len(nests_for_each_x)\n    n_deltas = len(nests_for_each_y)\n    n_alpha = n_rhos + n_deltas\n\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    hess_x = np.zeros((X, Y, Y, n_alpha))\n    hess_y = np.zeros((X, Y, X, n_alpha))\n    hess_xy = np.zeros((X, Y, n_alpha))\n    der_logxy = 1.0 / muxy\n\n    for x in range(X):\n        for i_n, nest in enumerate(nests_x):\n            mux_nest_n = muxy[x, nest]\n            mu_xn = np.sum(mux_nest_n)\n            der_logxn = 1.0 / mu_xn\n            for t in nest:\n                hess_x[x, nest, t, i_n] = der_logxn\n            hess_xy[x, nest, i_n] = der_logxn - der_logxy[x, nest]\n\n    for y in range(Y):\n        for i_n, nest in enumerate(nests_y):\n            muy_nest_n = muxy[nest, y]\n            mu_ny = np.sum(muy_nest_n)\n            der_logny = 1.0 / mu_ny\n            i_n2 = i_n + n_rhos\n            for z in nest:\n                hess_y[nest, y, z, i_n2] = der_logny\n            hess_xy[nest, y, i_n2] = der_logny - der_logxy[nest, y]\n\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"nested_logit/#cupid_matching.nested_logit.e_derivative_r_nested_logit","title":"<code>e_derivative_r_nested_logit(muhat, additional_parameters=None)</code>","text":"<p>Returns the derivatives of the parameter-dependent part \\(e\\)  wrt \\(r\\) for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list | None</code> <p>a list with the nest structure</p> <code>None</code> <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt \\((\\mu,r)\\).</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e_derivative_r_nested_logit(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; TwoArrays:\n    \"\"\"Returns the derivatives of the parameter-dependent part $e$\n     wrt $r$ for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $(\\\\mu,r)$.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = _get_params(additional_parameters)\n    n_rhos = len(nests_for_each_x)\n    n_deltas = len(nests_for_each_y)\n    n_alpha = n_rhos + n_deltas\n\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    hess_n = np.zeros((X, Y, n_alpha))\n    hess_m = np.zeros((X, Y, n_alpha))\n\n    return hess_n, hess_m\n</code></pre>"},{"location":"nested_logit/#cupid_matching.nested_logit.e_nested_logit","title":"<code>e_nested_logit(muhat, additional_parameters=None)</code>","text":"<p>Returns the values of the parameter-dependent part  \\(e\\) for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list | None</code> <p>a list with the nest structure</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>the (X,Y,n_alpha) array of the parameter-dependent part</p> <code>ndarray</code> <p>of the first derivative of the entropy.</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e_nested_logit(\n    muhat: Matching, additional_parameters: list | None = None\n) -&gt; np.ndarray:\n    \"\"\"Returns the values of the parameter-dependent part  $e$\n    for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the (X,Y,n_alpha) array of the parameter-dependent part\n        of the first derivative of the entropy.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = _get_params(additional_parameters)\n    nests_x = change_indices(nests_for_each_x)\n    nests_y = change_indices(nests_for_each_y)\n    n_rhos = len(nests_for_each_x)\n    n_deltas = len(nests_for_each_y)\n    n_alpha = n_rhos + n_deltas\n\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    e_vals = np.zeros((X, Y, n_alpha))\n\n    for x in range(X):\n        for i_n, nest in enumerate(nests_x):\n            mux_nest_n = muxy[x, nest]\n            mu_xn = np.sum(mux_nest_n)\n            e_vals[x, nest, i_n] = -np.log(mux_nest_n / mu_xn)\n\n    for y in range(Y):\n        for i_n, nest in enumerate(nests_y):\n            muy_nest_n = muxy[nest, y]\n            mu_ny = np.sum(muy_nest_n)\n            e_vals[nest, y, (i_n + n_rhos)] -= np.log(muy_nest_n / mu_ny)\n\n    return e_vals\n</code></pre>"},{"location":"poisson_glm/","title":"<code>poisson_glm</code> module","text":"<p>Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM.</p>"},{"location":"poisson_glm/#cupid_matching.poisson_glm.choo_siow_poisson_glm","title":"<code>choo_siow_poisson_glm(muhat, phi_bases, no_singles=False, tol=1e-12, max_iter=10000, verbose=1)</code>","text":"<p>Estimates the semilinear Choo and Siow homoskedastic (2006) model     using Poisson GLM.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>the observed Matching</p> required <code>phi_bases</code> <code>ndarray</code> <p>an (X, Y, K) array of bases</p> required <code>no_singles</code> <code>bool</code> <p>if True, we do not observe the singles</p> <code>False</code> <code>tol</code> <code>float | None</code> <p>tolerance level for <code>linear_model.PoissonRegressor.fit</code></p> <code>1e-12</code> <code>max_iter</code> <code>int | None</code> <p>maximum number of iterations for <code>linear_model.PoissonRegressor.fit</code></p> <code>10000</code> <code>verbose</code> <code>int | None</code> <p>defines how much output we want (0 = least)</p> <code>1</code> <p>Returns:</p> Type Description <code>PoissonGLMResults</code> <p>a <code>PoissonGLMResults</code> instance</p> Example <pre><code>n_households = 1e6\nX, Y, K = 4, 3, 6\n# we setup a quadratic set of basis functions\nphi_bases = np.zeros((X, Y, K))\nphi_bases[:, :, 0] = 1\nfor x in range(X):\n    phi_bases[x, :, 1] = x\n    phi_bases[x, :, 3] = x * x\n    for y in range(Y):\n        phi_bases[x, y, 4] = x * y\nfor y in range(Y):\n    phi_bases[:, y, 2] = y\n    phi_bases[:, y, 5] = y * y\n\nlambda_true = np.random.randn(K)\nphi_bases = np.random.randn(X, Y, K)\nPhi = phi_bases @ lambda_true\n\n# we simulate a Choo and Siow sample from a population\n#  with equal numbers of men and women of each type\nn = np.ones(X)\nm = np.ones(Y)\nchoo_siow_instance = ChooSiowPrimitives(Phi, n, m)\nmus_sim = choo_siow_instance.simulate(n_households)\nmuxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack()\n\nresults = choo_siow_poisson_glm(mus_sim, phi_bases)\n\n# compare true and estimated parameters\nresults.print_results(\n    lambda_true,\n    u_true=-np.log(mux0_sim / n_sim),\n    v_true=-np.log(mu0y_sim / m_sim)\n)\n</code></pre> Source code in <code>cupid_matching/poisson_glm.py</code> <pre><code>def choo_siow_poisson_glm(\n    muhat: Matching,\n    phi_bases: np.ndarray,\n    no_singles: bool = False,\n    tol: float | None = 1e-12,\n    max_iter: int | None = 10000,\n    verbose: int | None = 1,\n) -&gt; PoissonGLMResults:\n    \"\"\"Estimates the semilinear Choo and Siow homoskedastic (2006) model\n        using Poisson GLM.\n\n    Args:\n        muhat: the observed Matching\n        phi_bases: an (X, Y, K) array of bases\n        no_singles: if True, we do not observe the singles\n        tol: tolerance level for `linear_model.PoissonRegressor.fit`\n        max_iter: maximum number of iterations\n            for `linear_model.PoissonRegressor.fit`\n        verbose: defines how much output we want (0 = least)\n\n    Returns:\n        a `PoissonGLMResults` instance\n\n    Example:\n        ```py\n        n_households = 1e6\n        X, Y, K = 4, 3, 6\n        # we setup a quadratic set of basis functions\n        phi_bases = np.zeros((X, Y, K))\n        phi_bases[:, :, 0] = 1\n        for x in range(X):\n            phi_bases[x, :, 1] = x\n            phi_bases[x, :, 3] = x * x\n            for y in range(Y):\n                phi_bases[x, y, 4] = x * y\n        for y in range(Y):\n            phi_bases[:, y, 2] = y\n            phi_bases[:, y, 5] = y * y\n\n        lambda_true = np.random.randn(K)\n        phi_bases = np.random.randn(X, Y, K)\n        Phi = phi_bases @ lambda_true\n\n        # we simulate a Choo and Siow sample from a population\n        #  with equal numbers of men and women of each type\n        n = np.ones(X)\n        m = np.ones(Y)\n        choo_siow_instance = ChooSiowPrimitives(Phi, n, m)\n        mus_sim = choo_siow_instance.simulate(n_households)\n        muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack()\n\n        results = choo_siow_poisson_glm(mus_sim, phi_bases)\n\n        # compare true and estimated parameters\n        results.print_results(\n            lambda_true,\n            u_true=-np.log(mux0_sim / n_sim),\n            v_true=-np.log(mu0y_sim / m_sim)\n        )\n        ```\n\n    \"\"\"\n    X, Y, K = phi_bases.shape\n    XY = X * Y\n\n    # the vector of weights for the Poisson regression\n    w = (\n        2 * np.ones(XY)\n        if no_singles\n        else np.concatenate((2 * np.ones(XY), np.ones(X + Y)))\n    )\n    # reshape the bases\n    phi_mat = make_XY_K_mat(phi_bases)\n\n    id_X = np.eye(X)\n    id_Y = np.eye(Y)\n    ones_X = np.ones((X, 1))\n    ones_Y = np.ones((Y, 1))\n    if no_singles:\n        Z_unweighted = np.hstack(\n            [-np.kron(id_X, ones_Y), -np.kron(ones_X, id_Y), phi_mat]\n        )\n        # we need to normalize u_1 = 0, so we delete the first column\n        Z_unweighted = Z_unweighted[:, 1:]\n    else:\n        zeros_XK = np.zeros((X, K))\n        zeros_YK = np.zeros((Y, K))\n        zeros_XY = np.zeros((X, Y))\n        zeros_YX = np.zeros((Y, X))\n        Z_unweighted = np.vstack(\n            [\n                np.hstack([-np.kron(id_X, ones_Y), -np.kron(ones_X, id_Y), phi_mat]),\n                np.hstack([-id_X, zeros_XY, zeros_XK]),\n                np.hstack([zeros_YX, -id_Y, zeros_YK]),\n            ]\n        )\n    Z = Z_unweighted / w.reshape((-1, 1))\n\n    var_muhat = variance_muhat(muhat)\n    (\n        muhat_norm,\n        var_muhat_norm,\n        n_households,\n        n_individuals,\n    ) = prepare_data(muhat, var_muhat, no_singles=no_singles)\n\n    clf = linear_model.PoissonRegressor(\n        fit_intercept=False,\n        tol=tol,\n        verbose=verbose,\n        alpha=0,\n        max_iter=max_iter,\n    )\n    if no_singles:\n        muxyhat_norm = muhat_norm[:XY]\n        clf.fit(Z, muxyhat_norm, sample_weight=w)\n    else:\n        clf.fit(Z, muhat_norm, sample_weight=w)\n    gamma_est = clf.coef_\n\n    # we compute_ the variance-covariance of the estimator\n    var_allmus_norm = var_muhat_norm.var_allmus\n    var_norm = var_allmus_norm[:XY, :XY] if no_singles else var_allmus_norm\n    nr, nc = Z.shape\n    exp_Zg = np.exp(Z @ gamma_est).reshape(nr)\n    A_hat = np.zeros((nc, nc))\n    B_hat = np.zeros((nc, nc))\n    for i in range(nr):\n        Zi = Z[i, :]\n        wi = w[i]\n        A_hat += wi * exp_Zg[i] * np.outer(Zi, Zi)\n        for j in range(nr):\n            Zj = Z[j, :]\n            B_hat += wi * w[j] * var_norm[i, j] * np.outer(Zi, Zj)\n\n    A_inv = spla.inv(A_hat)\n    varcov_gamma = A_inv @ B_hat @ A_inv\n    stderrs_gamma = np.sqrt(np.diag(varcov_gamma))\n\n    beta_est = gamma_est[-K:]\n    varcov_beta = varcov_gamma[-K:, -K:]\n    beta_std = stderrs_gamma[-K:]\n    Phi_est = phi_bases @ beta_est\n\n    # we correct for the effect of the normalization\n    _, _, _, n, m = muhat.unpack()\n    n_norm = n / n_individuals\n    m_norm = m / n_individuals\n    if no_singles:\n        u_est = gamma_est[: (X - 1)]\n        v_est = gamma_est[(X - 1) : -K]\n        # normalize u_1 = 0\n        n_0 = n_norm[0]\n        u_est = np.concatenate((np.zeros(1), u_est + np.log(n_norm[1:] / n_0)))\n        v_est += np.log(m_norm * n_0)\n    else:\n        u_est = gamma_est[:X] + np.log(n_norm)\n        v_est = gamma_est[X:-K] + np.log(m_norm)\n\n    # since u and v are translated from gamma we need to adjust the estimated stderrs\n    A_inv_Z = A_inv @ Z_unweighted.T\n    if no_singles:\n        u_std = _stderrs_u_no_singles(\n            varcov_gamma, n_norm, var_muhat_norm, A_inv_Z, X, Y\n        )\n        v_std = _stderrs_v_no_singles(\n            varcov_gamma, m_norm, n_norm, var_muhat_norm, A_inv_Z, X, Y\n        )\n    else:\n        u_std = _stderrs_u(varcov_gamma, n_norm, var_muhat_norm, A_inv_Z, X, Y)\n        v_std = _stderrs_v(varcov_gamma, m_norm, var_muhat_norm, A_inv_Z, X, Y)\n\n    results = PoissonGLMResults(\n        X=X,\n        Y=Y,\n        K=K,\n        number_households=n_households,\n        number_individuals=n_individuals,\n        estimated_gamma=gamma_est,\n        estimated_Phi=Phi_est,\n        estimated_beta=beta_est,\n        estimated_u=u_est,\n        estimated_v=v_est,\n        varcov_gamma=varcov_gamma,\n        varcov_beta=varcov_beta,\n        stderrs_gamma=stderrs_gamma,\n        stderrs_beta=beta_std,\n        stderrs_u=u_std,\n        stderrs_v=v_std,\n    )\n\n    return results\n</code></pre>"},{"location":"poisson_glm_utils/","title":"<code>poisson_glm_utils</code> module","text":"<p>Utilities for Poisson GLM.</p>"},{"location":"poisson_glm_utils/#cupid_matching.poisson_glm_utils.PoissonGLMResults","title":"<code>PoissonGLMResults</code>  <code>dataclass</code>","text":"<p>Stores and formats the estimation results.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>int</code> <p>int</p> required <code>Y</code> <code>int</code> <p>int</p> required <code>K</code> <code>int</code> <p>int</p> required <code>number_households</code> <code>int</code> <p>int</p> required <code>number_individuals</code> <code>int</code> <p>int</p> required <code>estimated_gamma</code> <code>ndarray</code> <p>np.ndarray</p> required <code>varcov_gamma</code> <code>ndarray</code> <p>np.ndarray</p> required <code>stderrs_gamma</code> <code>ndarray</code> <p>np.ndarray</p> required <code>estimated_beta</code> <code>ndarray</code> <p>np.ndarray</p> required <code>estimated_u</code> <code>ndarray</code> <p>np.ndarray</p> required <code>estimated_v</code> <code>ndarray</code> <p>np.ndarray</p> required <code>varcov_beta</code> <code>ndarray</code> <p>np.ndarray</p> required <code>stderrs_beta</code> <code>ndarray</code> <p>np.ndarray</p> required <code>stderrs_u</code> <code>ndarray</code> <p>np.ndarray</p> required <code>stderrs_v</code> <code>ndarray</code> <p>np.ndarray</p> required <code>estimated_Phi</code> <code>ndarray</code> <p>np.ndarray</p> required Source code in <code>cupid_matching/poisson_glm_utils.py</code> <pre><code>@dataclass\nclass PoissonGLMResults:\n    \"\"\"Stores and formats the estimation results.\n\n    Args:\n        X: int\n        Y: int\n        K: int\n        number_households: int\n        number_individuals: int\n        estimated_gamma: np.ndarray\n        varcov_gamma: np.ndarray\n        stderrs_gamma: np.ndarray\n        estimated_beta: np.ndarray\n        estimated_u: np.ndarray\n        estimated_v: np.ndarray\n        varcov_beta: np.ndarray\n        stderrs_beta: np.ndarray\n        stderrs_u: np.ndarray\n        stderrs_v: np.ndarray\n        estimated_Phi: np.ndarray\n    \"\"\"\n\n    X: int\n    Y: int\n    K: int\n    number_households: int\n    number_individuals: int\n    estimated_gamma: np.ndarray\n    varcov_gamma: np.ndarray\n    stderrs_gamma: np.ndarray\n    estimated_beta: np.ndarray\n    varcov_beta: np.ndarray\n    estimated_u: np.ndarray\n    estimated_v: np.ndarray\n    stderrs_beta: np.ndarray\n    stderrs_u: np.ndarray\n    stderrs_v: np.ndarray\n    estimated_Phi: np.ndarray\n\n    def __str__(self):\n        line_stars = \"*\" * 80 + \"\\n\"\n        print_stars(\"Estimating a Choo and Siow model by Poisson GLM.\")\n        model_str = f\"The data has {self.number_households} households\\n\\n\"\n        model_str += f\"We use {self.K} basis functions.\\n\\n\"\n        repr_str = line_stars + model_str\n        repr_str += (\n            \"The estimated basis coefficients (and their standard errors) are\\n\\n\"\n        )\n        for i in range(self.K):\n            repr_str += (\n                f\"   base_{i + 1}: {self.estimated_beta[i]: &gt; 10.3f}  \"\n                + f\"({self.stderrs_beta[i]: .3f})\\n\"\n            )\n        repr_str += \"The estimated utilities of men (and their standard errors) are\\n\\n\"\n        for i in range(self.X):\n            repr_str += (\n                f\"   u_{i + 1}: {self.estimated_u[i]: &gt; 10.3f}  \"\n                + f\"({self.stderrs_u[i]: .3f})\\n\"\n            )\n        repr_str += (\n            \"The estimated utilities of women (and their standard errors) are\\n\\n\"\n        )\n        for i in range(self.Y):\n            repr_str += (\n                f\"   v {i + 1}: {self.estimated_v[i]: &gt; 10.3f}  \"\n                + f\"({self.stderrs_v[i]: .3f})\\n\"\n            )\n        return repr_str + line_stars\n\n    def print_results(\n        self,\n        lambda_true: np.ndarray | None = None,\n        u_true: np.ndarray | None = None,\n        v_true: np.ndarray | None = None,\n    ) -&gt; float | None:\n        estimates_beta = self.estimated_beta\n        stderrs_beta = self.stderrs_beta\n\n        if lambda_true is None:\n            repr_str = \"The  estimated coefficients \"\n            repr_str += \"(and their standard errors) are\\n\\n\"\n            for i, coeff in enumerate(estimates_beta):\n                repr_str += f\" {coeff: &gt; 10.3f}  ({stderrs_beta[i]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n        else:\n            repr_str = \"The  true and estimated coefficients \"\n            repr_str += \"(and their standard errors) are\\n\\n\"\n            for i, coeff in enumerate(estimates_beta):\n                repr_str += f\"   base {i + 1}: {lambda_true[i]: &gt; 10.3f} \"\n                repr_str += f\" {coeff: &gt; 10.3f}  ({stderrs_beta[i]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n\n        self.report_utilities(\"men\", u_true)\n        self.report_utilities(\"women\", v_true)\n\n        if lambda_true is None:\n            return None\n        else:\n            discrepancy = npmaxabs(lambda_true - estimates_beta)\n            print_stars(\n                \"The largest difference between true and estimated coefficients is\"\n                f\" {discrepancy: .2e}\"\n            )\n            return cast(float, discrepancy)\n\n    def report_utilities(self, gender: str, utils_true: np.ndarray | None) -&gt; None:\n        if gender not in [\"men\", \"women\"]:\n            bs_error_abort(f\"gender can only be 'men' or 'women', not {gender}\")\n        utils_estimates = self.estimated_u if gender == \"men\" else self.estimated_v\n        utils_stderrs = self.stderrs_u if gender == \"men\" else self.stderrs_v\n        util_prefix = \"u\" if gender == \"men\" else \"v\"\n        if utils_true is None:\n            repr_str = f\"The estimated utilities for {gender} \"\n            repr_str += \"(and their standard errors) are:\\n\\n\"\n            for i, coeff in enumerate(utils_estimates):\n                repr_str += f\"   {util_prefix}_{i + 1}: \"\n                repr_str += f\" {coeff: &gt; 10.3f}  ({utils_stderrs[i]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n        else:\n            repr_str = f\"The true and estimated utilities for {gender} \"\n            repr_str += \"(and their standard errors) are:\\n\\n\"\n            for i, coeff in enumerate(utils_estimates):\n                repr_str += f\"   {util_prefix}_{i + 1}: {utils_true[i]: &gt; 10.3f} \"\n                repr_str += f\" {coeff: &gt; 10.3f}  ({utils_stderrs[i]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n</code></pre>"},{"location":"poisson_glm_utils/#cupid_matching.poisson_glm_utils.prepare_data","title":"<code>prepare_data(muhat, var_muhat, no_singles=False)</code>","text":"<p>Normalizes the matching patterns and stacks them. We rescale the data so that the total number of individuals is one.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>the observed Matching</p> required <code>var_muhat</code> <code>VarianceMatching</code> <p>the variance-covariance object for the observed matching</p> required <code>no_singles</code> <code>bool</code> <p>if True, we do not observe singles</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>the stacked, normalized <code>muxy, mux0, mu0y</code> (the latter two are zero if <code>no_singles</code>)</p> <code>VarianceMatching</code> <p>the corresponding variance-covariance matrix</p> <code>int</code> <p>the number of households</p> <code>int</code> <p>the number of individuals</p> Source code in <code>cupid_matching/poisson_glm_utils.py</code> <pre><code>def prepare_data(\n    muhat: Matching,\n    var_muhat: VarianceMatching,\n    no_singles: bool = False,\n) -&gt; tuple[np.ndarray, VarianceMatching, int, int]:\n    \"\"\"Normalizes the matching patterns and stacks them.\n    We rescale the data so that the total number of individuals is one.\n\n    Args:\n        muhat: the observed Matching\n        var_muhat: the variance-covariance object for the observed matching\n        no_singles: if True, we do not observe singles\n\n    Returns:\n        the stacked, normalized `muxy, mux0, mu0y` (the latter two are zero if `no_singles`)\n        the corresponding variance-covariance matrix\n        the number of households\n        the number of individuals\n    \"\"\"\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    n_couples = np.sum(muxy)\n    if no_singles:\n        mux0 = np.zeros(mux0.shape)\n        mu0y = np.zeros(mu0y.shape)\n    n_households = n_couples + np.sum(mux0) + np.sum(mu0y)\n    n_individuals = n_households + n_couples\n    # rescale the data so that the total number of individuals is one\n    muhat_norm = np.concatenate([muxy.flatten(), mux0, mu0y]) / n_individuals\n    n_indivs2 = n_individuals * n_individuals\n    var_muhat_norm = var_divide(var_muhat, n_indivs2)\n    return (\n        muhat_norm,\n        var_muhat_norm,\n        n_households,\n        n_individuals,\n    )\n</code></pre>"},{"location":"utils/","title":"<code>utils</code> module","text":"<p>This module contains some utility programs used by the package.</p>"},{"location":"utils/#cupid_matching.utils.change_indices","title":"<code>change_indices(nests)</code>","text":"<p>subtracts 1 from the indices within the nest structure</p> <p>Parameters:</p> Name Type Description Default <code>nests</code> <code>NestsList</code> <p>the nest structure</p> required <p>Returns:</p> Type Description <code>NestsList</code> <p>a similar list</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def change_indices(nests: NestsList) -&gt; NestsList:\n    \"\"\"subtracts 1 from the indices within the nest structure\n\n    Args:\n        nests: the nest structure\n\n    Returns:\n        a similar list\n    \"\"\"\n    return [[nest_i - 1 for nest_i in nest] for nest in nests]\n</code></pre>"},{"location":"utils/#cupid_matching.utils.find_nest_of","title":"<code>find_nest_of(nests, y)</code>","text":"<p>find the index of the nest that contains y, or return -1</p> <p>Parameters:</p> Name Type Description Default <code>nests</code> <code>NestsList</code> <p>a nest structure</p> required <code>y</code> <code>int</code> <p>the type we are looking for</p> required <p>Returns:</p> Type Description <code>int</code> <p>the nest of y, or -1 if not found</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def find_nest_of(nests: NestsList, y: int) -&gt; int:\n    \"\"\"find the index of the nest that contains y, or return -1\n\n    Args:\n        nests: a nest structure\n        y: the type we are looking for\n\n    Returns:\n        the nest of y, or -1 if not found\n    \"\"\"\n    for i_n, nest in enumerate(nests):\n        if y in nest:\n            return i_n\n    return -1  # if not found\n</code></pre>"},{"location":"utils/#cupid_matching.utils.make_XY_K_mat","title":"<code>make_XY_K_mat(xyk_array)</code>","text":"<p>Reshapes an (X,Y,K) array to an (XY,K) matrix.</p> <p>Parameters:</p> Name Type Description Default <code>xyk_array</code> <code>ndarray</code> <p>an (X, Y, K) array of bases</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the same,  (XY, K)-reshaped</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def make_XY_K_mat(xyk_array: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Reshapes an (X,Y,K) array to an (XY,K) matrix.\n\n    Args:\n        xyk_array: an (X, Y, K) array of bases\n\n    Returns:\n        the same,  (XY, K)-reshaped\n    \"\"\"\n    X, Y, K = xyk_array.shape\n    XY = X * Y\n    xy_k_mat = np.zeros((XY, K))\n    for k in range(K):\n        xy_k_mat[:, k] = xyk_array[:, :, k].ravel()\n    return xy_k_mat\n</code></pre>"},{"location":"utils/#cupid_matching.utils.reshape4_to2","title":"<code>reshape4_to2(array4)</code>","text":"<p>Reshapes an array (X,Y,Z,T) to a matrix (XY,ZT).</p> <p>Parameters:</p> Name Type Description Default <code>array4</code> <code>ndarray</code> <p>an (X, Y, Z, T) array</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>the same,  (XY, ZT)-reshaped</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def reshape4_to2(array4: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Reshapes an array (X,Y,Z,T) to a matrix (XY,ZT).\n\n    Args:\n        array4: an (X, Y, Z, T) array\n\n    Returns:\n        the same,  (XY, ZT)-reshaped\n    \"\"\"\n    if array4.ndim != 4:\n        bs_error_abort(f\"array4 should have 4 dimensions not {array4.ndim}\")\n    X, Y, Z, T = array4.shape\n    XY, ZT = X * Y, Z * T\n    array2 = np.zeros((XY, ZT))\n    xy = 0\n    for x in range(X):\n        for y in range(Y):\n            array2[xy, :] = array4[x, y, :, :].ravel()\n            xy += 1\n    return array2\n</code></pre>"}]}