{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"cupid_matching","text":"<p>A Python package to solve, simulate and estimate separable matching models</p> <ul> <li>Free software: MIT license</li> <li>Documentation: https://bsalanie.github.io/cupid_matching</li> <li>See also: An interactive Streamlit app</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install [-U] cupid_matching\n</code></pre>"},{"location":"#importing-functions-from-the-package","title":"Importing functions from the package","text":"<p>For instance:</p> <pre><code>from cupid_matching.min_distance import estimate_semilinear_mde\n</code></pre>"},{"location":"#examples","title":"Examples","text":"<ul> <li><code>example_choosiow.py</code> shows how to run minimum distance and Poisson estimators on a Choo and Siow homoskedastic model. </li> <li><code>example_nestedlogit.py</code> shows how to run minimum distance estimators on a two-layer nested logit model. </li> </ul>"},{"location":"#warnings","title":"Warnings","text":"<ul> <li>many of these models (including all variants of Choo and Siow) rely heavily on logarithms and exponentials. It is easy to generate examples where numeric instability sets in.</li> <li>as a consequence,  the <code>numeric</code> versions of the minimum distance estimator (which use numerical derivatives) are not recommended. </li> <li>the bias-corrected minimum distance estimator (<code>corrected</code>) may have a larger mean-squared error and/or introduce numerical instabilities.</li> </ul>"},{"location":"#release-notes","title":"Release notes","text":""},{"location":"#version-104","title":"version 1.0.4","text":"<ul> <li>added an optional bias-correction for the minimum distance estimator in the Choo and Siow homoskedastic model, to help with cases when the matching patterns vary a lot across cells.</li> <li>added two complete examples: example_choosiow.py and example_nestedlogit.py.</li> </ul>"},{"location":"choo_siow/","title":"<code>choo_siow</code> module","text":"<p>The components of the derivative of the entropy for the Choo and Siow homoskedastic model.</p>"},{"location":"choo_siow/#cupid_matching.choo_siow.e0_fun_choo_siow","title":"<code>e0_fun_choo_siow(muhat)</code>","text":"<p>Returns the values of e_0 for the Choo and Siow model.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>the (X,Y) matrix of the first derivative of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def e0_fun_choo_siow(muhat: Matching) -&gt; np.ndarray:\n\"\"\"Returns the values of $e_0$ for the Choo and Siow model.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y) matrix of the first derivative of the entropy\n    \"\"\"\n    entropy_res = _entropy_choo_siow(muhat, deriv=1)\n    return entropy_res[1]\n</code></pre>"},{"location":"choo_siow/#cupid_matching.choo_siow.e0_fun_choo_siow_corrected","title":"<code>e0_fun_choo_siow_corrected(muhat)</code>","text":"<p>Returns the values of e_0 for the Choo and Siow model, using the finite-sample correction.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>the (X,Y) matrix of the first derivative of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def e0_fun_choo_siow_corrected(\n        muhat: Matching\n) -&gt; np.ndarray:\n\"\"\"Returns the values of $e_0$ for the Choo and Siow model,\n    using the finite-sample correction.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y) matrix of the first derivative of the entropy\n    \"\"\"\n    entropy_res = _entropy_choo_siow(muhat, deriv=1)\n    e0_val = entropy_res[1]\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    n_households = np.sum(muxy) + np.sum(mux0) + np.sum(mu0y)\n    e0_val_corrected = e0_val - (1.0 - muxy / n_households) / muxy\n    e0_val_corrected += ((1.0 - mux0 / n_households) / (2.0 * mux0)).reshape((-1, 1))\n    e0_val_corrected += ((1.0 - mu0y / n_households) / (2.0 * mu0y))\n    # print(f\"{npmaxabs(e0_val_corrected/e0_val - 1.0)=}\")\n    return e0_val_corrected\n</code></pre>"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mumu_choo_siow","title":"<code>hessian_mumu_choo_siow(muhat)</code>","text":"<p>Returns the derivatives of e_0 in \\mu for the Choo and Siow model.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the three components of the hessian wrt (\\mu,\\mu) of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def hessian_mumu_choo_siow(muhat: Matching) -&gt; ThreeArrays:\n\"\"\"Returns the derivatives of $e_0$ in $\\\\mu$\n    for the Choo and Siow model.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the three components of the hessian wrt $(\\\\mu,\\\\mu)$ of the entropy\n    \"\"\"\n    entropy_res = _entropy_choo_siow(muhat, deriv=2)\n    hessmumu = entropy_res[2]\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    hess_x = np.zeros((X, Y, Y))\n    hess_y = np.zeros((X, Y, X))\n    hess_xy = np.zeros((X, Y))\n    for x in range(X):\n        for y in range(Y):\n            d2xy = hessmumu[x, y, :, :]\n            hess_x[x, y, :] = d2xy[x, :]\n            hess_y[x, y, :] = d2xy[:, y]\n            hess_xy[x, y] = d2xy[x, y]\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mumu_choo_siow_corrected","title":"<code>hessian_mumu_choo_siow_corrected(muhat)</code>","text":"<p>Returns the derivatives of e_0 in \\mu for the Choo and Siow model, with the small sample correction</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the three components of the hessian wrt (\\mu,\\mu) of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def hessian_mumu_choo_siow_corrected(\n        muhat: Matching\n) -&gt; ThreeArrays:\n\"\"\"Returns the derivatives of $e_0$ in $\\\\mu$\n    for the Choo and Siow model, with the small sample correction\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the three components of the hessian wrt $(\\\\mu,\\\\mu)$ of the entropy\n    \"\"\"\n    hess_x, hess_y, hess_xy = hessian_mumu_choo_siow(muhat)\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    n_households = np.sum(muxy) + np.sum(mux0) + np.sum(mu0y)\n    X, Y = hess_xy.shape\n    corr_x0 = 1.0 / (2.0*mux0*mux0)\n    corr_0y = 1.0 / (2.0*mu0y*mu0y)\n    corr_xy = -1.0 / (muxy*muxy)\n    for x in range(X):\n        for y in range(Y):\n            hess_x[x, y, y] += corr_x0[x]\n            hess_y[x, y, x] += corr_0y[y]\n            hess_xy[x, y] += corr_xy[x, y]\n\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mur_choo_siow","title":"<code>hessian_mur_choo_siow(muhat)</code>","text":"<p>Returns the derivatives of e_0 in r for the Choo and Siow model.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the two components of the hessian wrt (\\mu,r) of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def hessian_mur_choo_siow(muhat: Matching) -&gt; TwoArrays:\n\"\"\"Returns the derivatives of $e_0$ in $r$\n    for the Choo and Siow model.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the two components of the hessian wrt $(\\\\mu,r)$ of the entropy\n    \"\"\"\n    entropy_res = _entropy_choo_siow(muhat, deriv=2)\n    hessmur = entropy_res[3]\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    hess_nx = np.zeros((X, Y))\n    hess_my = np.zeros((X, Y))\n    for x in range(X):\n        for y in range(Y):\n            d2r = hessmur[x, y, :]\n            hess_nx[x, y] = d2r[x]\n            hess_my[x, y] = d2r[X + y]\n    return hess_nx, hess_my\n</code></pre>"},{"location":"choo_siow/#cupid_matching.choo_siow.hessian_mur_choo_siow_corrected","title":"<code>hessian_mur_choo_siow_corrected(muhat)</code>","text":"<p>Returns the derivatives of e_0 in r for the Choo and Siow model, with the small sample correction</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the two components of the hessian wrt (\\mu,r) of the entropy</p> Source code in <code>cupid_matching/choo_siow.py</code> <pre><code>def hessian_mur_choo_siow_corrected(\n        muhat: Matching\n) -&gt; TwoArrays:\n\"\"\"Returns the derivatives of $e_0$ in $r$\n    for the Choo and Siow model, with the small sample correction\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the two components of the hessian wrt $(\\\\mu,r)$ of the entropy\n    \"\"\"\n    hess_nx, hess_my = hessian_mur_choo_siow(muhat)\n    _, mux0, mu0y, *_ = muhat.unpack()\n    corr_nx = 1.0 / (2.0*mux0*mux0)\n    corr_my = 1.0 / (2.0*mu0y*mu0y)\n    X, Y = mux0.size, mu0y.size\n    for x in range(X):\n        hess_my[x, :] += corr_my\n    for y in range(Y):\n        hess_nx[:, y] += corr_nx\n    return hess_nx, hess_my\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/","title":"<code>choo_siow_gender_heteroskedastic</code> module","text":"<p>The components of the derivative of the entropy for the Choo and Siow gender-heteroskedastic model.</p> <p>We normalize the standard error for the X side at 1, and we estimate the standard error on the Y side.</p>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e0_choo_siow_gender_heteroskedastic","title":"<code>e0_choo_siow_gender_heteroskedastic(muhat)</code>","text":"<p>Returns the values of the parameter-independent part e_0 for the Choo and Siow gender-heteroskedastic model; we normalized \\sigma=1.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>the (X,Y) matrix of the parameter-independent part</p> <code>np.ndarray</code> <p>of the first derivative of the entropy.</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e0_choo_siow_gender_heteroskedastic(muhat: Matching) -&gt; np.ndarray:\n\"\"\"Returns the values of the parameter-independent part $e_0$\n    for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y) matrix of the parameter-independent part\n        of the first derivative of the entropy.\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    e0_vals = -np.log(muxy / mux0.reshape((-1, 1)))\n    return e0_vals\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e0_derivative_mu_gender_heteroskedastic","title":"<code>e0_derivative_mu_gender_heteroskedastic(muhat)</code>","text":"<p>Returns the derivatives of the parameter-independent part e_0 in \\mu. for the Choo and Siow gender-heteroskedastic model; we normalized \\sigma=1.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the  parameter-independent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt (\\mu,\\mu).</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e0_derivative_mu_gender_heteroskedastic(\n    muhat: Matching,\n) -&gt; ThreeArrays:\n\"\"\"Returns the derivatives of the parameter-independent part $e_0$ in $\\\\mu$.\n    for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the  parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu,\\\\mu)$.\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    hess_x = np.zeros((X, Y, Y))\n    hess_y = np.zeros((X, Y, X))\n    hess_xy = np.zeros((X, Y))\n    der_logxy = 1.0 / muxy\n    der_logx0 = 1.0 / mux0\n    for x in range(X):\n        dlogx0 = der_logx0[x]\n        for y in range(Y):\n            hess_x[x, y, :] = -dlogx0\n            hess_xy[x, y] = -der_logxy[x, y] - dlogx0\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e0_derivative_r_gender_heteroskedastic","title":"<code>e0_derivative_r_gender_heteroskedastic(muhat)</code>","text":"<p>Returns the derivatives of the parameter-independent part e_0 wrt r for the Choo and Siow gender-heteroskedastic model; we normalized \\sigma=1.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-independent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt (\\mu,r).</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e0_derivative_r_gender_heteroskedastic(\n    muhat: Matching,\n) -&gt; TwoArrays:\n\"\"\"Returns the derivatives of the parameter-independent part $e_0$ wrt $r$\n    for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu,r)$.\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    hess_n = np.zeros((X, Y))\n    hess_m = np.zeros((X, Y))\n    der_logx0 = 1.0 / mux0\n    for x in range(X):\n        dlogx0 = der_logx0[x]\n        for y in range(Y):\n            hess_n[x, y] = dlogx0\n    return hess_n, hess_m\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e_choo_siow_gender_heteroskedastic","title":"<code>e_choo_siow_gender_heteroskedastic(muhat)</code>","text":"<p>Returns the values of the parameter-dependent part  e for the Choo and Siow gender-heteroskedastic model; we normalized \\sigma=1.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>the (X,Y,1) array of the parameter-dependent part</p> <code>np.ndarray</code> <p>of the first derivative of the entropy.</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e_choo_siow_gender_heteroskedastic(muhat: Matching) -&gt; np.ndarray:\n\"\"\"Returns the values of the parameter-dependent part  $e$\n    for the Choo and Siow gender-heteroskedastic model; we normalized $\\\\sigma=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y,1) array of the parameter-dependent part\n        of the first derivative of the entropy.\n    \"\"\"\n    muxy, _, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    n_alpha = 1\n\n    e_vals = np.zeros((X, Y, n_alpha))\n    e_vals[:, :, 0] = -np.log(muxy / mu0y)\n    return e_vals\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e_derivative_mu_gender_heteroskedastic","title":"<code>e_derivative_mu_gender_heteroskedastic(muhat)</code>","text":"<p>Returns the derivatives of the parameter-dependent part e  wrt \\mu for the Choo and Siow gender-heteroskedastic model;  we normalized \\sigma_1=1.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt (\\mu,\\mu).</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e_derivative_mu_gender_heteroskedastic(\n    muhat: Matching,\n) -&gt; ThreeArrays:\n\"\"\"Returns the derivatives of the parameter-dependent part $e$\n     wrt $\\\\mu$ for the Choo and Siow gender-heteroskedastic model;\n     we normalized $\\\\sigma_1=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $(\\\\mu,\\\\mu)$.\n    \"\"\"\n    muxy, _, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    n_alpha = 1\n    hess_x = np.zeros((X, Y, Y, n_alpha))\n    hess_y = np.zeros((X, Y, X, n_alpha))\n    hess_xy = np.zeros((X, Y, n_alpha))\n    der_logxy = 1.0 / muxy\n    der_log0y = 1.0 / mu0y\n    for x in range(X):\n        for y in range(Y):\n            dlog0y = der_log0y[y]\n            hess_y[x, y, :, 0] = -dlog0y\n            hess_xy[x, y, 0] = -der_logxy[x, y] - dlog0y\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow_gender_heteroskedastic/#cupid_matching.choo_siow_gender_heteroskedastic.e_derivative_r_gender_heteroskedastic","title":"<code>e_derivative_r_gender_heteroskedastic(muhat)</code>","text":"<p>Returns the derivatives of the parameter-dependent part e  wrt r for the Choo and Siow gender-heteroskedastic model;  we normalized \\sigma_1=1.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt (\\mu,r)</p> Source code in <code>cupid_matching/choo_siow_gender_heteroskedastic.py</code> <pre><code>def e_derivative_r_gender_heteroskedastic(\n    muhat: Matching,\n) -&gt; TwoArrays:\n\"\"\"Returns the derivatives of the parameter-dependent part $e$\n     wrt $r$ for the Choo and Siow gender-heteroskedastic model;\n     we normalized $\\\\sigma_1=1$.\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $(\\\\mu,r)$\n    \"\"\"\n    muxy, _, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    n_alpha = 1\n    hess_n = np.zeros((X, Y, n_alpha))\n    hess_m = np.zeros((X, Y, n_alpha))\n    der_log0y = 1.0 / mu0y\n    for x in range(X):\n        for y in range(Y):\n            dlog0y = der_log0y[y]\n            hess_m[x, y, 0] = dlog0y\n    return hess_n, hess_m\n</code></pre>"},{"location":"choo_siow_heteroskedastic/","title":"<code>choo_siow_heteroskedastic</code> module","text":"<p>The components of the derivative of the entropy for the Choo and Siow fully heteroskedastic model.</p> <p>We normalize the standard error for X=1 at 1, and we estimate the standard errors for all other types on the X side and for all types on the Y side.</p>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e0_choo_siow_heteroskedastic","title":"<code>e0_choo_siow_heteroskedastic(muhat)</code>","text":"<p>Returns the values of the parameter-independent part e_0 for the Choo and Siow heteroskedastic model; we normalized \\sigma_1=1</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>the (X,Y) matrix of the parameter-independent part</p> <code>np.ndarray</code> <p>of the first derivative of the entropy</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e0_choo_siow_heteroskedastic(muhat: Matching) -&gt; np.ndarray:\n\"\"\"Returns the values of the parameter-independent part $e_0$\n    for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y) matrix of the parameter-independent part\n        of the first derivative of the entropy\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    mu1y = muxy[0, :]\n    mu10 = mux0[0]\n    e0_vals = np.zeros_like(muxy)\n    e0_vals[0, :] = -np.log(mu1y / mu10)\n    return e0_vals\n</code></pre>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e0_derivative_mu_heteroskedastic","title":"<code>e0_derivative_mu_heteroskedastic(muhat)</code>","text":"<p>Returns the derivatives of the parameter-independent part e_0 wrt \\mu for the Choo and Siow heteroskedastic model; we normalized \\sigma_1=1</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the parameter-independent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt (\\mu, \\mu).</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e0_derivative_mu_heteroskedastic(\n    muhat: Matching,\n) -&gt; ThreeArrays:\n\"\"\"Returns the derivatives of the parameter-independent part $e_0$\n    wrt $\\\\mu$ for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu, \\\\mu)$.\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    mu1y = muxy[0, :]\n    mu10 = mux0[0]\n    hess_x = np.zeros((X, Y, Y))\n    hess_y = np.zeros((X, Y, X))\n    hess_xy = np.zeros((X, Y))\n    der_log1y = 1.0 / mu1y\n    der_log10 = 1.0 / mu10\n    for y in range(Y):\n        hess_x[0, y, :] = -der_log10\n        hess_xy[0, y] = -der_log1y[y] - der_log10\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e0_derivative_r_heteroskedastic","title":"<code>e0_derivative_r_heteroskedastic(muhat)</code>","text":"<p>Returns the derivatives of the parameter-independent part e_0 wrt r for the Choo and Siow heteroskedastic model; we normalized \\sigma_1=1</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-independent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt (\\mu,r).</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e0_derivative_r_heteroskedastic(\n    muhat: Matching,\n) -&gt; TwoArrays:\n\"\"\"Returns the derivatives of the parameter-independent part $e_0$\n    wrt $r$ for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu,r)$.\n    \"\"\"\n    muxy, mux0, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    mu10 = mux0[0]\n    hess_n = np.zeros((X, Y))\n    hess_m = np.zeros((X, Y))\n    der_log10 = 1.0 / mu10\n    for y in range(Y):\n        hess_n[0, y] = der_log10\n    return hess_n, hess_m\n</code></pre>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e_choo_siow_heteroskedastic","title":"<code>e_choo_siow_heteroskedastic(muhat)</code>","text":"<p>Returns the values of the parameter-dependent part  e for the Choo and Siow heteroskedastic model; we normalized \\sigma_1=1</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy.</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e_choo_siow_heteroskedastic(muhat: Matching) -&gt; np.ndarray:\n\"\"\"Returns the values of the parameter-dependent part  $e$\n    for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the (X,Y,X+Y-1) parameter-dependent part of the hessian of the entropy.\n    \"\"\"\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    n_alpha = X + Y - 1\n\n    e_vals = np.zeros((X, Y, n_alpha))\n    i = 0\n    for x in range(1, X):\n        e_vals[x, :, i] = -np.log(muxy[x, :] / mux0[x])\n        i += 1\n    for y in range(Y):\n        e_vals[:, y, i] = -np.log(muxy[:, y] / mu0y[y])\n        i += 1\n\n    return e_vals\n</code></pre>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e_derivative_mu_heteroskedastic","title":"<code>e_derivative_mu_heteroskedastic(muhat)</code>","text":"<p>Returns the derivatives of the parameter-dependent part e wrt \\mu for the Choo and Siow heteroskedastic model; we normalized \\sigma_1=1</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt (\\mu,\\mu).</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e_derivative_mu_heteroskedastic(\n    muhat: Matching,\n) -&gt; ThreeArrays:\n\"\"\"Returns the derivatives of the parameter-dependent part $e$\n    wrt $\\\\mu$ for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $(\\\\mu,\\\\mu)$.\n    \"\"\"\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    n_alpha = X + Y - 1\n    hess_x = np.zeros((X, Y, Y, n_alpha))\n    hess_y = np.zeros((X, Y, X, n_alpha))\n    hess_xy = np.zeros((X, Y, n_alpha))\n\n    der_logxy = 1.0 / muxy\n    der_logx0 = 1.0 / mux0\n    der_log0y = 1.0 / mu0y\n    i = 0\n    for x in range(1, X):\n        # derivatives wrt sigma_x\n        dlogx0 = der_logx0[x]\n        dlogxy = der_logxy[x, :]\n        for y in range(Y):\n            hess_x[x, y, :, i] = -dlogx0\n            hess_xy[x, y, i] = -dlogxy[y] - dlogx0\n        i += 1\n    for y in range(Y):\n        # derivatives wrt tau_y\n        dlog0y = der_log0y[y]\n        dlogxy = der_logxy[:, y]\n        for x in range(X):\n            hess_y[x, y, :, i] = -dlog0y\n            hess_xy[x, y, i] = -dlogxy[x] - dlog0y\n        i += 1\n\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"choo_siow_heteroskedastic/#cupid_matching.choo_siow_heteroskedastic.e_derivative_r_heteroskedastic","title":"<code>e_derivative_r_heteroskedastic(muhat)</code>","text":"<p>Returns the derivatives of the parameter-dependent part e wrt r for the Choo and Siow heteroskedastic model; we normalized \\sigma_1=1</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt r.</p> Source code in <code>cupid_matching/choo_siow_heteroskedastic.py</code> <pre><code>def e_derivative_r_heteroskedastic(\n    muhat: Matching,\n) -&gt; TwoArrays:\n\"\"\"Returns the derivatives of the parameter-dependent part $e$\n    wrt $r$ for the Choo and Siow heteroskedastic model;\n    we normalized $\\\\sigma_1=1$\n\n    Args:\n        muhat: a Matching\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $r$.\n    \"\"\"\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    n_alpha = X + Y - 1\n    hess_n = np.zeros((X, Y, n_alpha))\n    hess_m = np.zeros((X, Y, n_alpha))\n\n    der_logx0 = 1.0 / mux0\n    der_log0y = 1.0 / mu0y\n    i = 0\n    for x in range(1, X):\n        # derivatives wrt sigma_x\n        dlogx0 = der_logx0[x]\n        for y in range(Y):\n            hess_n[x, y, i] = dlogx0\n        i += 1\n    for y in range(Y):\n        # derivatives wrt tau_y\n        dlog0y = der_log0y[y]\n        for x in range(X):\n            hess_m[x, y, i] = dlog0y\n        i += 1\n\n    return hess_n, hess_m\n</code></pre>"},{"location":"cupid_streamlit/","title":"<code>cupid_streamlit</code> module","text":"<p>An interactive Streamlit application that solves for the stable matching and estimates the parameters of the joint surplus in a Choo and Siow 2006 homoskedastic model.</p>"},{"location":"entropy/","title":"<code>entropy</code> module","text":"<p>Entropies and their derivatives.</p>"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianComponents","title":"<code>EntropyHessianComponents = tuple[ThreeArrays, TwoArrays]</code>  <code>module-attribute</code>","text":"<p>combines the tuples of the values  of the components of the hessians.</p>"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianMuMu","title":"<code>EntropyHessianMuMu = Callable[[Matching], ThreeArrays]</code>  <code>module-attribute</code>","text":"<p>The type of a function that takes in a Matching and returns the three components of the hessian of the entropy wrt (\\mu,\\mu).</p>"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianMuMuParam","title":"<code>EntropyHessianMuMuParam = Callable[[Matching, list[Any]], ThreeArrays]</code>  <code>module-attribute</code>","text":"<p>The type of a function that takes in a Matching and a list of additional parameters and returns the three components of the hessian of the entropy wrt (\\mu,\\mu).</p>"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianMuR","title":"<code>EntropyHessianMuR = Callable[[Matching], TwoArrays]</code>  <code>module-attribute</code>","text":"<p>The type of a function that takes in a Matching and returns the two components of the hessian of the entropy wrt (\\mu,n) and (\\mu, m)).</p>"},{"location":"entropy/#cupid_matching.entropy.EntropyHessianMuRParam","title":"<code>EntropyHessianMuRParam = Callable[[Matching, list[Any]], TwoArrays]</code>  <code>module-attribute</code>","text":"<p>The type of a function that takes in a Matching and a list of additional parameters and returns the two components of the hessian of the entropy wrt (\\mu,n) and (\\mu, m)).</p>"},{"location":"entropy/#cupid_matching.entropy.EntropyHessians","title":"<code>EntropyHessians = tuple[EntropyHessianMuMu, EntropyHessianMuR]</code>  <code>module-attribute</code>","text":"<p>combines the hessian functions</p>"},{"location":"entropy/#cupid_matching.entropy.EntropyHessiansParam","title":"<code>EntropyHessiansParam = tuple[EntropyHessianMuMuParam, EntropyHessianMuRParam]</code>  <code>module-attribute</code>","text":"<p>combines the hessian functions  when additional parameters are used</p>"},{"location":"entropy/#cupid_matching.entropy.EntropyFunctions","title":"<code>EntropyFunctions</code>  <code>dataclass</code>","text":"<p>Defines the entropy used, via the derivative e_0 + e \\cdot \\alpha</p> <p>Attributes:</p> Name Type Description <code>e0_fun</code> <code>MatchingFunction | MatchingFunctionParam</code> <p>required</p> <code>parameter_dependent</code> <code>bool</code> <p>if <code>True</code>, the entropy depends on parameters. Defaults to <code>False</code></p> <code>e_fun</code> <code>Optional[MatchingFunction | MatchingFunctionParam]</code> <p>only in entropies that depend on parameters. Defaults to <code>None</code></p> <code>hessian</code> <code>Optional[str]</code> <p>defaults to <code>\"numeric\"</code> * if <code>\"provided\"</code>, we provide the hessian of the entropy. * if <code>\"numerical\"</code>, it is computed by central differences.</p> <code>e0_derivative</code> <code>Optional[EntropyHessians | EntropyHessiansParam]</code> <p>the derivative of <code>e0_fun</code>, if available. Defaults to <code>None</code></p> <code>e_derivative</code> <code>Optional[EntropyHessians | EntropyHessiansParam]</code> <p>the derivative of <code>e_fun</code>, if available. Defaults to <code>None</code></p> <code>additional_parameters</code> <code>Optional[list]</code> <p>additional parameters that define the distribution of errors. Defaults to <code>None</code></p> <code>description</code> <code>Optional[str]</code> <p>some text describing the model. Defaults to <code>None</code></p> <p>Examples:</p> <p>See <code>entropy_choo_siow</code> in <code>choo_siow.py</code></p> Source code in <code>cupid_matching/entropy.py</code> <pre><code>@dataclass\nclass EntropyFunctions:\n\"\"\"Defines the entropy used, via the derivative $e_0 + e \\\\cdot \\\\alpha$\n\n    Attributes:\n        e0_fun: required\n        parameter_dependent:  if `True`, the entropy depends on parameters.\n            Defaults to `False`\n        e_fun: only in entropies that depend on parameters.\n            Defaults to `None`\n        hessian: defaults to `\"numeric\"`\n            * if `\"provided\"`, we provide the hessian of the entropy.\n            * if `\"numerical\"`, it is computed by central differences.\n        e0_derivative: the derivative of `e0_fun`, if available.\n            Defaults to `None`\n        e_derivative: the derivative of `e_fun`, if available.\n            Defaults to `None`\n        additional_parameters: additional parameters\n            that define the distribution of errors.\n            Defaults to `None`\n        description: some text describing the model.\n            Defaults to `None`\n\n    Examples:\n        See `entropy_choo_siow` in `choo_siow.py`\n    \"\"\"\n\n    e0_fun: MatchingFunction | MatchingFunctionParam\n    e0_derivative: Optional[EntropyHessians | EntropyHessiansParam] = None\n    additional_parameters: Optional[list] = None\n    description: Optional[str] = None\n    e_fun: Optional[MatchingFunction | MatchingFunctionParam] = None\n    e_derivative: Optional[EntropyHessians | EntropyHessiansParam] = None\n    hessian: Optional[str] = \"numerical\"\n    parameter_dependent: bool = False\n\n    def __post_init__(self):\n        if not self.parameter_dependent:\n            if self.hessian == \"provided\" and self.e0_derivative is None:\n                bs_error_abort(\n                    \"You claim to provide the hessian \"\n                    + \"but you did not provide the e0_derivative.\"\n                )\n        else:\n            if self.e_fun is None:\n                bs_error_abort(\n                    \"Your entropy is parameter dependent \"\n                    + \" but you did not provide the e_fun.\"\n                )\n            if self.hessian == \"provided\" and self.e_derivative is None:\n                bs_error_abort(\n                    \"Your entropy is parameter dependent, \"\n                    + \"you claim to provide the hessian,\\n\"\n                    + \" but I do not see the e_derivative.\"\n                )\n</code></pre>"},{"location":"entropy/#cupid_matching.entropy.entropy_gradient","title":"<code>entropy_gradient(entropy, muhat, alpha=None, additional_parameters=None)</code>","text":"<p>Computes the derivative of the entropy wrt \\mu  at (\\mu, n, m, \\alpha, p)</p> <p>Parameters:</p> Name Type Description Default <code>entropy</code> <code>EntropyFunctions</code> <p>the <code>EntropyFunctions</code> object</p> required <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>alpha</code> <code>Optional[np.ndarray]</code> <p>a vector of parameters of the derivative of the entropy, if any</p> <code>None</code> <code>additional_parameters</code> <code>Optional[list]</code> <p>a list of additional parameters <code>p</code>, if any</p> <code>None</code> <p>Returns:</p> Type Description <code>np.ndarray</code> <p>the derivative of the entropy wrt \\mu</p> <code>np.ndarray</code> <p>at (\\mu, n, m, \\alpha, p).</p> Source code in <code>cupid_matching/entropy.py</code> <pre><code>def entropy_gradient(\n    entropy: EntropyFunctions,\n    muhat: Matching,\n    alpha: Optional[np.ndarray] = None,\n    additional_parameters: Optional[list] = None,\n) -&gt; np.ndarray:\n\"\"\"Computes the derivative of the entropy wrt $\\\\mu$\n     at $(\\\\mu, n, m, \\\\alpha, p)$\n\n    Args:\n        entropy: the `EntropyFunctions` object\n        muhat: a Matching\n        alpha: a vector of parameters of the derivative of the entropy, if any\n        additional_parameters: a list of additional parameters `p`, if any\n\n    Returns:\n        the derivative of the entropy wrt $\\\\mu$\n        at $(\\\\mu, n, m, \\\\alpha, p)$.\n    \"\"\"\n    e0_fun = entropy.e0_fun\n    if additional_parameters is not None:\n        e0_fun = cast(MatchingFunctionParam, e0_fun)\n        e0_vals = e0_fun(muhat, additional_parameters)\n    else:\n        e0_fun = cast(MatchingFunction, e0_fun)\n        e0_vals = e0_fun(muhat)\n    parameter_dependent = entropy.parameter_dependent\n    if parameter_dependent:\n        if alpha is None:\n            bs_error_abort(\"alpha should be specified for this model\")\n        e_fun = entropy.e_fun\n        if e_fun is None:\n            bs_error_abort(\"we should have an e_fun in this model\")\n        else:\n            if additional_parameters is not None:\n                e_fun = cast(MatchingFunctionParam, e_fun)\n                e_vals = e_fun(muhat, additional_parameters)\n            else:\n                e_fun = cast(MatchingFunction, e_fun)\n                e_vals = e_fun(muhat)\n        return e0_vals + e_vals @ alpha\n    else:\n        return e0_vals\n</code></pre>"},{"location":"example_choosiow/","title":"<code>example_choosiow</code> module","text":"<p>example using the Choo and Siow homoskedastic model</p>"},{"location":"example_choosiow/#cupid_matching.example_choosiow.create_choosiow_population","title":"<code>create_choosiow_population(X, Y, K, std_betas=1.0)</code>","text":"<p>we simulate a Choo and Siow population with equal numbers of men and women of each type and random bases dunctions and coefficients</p> <pre><code>Args:\n X: number of types of men\n Y: number of types of women\n K: random basis functions\n std_betas: the coefficients are drawn from a centered normal\n             with this standard deviation\n\nReturns:\n    a ChooSiowPrimitives instance, the basis functions, and the coefficients\n</code></pre> Source code in <code>cupid_matching/example_choosiow.py</code> <pre><code>def create_choosiow_population(X: int, Y: int, K: int,\n                               std_betas: Optional[float] = 1.0) \\\n        -&gt; Tuple[ChooSiowPrimitives, np.ndarray, np.ndarray]:\n\"\"\"\n    we simulate a Choo and Siow population\n    with equal numbers of men and women of each type\n    and random bases dunctions and coefficients\n\n        Args:\n         X: number of types of men\n         Y: number of types of women\n         K: random basis functions\n         std_betas: the coefficients are drawn from a centered normal\n                     with this standard deviation\n\n        Returns:\n            a ChooSiowPrimitives instance, the basis functions, and the coefficients\n    \"\"\"\n    betas_true = std_betas * np.random.randn(K)\n    phi_bases = np.random.randn(X, Y, K)\n    n = np.ones(X)\n    m = np.ones(Y)\n    Phi = phi_bases @ betas_true\n    choo_siow_instance = ChooSiowPrimitives(Phi, n, m)\n    return choo_siow_instance, phi_bases, betas_true\n</code></pre>"},{"location":"example_choosiow/#cupid_matching.example_choosiow.mde_estimate","title":"<code>mde_estimate(mus_sim, phi_bases, betas_true, entropy, title)</code>","text":"<p>we estimate the parameters using the minimum distance estimator</p> <p>Parameters:</p> Name Type Description Default <code>mus_sim</code> <code>Matching</code> <p>a Choo and Siow Matching</p> required <code>phi_bases</code> <code>np.ndarray</code> <p>the basis functions</p> required <code>betas_true</code> <code>np.ndarray</code> <p>their true coefficients</p> required <code>entropy</code> <code>EntropyFunctions</code> <p>the entropy functions we use</p> required <code>title</code> <code>str</code> <p>the name of the estimator</p> required <p>Returns:</p> Type Description <code>float</code> <p>the largest absolute difference between the true and estimated coefficients</p> Source code in <code>cupid_matching/example_choosiow.py</code> <pre><code>def mde_estimate(mus_sim: Matching,\n                 phi_bases: np.ndarray,\n                 betas_true: np.ndarray,\n                 entropy: EntropyFunctions,\n                 title: str) -&gt; float:\n\"\"\"we estimate the parameters using the minimum distance estimator\n\n    Args:\n        mus_sim: a Choo and Siow Matching\n        phi_bases: the basis functions\n        betas_true: their true coefficients\n        entropy: the entropy functions we use\n        title: the name of the estimator\n\n    Returns:\n        the largest absolute difference between the true and estimated coefficients\n    \"\"\"\n    print_stars(f\"    {title}\")\n    mde_results = estimate_semilinear_mde(\n        mus_sim, phi_bases, entropy\n    )\n    mde_discrepancy = mde_results.print_results(true_coeffs=betas_true)\n    return mde_discrepancy\n</code></pre>"},{"location":"example_nestedlogit/","title":"<code>example_nestedlogit</code> module","text":"<p>example using a simple two-layer nested logit model One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters.</p>"},{"location":"example_nestedlogit/#cupid_matching.example_nestedlogit.create_nestedlogit_population","title":"<code>create_nestedlogit_population(X, Y, K, std_alphas=0.5, std_betas=1.0)</code>","text":"<p>we simulate a nested logit population with equal numbers of men and women of each type and random bases dunctions and coefficients</p> <pre><code>Args:\n X: number of types of men\n Y: number of types of women\n K: random basis functions\n std_alphas: the nest parameters are drawn from a U[0, std_alphas] distribution\n std_betas: the coefficients of the bases are drawn from a centered normal\n             with this standard deviation\n\nReturns:\n    a NestedLogitPrimitives instance, the basis functions, the true coefficients,\n    and the entropy functions\n</code></pre> Source code in <code>cupid_matching/example_nestedlogit.py</code> <pre><code>def create_nestedlogit_population(X: int, Y: int, K: int,\n                                  std_alphas: Optional[float] = 0.5,\n                                  std_betas: Optional[float] = 1.0) \\\n        -&gt; Tuple[NestedLogitPrimitives, np.ndarray, np.ndarray, EntropyFunctions, EntropyFunctions]:\n\"\"\"\n    we simulate a nested logit population\n    with equal numbers of men and women of each type\n    and random bases dunctions and coefficients\n\n        Args:\n         X: number of types of men\n         Y: number of types of women\n         K: random basis functions\n         std_alphas: the nest parameters are drawn from a U[0, std_alphas] distribution\n         std_betas: the coefficients of the bases are drawn from a centered normal\n                     with this standard deviation\n\n        Returns:\n            a NestedLogitPrimitives instance, the basis functions, the true coefficients,\n            and the entropy functions\n    \"\"\"\n    X, Y, K = 10, 12, 5\n    nests_for_each_x = [\n        list(range(1, Y // 2 + 1)),\n        list(range(Y // 2 + 1, Y + 1)),\n    ]\n    nests_for_each_y = [\n        list(range(1, X // 2 + 1)),\n        list(range(X // 2 + 1, X + 1)),\n    ]\n\n    n = np.ones(X)\n    m = np.ones(Y)\n    phi_bases = np.random.randn(X, Y, K)\n\n    entropy_nested_logit, entropy_nested_logit_numeric = setup_standard_nested_logit(nests_for_each_x,\n                                                                                     nests_for_each_y)\n    n_rhos, n_deltas = len(nests_for_each_x), len(nests_for_each_y)\n    n_alphas = n_rhos + n_deltas\n\n    betas_true = std_betas * np.random.randn(K)\n    alphas_true = std_alphas * np.random.uniform(size=n_alphas)\n\n    Phi = phi_bases @ betas_true\n    nested_logit_instance = NestedLogitPrimitives(\n        Phi, n, m, nests_for_each_x, nests_for_each_y, alphas_true\n    )\n    true_coeffs = np.concatenate((alphas_true, betas_true))\n    return nested_logit_instance, phi_bases, true_coeffs, entropy_nested_logit, entropy_nested_logit_numeric\n</code></pre>"},{"location":"example_nestedlogit/#cupid_matching.example_nestedlogit.mde_estimate","title":"<code>mde_estimate(mus_sim, phi_bases, true_coeffs, entropy, title)</code>","text":"<p>we estimate the parameters using the minimum distance estimator</p> <p>Parameters:</p> Name Type Description Default <code>mus_sim</code> <code>Matching</code> <p>a Choo and Siow Matching</p> required <code>phi_bases</code> <code>np.ndarray</code> <p>the basis functions</p> required <code>true_coeffs</code> <code>np.ndarray</code> <p>their true coefficients and  the nesting parameters</p> required <code>entropy</code> <code>EntropyFunctions</code> <p>the entropy functions we use</p> required <code>title</code> <code>str</code> <p>the name of the estimator</p> required <p>Returns:</p> Type Description <code>float</code> <p>the largest absolute difference between the true and estimated coefficients</p> Source code in <code>cupid_matching/example_nestedlogit.py</code> <pre><code>def mde_estimate(mus_sim: Matching,\n                 phi_bases: np.ndarray,\n                 true_coeffs: np.ndarray,\n                 entropy: EntropyFunctions,\n                 title: str) -&gt; float:\n\"\"\"we estimate the parameters using the minimum distance estimator\n\n    Args:\n        mus_sim: a Choo and Siow Matching\n        phi_bases: the basis functions\n        true_coeffs: their true coefficients and  the nesting parameters\n        entropy: the entropy functions we use\n        title: the name of the estimator\n\n    Returns:\n        the largest absolute difference between the true and estimated coefficients\n    \"\"\"\n    print_stars(f\"    {title}\")\n    mde_results = estimate_semilinear_mde(\n        mus_sim, phi_bases, entropy,\n        additional_parameters=entropy.additional_parameters,\n    )\n    mde_discrepancy = mde_results.print_results(true_coeffs=true_coeffs)\n    return mde_discrepancy\n</code></pre>"},{"location":"ipfp_solvers/","title":"<code>ipfp_solvers</code> module","text":"<p>Implementations of the IPFP algorithm to solve for equilibrium and do comparative statics in several variants of the <code>Choo and Siow 2006 &lt;https://www.jstor.org/stable/10.1086/498585?seq=1&gt;</code>_ model:</p> <ul> <li>homoskedastic with singles (as in Choo and Siow 2006)</li> <li>homoskedastic without singles</li> <li>gender-heteroskedastic: with a scale parameter on the error term for women</li> <li>gender- and type-heteroskedastic: with a scale parameter on the error term    for each gender and type</li> <li>two-level nested logit, with nests and nest parameters that do not depend on the type,    and {0} as the first nest</li> </ul> <p>Each solver, when fed the joint surplus and margins, returns the equilibrium matching patterns, the adding-up errors on the margins, and if requested (using <code>gr=True</code>) the derivatives of the matching patterns in all primitives.</p>"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_gender_heteroskedastic_solver","title":"<code>ipfp_gender_heteroskedastic_solver(Phi, men_margins, women_margins, tau, tol=1e-09, gr=False, verbose=False, maxiter=1000)</code>","text":"<p>Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market given systematic surplus and margins and a scale parameter <code>tau</code></p> <p>Parameters:</p> Name Type Description Default <code>Phi</code> <code>np.ndarray</code> <p>matrix of systematic surplus, shape (X, Y)</p> required <code>men_margins</code> <code>np.ndarray</code> <p>vector of men margins, shape (X)</p> required <code>women_margins</code> <code>np.ndarray</code> <p>vector of women margins, shape (Y)</p> required <code>tau</code> <code>float</code> <p>the standard error for all women</p> required <code>tol</code> <code>float</code> <p>tolerance on change in solution</p> <code>1e-09</code> <code>gr</code> <code>bool</code> <p>if <code>True</code>, also evaluate derivatives of the matching patterns</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>if <code>True</code>, prints information</p> <code>False</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations</p> <code>1000</code> <p>Returns:</p> Type Description <code>muxy, mux0, mu0y</code> <p>the matching patterns</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>marg_err_x, marg_err_y: the errors on the margins</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>and the gradients of the matching patterns</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>wrt (men_margins, women_margins, Phi, tau) if <code>gr</code> is <code>True</code></p> Source code in <code>cupid_matching/ipfp_solvers.py</code> <pre><code>def ipfp_gender_heteroskedastic_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    tau: float,\n    tol: float = 1e-9,\n    gr: bool = False,\n    verbose: bool = False,\n    maxiter: int = 1000,\n) -&gt; IPFPNoGradientResults | IPFPGradientResults:\n\"\"\"Solves for equilibrium in a in a gender-heteroskedastic Choo and Siow market\n    given systematic surplus and margins and a scale parameter `tau`\n\n    Args:\n        Phi: matrix of systematic surplus, shape (X, Y)\n        men_margins: vector of men margins, shape (X)\n        women_margins: vector of women margins, shape (Y)\n        tau: the standard error for all women\n        tol: tolerance on change in solution\n        gr: if `True`, also evaluate derivatives of the matching patterns\n        verbose: if `True`, prints information\n        maxiter: maximum number of iterations\n\n    Returns:\n         (muxy, mux0, mu0y): the matching patterns\n         marg_err_x, marg_err_y: the errors on the margins\n         and the gradients of the matching patterns\n         wrt (men_margins, women_margins, Phi, tau) if `gr` is `True`\n    \"\"\"\n    X, Y = _ipfp_check_sizes(men_margins, women_margins, Phi)\n\n    if tau &lt;= 0:\n        bs_error_abort(f\"We need a positive tau, not {tau}\")\n\n    #############################################################################\n    # we use ipfp_heteroxy_solver with sigma_x = 1 and tau_y = tau\n    #############################################################################\n\n    sigma_x = np.ones(X)\n    tau_y = np.full(Y, tau)\n\n    if gr:\n        (\n            mus_hxy,\n            marg_err_x,\n            marg_err_y,\n            dmus_xy,\n            dmus_x0,\n            dmus_0y,\n        ) = ipfp_heteroskedastic_solver(\n            Phi,\n            men_margins,\n            women_margins,\n            sigma_x,\n            tau_y,\n            tol=tol,\n            gr=True,\n            maxiter=maxiter,\n            verbose=verbose,\n        )\n        muxy, _, _, _, _ = mus_hxy.unpack()\n        n_sum_categories = X + Y\n        n_prod_categories = X * Y\n        n_cols = n_sum_categories + n_prod_categories\n        itau_y = n_cols + X\n        dmuxy = np.zeros((n_prod_categories, n_cols + 1))\n        dmuxy[:, :n_cols] = dmus_xy[:, :n_cols]\n        dmuxy[:, -1] = np.sum(dmus_xy[:, itau_y:], 1)\n        dmux0 = np.zeros((X, n_cols + 1))\n        dmux0[:, :n_cols] = dmus_x0[:, :n_cols]\n        dmux0[:, -1] = np.sum(dmus_x0[:, itau_y:], 1)\n        dmu0y = np.zeros((Y, n_cols + 1))\n        dmu0y[:, :n_cols] = dmus_0y[:, :n_cols]\n        dmu0y[:, -1] = np.sum(dmus_0y[:, itau_y:], 1)\n        return (\n            Matching(muxy, men_margins, women_margins),\n            marg_err_x,\n            marg_err_y,\n            dmuxy,\n            dmux0,\n            dmu0y,\n        )\n\n    else:\n        return ipfp_heteroskedastic_solver(\n            Phi,\n            men_margins,\n            women_margins,\n            sigma_x,\n            tau_y,\n            tol=tol,\n            gr=False,\n            maxiter=maxiter,\n            verbose=verbose,\n        )\n</code></pre>"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_heteroskedastic_solver","title":"<code>ipfp_heteroskedastic_solver(Phi, men_margins, women_margins, sigma_x, tau_y, tol=1e-09, gr=False, verbose=False, maxiter=1000)</code>","text":"<p>Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market given systematic surplus and margins and standard errors <code>sigma_x</code> and <code>tau_y</code></p> <p>Parameters:</p> Name Type Description Default <code>Phi</code> <code>np.ndarray</code> <p>matrix of systematic surplus, shape (X, Y)</p> required <code>men_margins</code> <code>np.ndarray</code> <p>vector of men margins, shape (X)</p> required <code>women_margins</code> <code>np.ndarray</code> <p>vector of women margins, shape (Y)</p> required <code>sigma_x</code> <code>np.ndarray</code> <p>the vector of standard errors for the X types of men</p> required <code>sigma_x</code> <code>np.ndarray</code> <p>the vector of standard errors for Y types of women</p> required <code>tol</code> <code>float</code> <p>tolerance on change in solution</p> <code>1e-09</code> <code>gr</code> <code>bool</code> <p>if <code>True</code>, also evaluate derivatives of the matching patterns</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>if <code>True</code>, prints information</p> <code>False</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations</p> <code>1000</code> <p>Returns:</p> Type Description <code>muxy, mux0, mu0y</code> <p>the matching patterns</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>marg_err_x, marg_err_y: the errors on the margins</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>and the gradients of the matching patterns</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>wrt (men_margins, women_margins, Phi, sigma_x, tau_y)</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>if <code>gr</code> is <code>True</code></p> Source code in <code>cupid_matching/ipfp_solvers.py</code> <pre><code>def ipfp_heteroskedastic_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    sigma_x: np.ndarray,\n    tau_y: np.ndarray,\n    tol: float = 1e-9,\n    gr: bool = False,\n    verbose: bool = False,\n    maxiter: int = 1000,\n) -&gt; IPFPNoGradientResults | IPFPGradientResults:\n\"\"\"Solves for equilibrium in a in a fully heteroskedastic Choo and Siow market\n    given systematic surplus and margins\n    and standard errors `sigma_x` and `tau_y`\n\n    Args:\n        Phi: matrix of systematic surplus, shape (X, Y)\n        men_margins: vector of men margins, shape (X)\n        women_margins: vector of women margins, shape (Y)\n        sigma_x: the vector of standard errors for the X types of men\n        sigma_x: the vector of standard errors for Y types of women\n        tol: tolerance on change in solution\n        gr: if `True`, also evaluate derivatives of the matching patterns\n        verbose: if `True`, prints information\n        maxiter: maximum number of iterations\n\n    Returns:\n         (muxy, mux0, mu0y): the matching patterns\n         marg_err_x, marg_err_y: the errors on the margins\n         and the gradients of the matching patterns\n         wrt (men_margins, women_margins, Phi, sigma_x, tau_y)\n         if `gr` is `True`\n    \"\"\"\n\n    X, Y = _ipfp_check_sizes(men_margins, women_margins, Phi)\n\n    if np.min(sigma_x) &lt;= 0.0:\n        bs_error_abort(\"All elements of sigma_x must be positive\")\n    if np.min(tau_y) &lt;= 0.0:\n        bs_error_abort(\"All elements of tau_y must be positive\")\n\n    sumxy1 = 1.0 / np.add.outer(sigma_x, tau_y)\n    ephi2, der_ephi2 = npexp(Phi * sumxy1, deriv=True)\n\n    #############################################################################\n    # we solve the equilibrium equations muxy = ephi2 * tx * ty\n    #   with tx = mux0^(sigma_x/(sigma_x + tau_max))\n    #   and ty = mu0y^(tau_y/(sigma_max + tau_y))\n    #   starting with a reasonable initial point for tx and ty: tx = ty = bigc\n    #   it is important that it fit the number of individuals\n    #############################################################################\n\n    nindivs = np.sum(men_margins) + np.sum(women_margins)\n    bigc = nindivs / (X + Y + 2.0 * np.sum(ephi2))\n    # we find the largest values of sigma_x and tau_y\n    xmax = np.argmax(sigma_x)\n    sigma_max = sigma_x[xmax]\n    ymax = np.argmax(tau_y)\n    tau_max = tau_y[ymax]\n    # we use tx = mux0^(sigma_x/(sigma_x + tau_max))\n    #    and ty = mu0y^(tau_y/(sigma_max + tau_y))\n    sig_taumax = sigma_x + tau_max\n    txi = np.power(bigc, sigma_x / sig_taumax)\n    sigmax_tau = tau_y + sigma_max\n    tyi = np.power(bigc, tau_y / sigmax_tau)\n    err_diff = bigc\n    tol_diff = tol * bigc\n    tol_newton = tol\n    niter = 0\n    while (err_diff &gt; tol_diff) and (niter &lt; maxiter):  # IPFP main loop\n        # Newton iterates for men\n        err_newton = bigc\n        txin = txi.copy()\n        mu0y_in = np.power(np.power(tyi, sigmax_tau), 1.0 / tau_y)\n        while err_newton &gt; tol_newton:\n            txit = np.power(txin, sig_taumax)\n            mux0_in = np.power(txit, 1.0 / sigma_x)\n            out_xy = np.outer(\n                np.power(mux0_in, sigma_x), np.power(mu0y_in, tau_y)\n            )\n            muxy_in = ephi2 * np.power(out_xy, sumxy1)\n            errxi = mux0_in + np.sum(muxy_in, 1) - men_margins\n            err_newton = npmaxabs(errxi)\n            txin -= errxi / (\n                sig_taumax\n                * (mux0_in / sigma_x + np.sum(sumxy1 * muxy_in, 1))\n                / txin\n            )\n        tx = txin\n\n        # Newton iterates for women\n        err_newton = bigc\n        tyin = tyi.copy()\n        mux0_in = np.power(np.power(tx, sig_taumax), 1.0 / sigma_x)\n        while err_newton &gt; tol_newton:\n            tyit = np.power(tyin, sigmax_tau)\n            mu0y_in = np.power(tyit, 1.0 / tau_y)\n            out_xy = np.outer(\n                np.power(mux0_in, sigma_x), np.power(mu0y_in, tau_y)\n            )\n            muxy_in = ephi2 * np.power(out_xy, sumxy1)\n            erryi = mu0y_in + np.sum(muxy_in, 0) - women_margins\n            err_newton = npmaxabs(erryi)\n            tyin -= erryi / (\n                sigmax_tau\n                * (mu0y_in / tau_y + np.sum(sumxy1 * muxy_in, 0))\n                / tyin\n            )\n\n        ty = tyin\n\n        err_x = npmaxabs(tx - txi)\n        err_y = npmaxabs(ty - tyi)\n        err_diff = err_x + err_y\n\n        txi = tx\n        tyi = ty\n\n        niter += 1\n\n    mux0 = mux0_in\n    mu0y = mu0y_in\n    muxy = muxy_in\n    marg_err_x = mux0 + np.sum(muxy, 1) - men_margins\n    marg_err_y = mu0y + np.sum(muxy, 0) - women_margins\n\n    if verbose:\n        print(f\"After {niter} iterations:\")\n        print(f\"\\tMargin error on x: {npmaxabs(marg_err_x)}\")\n        print(f\"\\tMargin error on y: {npmaxabs(marg_err_y)}\")\n    if not gr:\n        return (\n            Matching(muxy, men_margins, women_margins),\n            marg_err_x,\n            marg_err_y,\n        )\n    else:  # we compute the derivatives\n        n_sum_categories = X + Y\n        n_prod_categories = X * Y\n        # we work directly with (mux0, mu0y)\n        sigrat_xy = sumxy1 * sigma_x.reshape((-1, 1))\n        taurat_xy = 1.0 - sigrat_xy\n        mux0_mat = nprepeat_col(mux0, Y)\n        mu0y_mat = nprepeat_row(mu0y, X)\n        # muxy = axy * bxy * ephi2\n        axy = nppow(mux0_mat, sigrat_xy)\n        bxy = nppow(mu0y_mat, taurat_xy)\n        der_axy1, der_axy2 = der_nppow(mux0_mat, sigrat_xy)\n        der_bxy1, der_bxy2 = der_nppow(mu0y_mat, taurat_xy)\n        der_axy1_rat, der_axy2_rat = der_axy1 / axy, der_axy2 / axy\n        der_bxy1_rat, der_bxy2_rat = der_bxy1 / bxy, der_bxy2 / bxy\n\n        # start with the LHS of the linear system on (dmux0, dmu0y)\n        lhs = np.zeros((n_sum_categories, n_sum_categories))\n        lhs[:X, :X] = np.diag(1.0 + np.sum(muxy * der_axy1_rat, 1))\n        lhs[:X, X:] = muxy * der_bxy1_rat\n        lhs[X:, X:] = np.diag(1.0 + np.sum(muxy * der_bxy1_rat, 0))\n        lhs[X:, :X] = (muxy * der_axy1_rat).T\n\n        # now fill the RHS (derivatives wrt men_margins, then men_margins,\n        #    then Phi, then sigma_x and tau_y)\n        n_cols_rhs = n_sum_categories + n_prod_categories + X + Y\n        rhs = np.zeros((n_sum_categories, n_cols_rhs))\n\n        #  to compute derivatives of (mux0, mu0y) wrt men_margins\n        rhs[:X, :X] = np.eye(X)\n        #  to compute derivatives of (mux0, mu0y) wrt women_margins\n        rhs[X:, X:n_sum_categories] = np.eye(Y)\n\n        #   the next line is sumxy1 with safeguards\n        sumxy1_safe = sumxy1 * der_ephi2 / ephi2\n\n        big_a = muxy * sumxy1_safe\n        big_b = der_axy2_rat - der_bxy2_rat\n        b_mu_s = big_b * muxy * sumxy1\n        a_phi = Phi * big_a\n        big_c = sumxy1 * (a_phi - b_mu_s * tau_y)\n        big_d = sumxy1 * (a_phi + b_mu_s * sigma_x.reshape((-1, 1)))\n\n        #  to compute derivatives of (mux0, mu0y) wrt Phi\n        ivar = n_sum_categories\n        for iman in range(X):\n            rhs[iman, ivar : (ivar + Y)] = -big_a[iman, :]\n            ivar += Y\n        ivar1 = X\n        ivar2 = n_sum_categories\n        iend_phi = n_sum_categories + n_prod_categories\n        for iwoman in range(Y):\n            rhs[ivar1, ivar2:iend_phi:Y] = -big_a[:, iwoman]\n            ivar1 += 1\n            ivar2 += 1\n\n        #  to compute derivatives of (mux0, mu0y) wrt sigma_x\n        iend_sig = iend_phi + X\n        der_sigx = np.sum(big_c, 1)\n        rhs[:X, iend_phi:iend_sig] = np.diag(der_sigx)\n        rhs[X:, iend_phi:iend_sig] = big_c.T\n        #  to compute derivatives of (mux0, mu0y) wrt tau_y\n        der_tauy = np.sum(big_d, 0)\n        rhs[X:, iend_sig:] = np.diag(der_tauy)\n        rhs[:X, iend_sig:] = big_d\n\n        # solve for the derivatives of mux0 and mu0y\n        dmu0 = spla.solve(lhs, rhs)\n        dmux0 = dmu0[:X, :]\n        dmu0y = dmu0[X:, :]\n\n        # now construct the derivatives of muxy\n        dmuxy = np.zeros((n_prod_categories, n_cols_rhs))\n        der1 = ephi2 * der_axy1 * bxy\n        ivar = 0\n        for iman in range(X):\n            dmuxy[ivar : (ivar + Y), :] = np.outer(\n                der1[iman, :], dmux0[iman, :]\n            )\n            ivar += Y\n        der2 = ephi2 * der_bxy1 * axy\n        for iwoman in range(Y):\n            dmuxy[iwoman:n_prod_categories:Y, :] += np.outer(\n                der2[:, iwoman], dmu0y[iwoman, :]\n            )\n\n        # add the terms that comes from differentiating ephi2\n        #  on the derivative wrt Phi\n        i = 0\n        j = n_sum_categories\n        for iman in range(X):\n            for iwoman in range(Y):\n                dmuxy[i, j] += big_a[iman, iwoman]\n                i += 1\n                j += 1\n        #  on the derivative wrt sigma_x\n        ivar = 0\n        ix = iend_phi\n        for iman in range(X):\n            dmuxy[ivar : (ivar + Y), ix] -= big_c[iman, :]\n            ivar += Y\n            ix += 1\n        # on the derivative wrt tau_y\n        iy = iend_sig\n        for iwoman in range(Y):\n            dmuxy[iwoman:n_prod_categories:Y, iy] -= big_d[:, iwoman]\n            iy += 1\n\n        return (\n            Matching(muxy, men_margins, women_margins),\n            marg_err_x,\n            marg_err_y,\n            dmuxy,\n            dmux0,\n            dmu0y,\n        )\n</code></pre>"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_homoskedastic_nosingles_solver","title":"<code>ipfp_homoskedastic_nosingles_solver(Phi, men_margins, women_margins, tol=1e-09, gr=False, verbose=False, maxiter=1000)</code>","text":"<p>Solves for equilibrium in a Choo and Siow market without singles, given systematic surplus and margins</p> <p>Parameters:</p> Name Type Description Default <code>Phi</code> <code>np.ndarray</code> <p>matrix of systematic surplus, shape (X, Y)</p> required <code>men_margins</code> <code>np.ndarray</code> <p>vector of men margins, shape (X)</p> required <code>women_margins</code> <code>np.ndarray</code> <p>vector of women margins, shape (Y)</p> required <code>tol</code> <code>float</code> <p>tolerance on change in solution</p> <code>1e-09</code> <code>gr</code> <code>bool</code> <p>if <code>True</code>, also evaluate derivatives of (\\mu_{xy}) wrt \\Phi</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>if <code>True</code>, prints information</p> <code>False</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations</p> <code>1000</code> <p>Returns:</p> Name Type Description <code>muxy</code> <code>ThreeArrays | FourArrays</code> <p>the matching patterns, shape (X, Y)</p> <code>ThreeArrays | FourArrays</code> <p>marg_err_x, marg_err_y: the errors on the margins</p> <code>ThreeArrays | FourArrays</code> <p>and the gradients of (\\mu_{xy}) wrt \\Phi if <code>gr</code> is <code>True</code></p> Source code in <code>cupid_matching/ipfp_solvers.py</code> <pre><code>def ipfp_homoskedastic_nosingles_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    tol: float = 1e-9,\n    gr: bool = False,\n    verbose: bool = False,\n    maxiter: int = 1000,\n) -&gt; ThreeArrays | FourArrays:\n\"\"\"Solves for equilibrium in a Choo and Siow market without singles,\n    given systematic surplus and margins\n\n    Args:\n        Phi: matrix of systematic surplus, shape (X, Y)\n        men_margins: vector of men margins, shape (X)\n        women_margins: vector of women margins, shape (Y)\n        tol: tolerance on change in solution\n        gr: if `True`, also evaluate derivatives of $(\\\\mu_{xy})$ wrt $\\\\Phi$\n        verbose: if `True`, prints information\n        maxiter: maximum number of iterations\n\n    Returns:\n         muxy: the matching patterns, shape (X, Y)\n         marg_err_x, marg_err_y: the errors on the margins\n         and the gradients of $(\\\\mu_{xy})$ wrt $\\\\Phi$ if `gr` is `True`\n    \"\"\"\n    X, Y = _ipfp_check_sizes(men_margins, women_margins, Phi)\n    n_couples = np.sum(men_margins)\n\n    # check that there are as many men as women\n    if np.abs(np.sum(women_margins) - n_couples) &gt; n_couples * tol:\n        bs_error_abort(\"There should be as many men as women\")\n\n    ephi2, der_ephi2 = npexp(Phi / 2.0, deriv=True)\n    ephi2T = ephi2.T\n\n    #############################################################################\n    # we solve the equilibrium equations muxy = ephi2 * tx * ty\n    #   starting with a reasonable initial point for tx and ty: : tx = ty = bigc\n    #   it is important that it fit the number of individuals\n    #############################################################################\n    bigc = sqrt(n_couples / np.sum(ephi2))\n    txi = np.full(X, bigc)\n    tyi = np.full(Y, bigc)\n\n    err_diff = bigc\n    tol_diff = tol * err_diff\n    niter = 0\n    while (err_diff &gt; tol_diff) and (niter &lt; maxiter):\n        sx = ephi2 @ tyi\n        tx = men_margins / sx\n        sy = ephi2T @ tx\n        ty = women_margins / sy\n        err_x = npmaxabs(tx - txi)\n        err_y = npmaxabs(ty - tyi)\n        err_diff = err_x + err_y\n        txi, tyi = tx, ty\n        niter += 1\n    muxy = ephi2 * np.outer(txi, tyi)\n    marg_err_x = np.sum(muxy, 1) - men_margins\n    marg_err_y = np.sum(muxy, 0) - women_margins\n    if verbose:\n        print(f\"After {niter} iterations:\")\n        print(f\"\\tMargin error on x: {npmaxabs(marg_err_x)}\")\n        print(f\"\\tMargin error on y: {npmaxabs(marg_err_y)}\")\n    if not gr:\n        return muxy, marg_err_x, marg_err_y\n    else:\n        sxi = ephi2 @ tyi\n        syi = ephi2T @ txi\n        n_sum_categories = X + Y\n        n_prod_categories = X * Y\n\n        # start with the LHS of the linear system\n        lhs = np.zeros((n_sum_categories, n_sum_categories))\n        lhs[:X, :X] = np.diag(sxi)\n        lhs[:X, X:] = ephi2 * txi.reshape((-1, 1))\n        lhs[X:, X:] = np.diag(syi)\n        lhs[X:, :X] = ephi2T * tyi.reshape((-1, 1))\n\n        # now fill the RHS\n        n_cols_rhs = n_prod_categories\n        rhs = np.zeros((n_sum_categories, n_cols_rhs))\n\n        #  to compute derivatives of (txi, tyi) wrt Phi\n        der_ephi2 /= 2.0 * ephi2  # 1/2 with safeguards\n        ivar = 0\n        for iman in range(X):\n            rhs[iman, ivar : (ivar + Y)] = -muxy[iman, :] * der_ephi2[iman, :]\n            ivar += Y\n        ivar1 = X\n        ivar2 = 0\n        for iwoman in range(Y):\n            rhs[ivar1, ivar2:n_cols_rhs:Y] = (\n                -muxy[:, iwoman] * der_ephi2[:, iwoman]\n            )\n            ivar1 += 1\n            ivar2 += 1\n        # solve for the derivatives of txi and tyi\n        dt_dT = spla.solve(lhs, rhs)\n        dt = dt_dT[:X, :]\n        dT = dt_dT[X:, :]\n        # now construct the derivatives of muxy\n        dmuxy = np.zeros((n_prod_categories, n_cols_rhs))\n        ivar = 0\n        for iman in range(X):\n            dt_man = dt[iman, :]\n            dmuxy[ivar : (ivar + Y), :] = np.outer(\n                (ephi2[iman, :] * tyi), dt_man\n            )\n            ivar += Y\n        for iwoman in range(Y):\n            dT_woman = dT[iwoman, :]\n            dmuxy[iwoman:n_prod_categories:Y, :] += np.outer(\n                (ephi2[:, iwoman] * txi), dT_woman\n            )\n        # add the term that comes from differentiating ephi2\n        muxy_vec2 = (muxy * der_ephi2).reshape(n_prod_categories)\n        dmuxy += np.diag(muxy_vec2)\n        return muxy, marg_err_x, marg_err_y, dmuxy\n</code></pre>"},{"location":"ipfp_solvers/#cupid_matching.ipfp_solvers.ipfp_homoskedastic_solver","title":"<code>ipfp_homoskedastic_solver(Phi, men_margins, women_margins, tol=1e-09, gr=False, verbose=False, maxiter=1000)</code>","text":"<p>Solves for equilibrium in a Choo and Siow market with singles, given systematic surplus and margins</p> <p>Parameters:</p> Name Type Description Default <code>Phi</code> <code>np.ndarray</code> <p>matrix of systematic surplus, shape (X, Y)</p> required <code>men_margins</code> <code>np.ndarray</code> <p>vector of men margins, shape (X)</p> required <code>women_margins</code> <code>np.ndarray</code> <p>vector of women margins, shape (Y)</p> required <code>tol</code> <code>float</code> <p>tolerance on change in solution</p> <code>1e-09</code> <code>gr</code> <code>bool</code> <p>if <code>True</code>, also evaluate derivatives of the matching patterns</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>if <code>True</code>, prints information</p> <code>False</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations</p> <code>1000</code> <p>Returns:</p> Type Description <code>muxy, mux0, mu0y</code> <p>the matching patterns</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>marg_err_x, marg_err_y: the errors on the margins</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>and the gradients of the matching patterns wrt (men_margins, women_margins, Phi)</p> <code>IPFPNoGradientResults | IPFPGradientResults</code> <p>if <code>gr</code> is <code>True</code></p> Example <pre><code># we generate a Choo and Siow homoskedastic matching\nX = Y = 20\nn_sum_categories = X + Y\nn_prod_categories = X * Y\n\nmu, sigma = 0.0, 1.0\nn_bases = 4\nbases_surplus = np.zeros((X, Y, n_bases))\nx_men = (np.arange(X) - X / 2.0) / X\ny_women = (np.arange(Y) - Y / 2.0) / Y\n\nbases_surplus[:, :, 0] = 1\nfor iy in range(Y):\n    bases_surplus[:, iy, 1] = x_men\nfor ix in range(X):\n    bases_surplus[ix, :, 2] = y_women\nfor ix in range(X):\n    for iy in range(Y):\n        bases_surplus[ix, iy, 3] = (x_men[ix] - y_women[iy]) * (\n            x_men[ix] - y_women[iy]\n        )\n\nmen_margins = np.random.uniform(1.0, 10.0, size=X)\nwomen_margins = np.random.uniform(1.0, 10.0, size=Y)\n\n# np.random.normal(mu, sigma, size=n_bases)\ntrue_surplus_params = np.array([3.0, -1.0, -1.0, -2.0])\ntrue_surplus_matrix = bases_surplus @ true_surplus_params\n\nmus, marg_err_x, marg_err_y = ipfp_homoskedastic_solver(\n    true_surplus_matrix, men_margins, women_margins, tol=1e-12\n)\n</code></pre> Source code in <code>cupid_matching/ipfp_solvers.py</code> <pre><code>def ipfp_homoskedastic_solver(\n    Phi: np.ndarray,\n    men_margins: np.ndarray,\n    women_margins: np.ndarray,\n    tol: float = 1e-9,\n    gr: bool = False,\n    verbose: bool = False,\n    maxiter: int = 1000,\n) -&gt; IPFPNoGradientResults | IPFPGradientResults:\n\"\"\"Solves for equilibrium in a Choo and Siow market with singles,\n    given systematic surplus and margins\n\n    Args:\n        Phi: matrix of systematic surplus, shape (X, Y)\n        men_margins: vector of men margins, shape (X)\n        women_margins: vector of women margins, shape (Y)\n        tol: tolerance on change in solution\n        gr: if `True`, also evaluate derivatives of the matching patterns\n        verbose: if `True`, prints information\n        maxiter: maximum number of iterations\n\n    Returns:\n         (muxy, mux0, mu0y): the matching patterns\n         marg_err_x, marg_err_y: the errors on the margins\n         and the gradients of the matching patterns wrt (men_margins, women_margins, Phi)\n         if `gr` is `True`\n\n\n    Example:\n        ```py\n        # we generate a Choo and Siow homoskedastic matching\n        X = Y = 20\n        n_sum_categories = X + Y\n        n_prod_categories = X * Y\n\n        mu, sigma = 0.0, 1.0\n        n_bases = 4\n        bases_surplus = np.zeros((X, Y, n_bases))\n        x_men = (np.arange(X) - X / 2.0) / X\n        y_women = (np.arange(Y) - Y / 2.0) / Y\n\n        bases_surplus[:, :, 0] = 1\n        for iy in range(Y):\n            bases_surplus[:, iy, 1] = x_men\n        for ix in range(X):\n            bases_surplus[ix, :, 2] = y_women\n        for ix in range(X):\n            for iy in range(Y):\n                bases_surplus[ix, iy, 3] = (x_men[ix] - y_women[iy]) * (\n                    x_men[ix] - y_women[iy]\n                )\n\n        men_margins = np.random.uniform(1.0, 10.0, size=X)\n        women_margins = np.random.uniform(1.0, 10.0, size=Y)\n\n        # np.random.normal(mu, sigma, size=n_bases)\n        true_surplus_params = np.array([3.0, -1.0, -1.0, -2.0])\n        true_surplus_matrix = bases_surplus @ true_surplus_params\n\n        mus, marg_err_x, marg_err_y = ipfp_homoskedastic_solver(\n            true_surplus_matrix, men_margins, women_margins, tol=1e-12\n        )\n        ```\n    \"\"\"\n    X, Y = _ipfp_check_sizes(men_margins, women_margins, Phi)\n\n    ephi2, der_ephi2 = npexp(Phi / 2.0, deriv=True)\n\n    #############################################################################\n    # we solve the equilibrium equations muxy = ephi2 * tx * ty\n    #   where mux0=tx**2  and mu0y=ty**2\n    #   starting with a reasonable initial point for tx and ty: tx = ty = bigc\n    #   it is important that it fit the number of individuals\n    #############################################################################\n\n    ephi2T = ephi2.T\n    nindivs = np.sum(men_margins) + np.sum(women_margins)\n    bigc = sqrt(nindivs / (X + Y + 2.0 * np.sum(ephi2)))\n    txi = np.full(X, bigc)\n    tyi = np.full(Y, bigc)\n\n    err_diff = bigc\n    tol_diff = tol * bigc\n    niter = 0\n    while (err_diff &gt; tol_diff) and (niter &lt; maxiter):\n        sx = ephi2 @ tyi\n        tx = (np.sqrt(sx * sx + 4.0 * men_margins) - sx) / 2.0\n        sy = ephi2T @ tx\n        ty = (np.sqrt(sy * sy + 4.0 * women_margins) - sy) / 2.0\n        err_x = npmaxabs(tx - txi)\n        err_y = npmaxabs(ty - tyi)\n        err_diff = err_x + err_y\n        txi = tx\n        tyi = ty\n        niter += 1\n    mux0 = txi * txi\n    mu0y = tyi * tyi\n    muxy = ephi2 * np.outer(txi, tyi)\n    marg_err_x = mux0 + np.sum(muxy, 1) - men_margins\n    marg_err_y = mu0y + np.sum(muxy, 0) - women_margins\n    if verbose:\n        print(f\"After {niter} iterations:\")\n        print(f\"\\tMargin error on x: {npmaxabs(marg_err_x)}\")\n        print(f\"\\tMargin error on y: {npmaxabs(marg_err_y)}\")\n    if not gr:\n        return (\n            Matching(muxy, men_margins, women_margins),\n            marg_err_x,\n            marg_err_y,\n        )\n    else:  # we compute the derivatives\n        sxi = ephi2 @ tyi\n        syi = ephi2T @ txi\n        n_sum_categories = X + Y\n        n_prod_categories = X * Y\n        # start with the LHS of the linear system\n        lhs = np.zeros((n_sum_categories, n_sum_categories))\n        lhs[:X, :X] = np.diag(2.0 * txi + sxi)\n        lhs[:X, X:] = ephi2 * txi.reshape((-1, 1))\n        lhs[X:, X:] = np.diag(2.0 * tyi + syi)\n        lhs[X:, :X] = ephi2T * tyi.reshape((-1, 1))\n        # now fill the RHS\n        n_cols_rhs = n_sum_categories + n_prod_categories\n        rhs = np.zeros((n_sum_categories, n_cols_rhs))\n        #  to compute derivatives of (txi, tyi) wrt men_margins\n        rhs[:X, :X] = np.eye(X)\n        #  to compute derivatives of (txi, tyi) wrt women_margins\n        rhs[X:n_sum_categories, X:n_sum_categories] = np.eye(Y)\n        #  to compute derivatives of (txi, tyi) wrt Phi\n        der_ephi2 /= 2.0 * ephi2  # 1/2 with safeguards\n        ivar = n_sum_categories\n        for iman in range(X):\n            rhs[iman, ivar : (ivar + Y)] = -muxy[iman, :] * der_ephi2[iman, :]\n            ivar += Y\n        ivar1 = X\n        ivar2 = n_sum_categories\n        for iwoman in range(Y):\n            rhs[ivar1, ivar2:n_cols_rhs:Y] = (\n                -muxy[:, iwoman] * der_ephi2[:, iwoman]\n            )\n            ivar1 += 1\n            ivar2 += 1\n        # solve for the derivatives of txi and tyi\n        dt_dT = spla.solve(lhs, rhs)\n        dt = dt_dT[:X, :]\n        dT = dt_dT[X:, :]\n        # now construct the derivatives of the mus\n        dmux0 = 2.0 * (dt * txi.reshape((-1, 1)))\n        dmu0y = 2.0 * (dT * tyi.reshape((-1, 1)))\n        dmuxy = np.zeros((n_prod_categories, n_cols_rhs))\n        ivar = 0\n        for iman in range(X):\n            dt_man = dt[iman, :]\n            dmuxy[ivar : (ivar + Y), :] = np.outer(\n                (ephi2[iman, :] * tyi), dt_man\n            )\n            ivar += Y\n        for iwoman in range(Y):\n            dT_woman = dT[iwoman, :]\n            dmuxy[iwoman:n_prod_categories:Y, :] += np.outer(\n                (ephi2[:, iwoman] * txi), dT_woman\n            )\n        # add the term that comes from differentiating ephi2\n        muxy_vec2 = (muxy * der_ephi2).reshape(n_prod_categories)\n        dmuxy[:, n_sum_categories:] += np.diag(muxy_vec2)\n        return (\n            Matching(muxy, men_margins, women_margins),\n            marg_err_x,\n            marg_err_y,\n            dmuxy,\n            dmux0,\n            dmu0y,\n        )\n</code></pre>"},{"location":"matching_utils/","title":"<code>matching_utils</code> module","text":"<p>matching-related utilities</p>"},{"location":"matching_utils/#cupid_matching.matching_utils.MatchingFunctionParam","title":"<code>MatchingFunctionParam = Callable[[Matching, list[Any]], np.ndarray]</code>  <code>module-attribute</code>","text":"<p>Same with a list of additional parameters</p>"},{"location":"matching_utils/#cupid_matching.matching_utils.Matching","title":"<code>Matching</code>  <code>dataclass</code>","text":"<p>stores the numbers of couples and singles of every type;</p> <p>muxy is an (X,Y)-matrix n is an X-vector m is an Y-vector mux0 and mu0y are generated as the corresponding numbers of singles</p> Source code in <code>cupid_matching/matching_utils.py</code> <pre><code>@dataclass\nclass Matching:\n\"\"\"stores the numbers of couples and singles of every type;\n\n    muxy is an (X,Y)-matrix\n    n is an X-vector\n    m is an Y-vector\n    mux0 and mu0y are generated as the corresponding numbers of singles\n    \"\"\"\n\n    mux0: np.ndarray = field(init=False)\n    mu0y: np.ndarray = field(init=False)\n    muxy: np.ndarray\n    n: np.ndarray\n    m: np.ndarray\n\n    def __str__(self):\n        X, Y = self.muxy.shape\n        n_couples = np.sum(self.muxy)\n        n_men, n_women = np.sum(self.n), np.sum(self.m)\n        repr_str = (\n            f\"This is a matching with {n_men}  men, {n_women} single women.\\n\"\n        )\n        repr_str += f\"   with {n_couples} couples,\\n \\n\"\n        repr_str += f\" We have {X} types of men and {Y} of women.\"\n        print_stars(repr_str)\n\n    def __post_init__(self):\n        X, Y = test_matrix(self.muxy)\n        Xn = test_vector(self.n)\n        Ym = test_vector(self.m)\n        if Xn != X:\n            bs_error_abort(\n                f\"muxy is a ({X}, {Y}) matrix but n has {Xn} elements.\"\n            )\n        if Ym != Y:\n            bs_error_abort(\n                f\"muxy is a ({X}, {Y}) matrix but m has {Ym} elements.\"\n            )\n        self.mux0, self.mu0y = _get_singles(self.muxy, self.n, self.m)\n\n    def unpack(self):\n        muxy, mux0, mu0y = self.muxy, self.mux0, self.mu0y\n        min_xy, min_x0, min_0y = np.min(muxy), np.min(mux0), np.min(mu0y)\n        if min_xy &lt; 0.0:\n            breakpoint()\n            bs_error_abort(f\"The smallest muxy is {min_xy}\")\n        if min_x0 &lt; 0.0:\n            breakpoint()\n            bs_error_abort(f\"The smallest mux0 is {min_x0}\")\n        if min_0y &lt; 0.0:\n            breakpoint()\n            bs_error_abort(f\"The smallest mux0 is {min_0y}\")\n        return muxy, mux0, mu0y, self.n, self.m\n</code></pre>"},{"location":"min_distance/","title":"<code>min_distance</code> module","text":"<p>Estimates semilinear separable models with a given entropy function. The entropy function and the surplus matrix must both be linear in the parameters.</p>"},{"location":"min_distance/#cupid_matching.min_distance.estimate_semilinear_mde","title":"<code>estimate_semilinear_mde(muhat, phi_bases, entropy, additional_parameters=None, initial_weights=None)</code>","text":"<p>Estimates the parameters of the distributions and of the base functions.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>the observed Matching</p> required <code>phi_bases</code> <code>np.ndarray</code> <p>an (X, Y, K) array of bases</p> required <code>entropy</code> <code>EntropyFunctions</code> <p>an <code>EntropyFunctions</code> object</p> required <code>additional_parameters</code> <code>Optional[list]</code> <p>additional parameters of the distribution of errors, if any</p> <code>None</code> <code>initial_weights</code> <code>Optional[np.ndarray]</code> <p>if specified, used as the weighting matrix for the first step when <code>entropy.param_dependent</code> is <code>True</code></p> <code>None</code> <p>Returns:</p> Type Description <code>MDEResults</code> <p>an <code>MDEResults</code> instance</p> Example <pre><code># We simulate a Choo and Siow homoskedastic marriage market\n#  and we estimate a gender-heteroskedastic model on the simulated data.\nX, Y, K = 10, 20, 2\nn_households = int(1e6)\nlambda_true = np.random.randn(K)\nphi_bases = np.random.randn(X, Y, K)\nn = np.ones(X)\nm = np.ones(Y)\nPhi = phi_bases @ lambda_true\nchoo_siow_instance = ChooSiowPrimitives(Phi, n, m)\nmus_sim = choo_siow_instance.simulate(n_households)\nchoo_siow_instance.describe()\n\nentropy_model =  entropy_choo_siow_gender_heteroskedastic_numeric\nn_alpha = 1\ntrue_alpha = np.ones(n_alpha)\ntrue_coeffs = np.concatenate((true_alpha, lambda_true))\n\nprint_stars(entropy_model.description)\n\nmde_results = estimate_semilinear_mde(\n    mus_sim, phi_bases, entropy_model)\n\nmde_results.print_results(true_coeffs=true_coeffs, n_alpha=1)\n</code></pre> Source code in <code>cupid_matching/min_distance.py</code> <pre><code>def estimate_semilinear_mde(\n    muhat: Matching,\n    phi_bases: np.ndarray,\n    entropy: EntropyFunctions,\n    additional_parameters: Optional[list] = None,\n    initial_weights: Optional[np.ndarray] = None,\n) -&gt; MDEResults:\n\"\"\"\n    Estimates the parameters of the distributions and of the base functions.\n\n    Args:\n        muhat: the observed Matching\n        phi_bases: an (X, Y, K) array of bases\n        entropy: an `EntropyFunctions` object\n        additional_parameters: additional parameters of the distribution of errors,\n            if any\n        initial_weights: if specified, used as the weighting matrix\n            for the first step when `entropy.param_dependent` is `True`\n\n    Returns:\n        an `MDEResults` instance\n\n    Example:\n        ```py\n        # We simulate a Choo and Siow homoskedastic marriage market\n        #  and we estimate a gender-heteroskedastic model on the simulated data.\n        X, Y, K = 10, 20, 2\n        n_households = int(1e6)\n        lambda_true = np.random.randn(K)\n        phi_bases = np.random.randn(X, Y, K)\n        n = np.ones(X)\n        m = np.ones(Y)\n        Phi = phi_bases @ lambda_true\n        choo_siow_instance = ChooSiowPrimitives(Phi, n, m)\n        mus_sim = choo_siow_instance.simulate(n_households)\n        choo_siow_instance.describe()\n\n        entropy_model =  entropy_choo_siow_gender_heteroskedastic_numeric\n        n_alpha = 1\n        true_alpha = np.ones(n_alpha)\n        true_coeffs = np.concatenate((true_alpha, lambda_true))\n\n        print_stars(entropy_model.description)\n\n        mde_results = estimate_semilinear_mde(\n            mus_sim, phi_bases, entropy_model)\n\n        mde_results.print_results(true_coeffs=true_coeffs, n_alpha=1)\n        ```\n\n    \"\"\"\n    muxyhat, _, _, nhat, mhat = muhat.unpack()\n    X, Y = muxyhat.shape\n    XY = X * Y\n    ndims_phi = phi_bases.ndim\n    if ndims_phi != 3:\n        bs_error_abort(f\"phi_bases should have 3 dimensions, not {ndims_phi}\")\n    Xp, Yp, K = phi_bases.shape\n    if Xp != X or Yp != Y:\n        bs_error_abort(\n            f\"phi_bases should have shape ({X}, {Y}, {K}) not ({Xp}, {Yp}, {K})\"\n        )\n    parameterized_entropy = entropy.parameter_dependent\n    if parameterized_entropy:\n        if initial_weights is None:\n            print_stars(\n                \"Using the identity matrix as weighting matrix in the first step.\"\n            )\n            S_mat = np.eye(XY)\n        else:\n            S_mat = initial_weights\n\n    phi_mat = _make_XY_K_mat(phi_bases)\n    e0_fun = entropy.e0_fun\n    if additional_parameters is None:\n        e0_fun = cast(MatchingFunction, e0_fun)\n        e0_vals = e0_fun(muhat)\n    else:\n        e0_fun = cast(MatchingFunctionParam, e0_fun)\n        e0_vals = e0_fun(muhat, additional_parameters)\n    e0_hat = e0_vals.ravel()\n\n    if not parameterized_entropy:  # we only have e0(mu,r)\n        n_pars = K\n        hessian = entropy.hessian\n        if hessian == \"provided\":\n            e0_derivative = cast(EntropyHessians, entropy.e0_derivative)\n            if additional_parameters is None:\n                hessian_components_mumu = e0_derivative[0](muhat)\n                hessian_components_mur = e0_derivative[1](muhat)\n            else:\n                e0_derivative1 = cast(\n                    EntropyHessiansParam, entropy.e0_derivative\n                )\n                hessian_components_mumu = e0_derivative1[0](\n                    muhat, additional_parameters\n                )\n                hessian_components_mur = e0_derivative1[1](\n                    muhat, additional_parameters\n                )\n        else:\n            if additional_parameters is None:\n                hessian_components = _numeric_hessian(entropy, muhat)\n            else:\n                hessian_components = _numeric_hessian(\n                    entropy,\n                    muhat,\n                    additional_parameters=additional_parameters,\n                )\n            (\n                hessian_components_mumu,\n                hessian_components_mur,\n            ) = hessian_components\n        hessian_mumu = _fill_hessianMuMu_from_components(\n            hessian_components_mumu\n        )\n        hessian_mur = _fill_hessianMuR_from_components(hessian_components_mur)\n        hessians_both = np.concatenate((hessian_mumu, hessian_mur), axis=1)\n\n        _, var_munm = _variance_muhat(muhat)\n        var_entropy_gradient = hessians_both @ var_munm @ hessians_both.T\n        S_mat = spla.inv(var_entropy_gradient)\n        estimated_coefficients, varcov_coefficients = _compute_estimates(\n            phi_mat, S_mat, e0_hat\n        )\n        stderrs_coefficients = np.sqrt(np.diag(varcov_coefficients))\n        est_Phi = phi_mat @ estimated_coefficients\n        residuals = est_Phi + e0_hat\n    else:  # parameterized entropy: e0(mu,r) + e(mu,r) . alpha\n        # create the F matrix\n        if additional_parameters is None:\n            e_fun = cast(MatchingFunction, entropy.e_fun)\n            e_vals = e_fun(muhat)\n        else:\n            e_fun1 = cast(MatchingFunctionParam, entropy.e_fun)\n            e_vals = e_fun1(muhat, additional_parameters)\n        e_hat = _make_XY_K_mat(e_vals)\n\n        F_hat = np.column_stack((e_hat, phi_mat))\n        n_pars = e_hat.shape[1] + K\n        # first pass with an initial weighting matrix\n        first_coeffs, _ = _compute_estimates(F_hat, S_mat, e0_hat)\n        first_alpha = first_coeffs[:-K]\n\n        # compute the efficient weighting matrix\n        hessian = entropy.hessian\n        if hessian == \"provided\":\n            if additional_parameters is None:\n                e0_derivative = cast(EntropyHessians, entropy.e0_derivative)\n                e_derivative = cast(EntropyHessians, entropy.e_derivative)\n                e0_derivative_mumu = cast(EntropyHessianMuMu, e0_derivative[0])\n                hessian_components_mumu_e0 = e0_derivative_mumu(muhat)\n                e0_derivative_mur = cast(EntropyHessianMuR, e0_derivative[1])\n                hessian_components_mur_e0 = e0_derivative_mur(muhat)\n                e_derivative_mumu = cast(EntropyHessianMuMu, e_derivative[0])\n                hessian_components_mumu_e = e_derivative_mumu(muhat)\n                e_derivative_mur = cast(EntropyHessianMuR, e_derivative[1])\n                hessian_components_mur_e = e_derivative_mur(muhat)\n            else:\n                e0_derivative1 = cast(\n                    EntropyHessiansParam, entropy.e0_derivative\n                )\n                e_derivative1 = cast(EntropyHessiansParam, entropy.e_derivative)\n                e0_derivative_mumu1 = cast(\n                    EntropyHessianMuMuParam, e0_derivative1[0]\n                )\n                e0_derivative_mur1 = cast(\n                    EntropyHessianMuRParam, e0_derivative1[1]\n                )\n                e_derivative_mumu1 = cast(\n                    EntropyHessianMuMuParam, e_derivative1[0]\n                )\n                e_derivative_mur1 = cast(\n                    EntropyHessianMuRParam, e_derivative1[1]\n                )\n                hessian_components_mumu_e0 = e0_derivative_mumu1(\n                    muhat, additional_parameters\n                )\n                hessian_components_mur_e0 = e0_derivative_mur1(\n                    muhat, additional_parameters\n                )\n                hessian_components_mumu_e = e_derivative_mumu1(\n                    muhat, additional_parameters\n                )\n                hessian_components_mur_e = e_derivative_mur1(\n                    muhat, additional_parameters\n                )\n\n            # print_stars(\"First-stage estimates:\")\n            # print(first_coeffs)\n\n            hessian_components_mumu1 = (\n                hessian_components_mumu_e0[0]\n                + hessian_components_mumu_e[0] @ first_alpha,\n                hessian_components_mumu_e0[1]\n                + hessian_components_mumu_e[1] @ first_alpha,\n                hessian_components_mumu_e0[2]\n                + hessian_components_mumu_e[2] @ first_alpha,\n            )\n            hessian_components_mur1 = (\n                hessian_components_mur_e0[0]\n                + hessian_components_mur_e[0] @ first_alpha,\n                hessian_components_mur_e0[1]\n                + hessian_components_mur_e[1] @ first_alpha,\n            )\n            hessian_mumu = _fill_hessianMuMu_from_components(\n                hessian_components_mumu1\n            )\n            hessian_mur = _fill_hessianMuR_from_components(\n                hessian_components_mur1\n            )\n        else:  # numeric hessian\n            if additional_parameters is None:\n                hessian_components = _numeric_hessian(\n                    entropy, muhat, alpha=first_alpha\n                )\n            else:\n                hessian_components = _numeric_hessian(\n                    entropy,\n                    muhat,\n                    alpha=first_alpha,\n                    additional_parameters=additional_parameters,\n                )\n            (\n                hessian_components_mumu,\n                hessian_components_mur,\n            ) = hessian_components\n            hessian_mumu = _fill_hessianMuMu_from_components(\n                hessian_components_mumu\n            )\n            hessian_mur = _fill_hessianMuR_from_components(\n                hessian_components_mur\n            )\n\n        hessians_both = np.concatenate((hessian_mumu, hessian_mur), axis=1)\n\n        _, var_munm = _variance_muhat(muhat)\n        var_entropy_gradient = hessians_both @ var_munm @ hessians_both.T\n        S_mat = spla.inv(var_entropy_gradient)\n\n        # second pass\n        estimated_coefficients, varcov_coefficients = _compute_estimates(\n            F_hat, S_mat, e0_hat\n        )\n        est_alpha, est_beta = (\n            estimated_coefficients[:-K],\n            estimated_coefficients[-K:],\n        )\n        stderrs_coefficients = np.sqrt(np.diag(varcov_coefficients))\n        est_Phi = phi_mat @ est_beta\n        residuals = est_Phi + e0_hat + e_hat @ est_alpha\n\n    value_obj = residuals.T @ S_mat @ residuals\n    ndf = X * Y - n_pars\n    test_stat = value_obj\n    n_individuals = np.sum(nhat) + np.sum(mhat)\n    n_households = n_individuals - np.sum(muxyhat)\n\n    results = MDEResults(\n        X=X,\n        Y=Y,\n        K=K,\n        number_households=n_households,\n        estimated_coefficients=estimated_coefficients,\n        varcov_coefficients=varcov_coefficients,\n        stderrs_coefficients=stderrs_coefficients,\n        estimated_Phi=est_Phi.reshape((X, Y)),\n        test_statistic=test_stat,\n        ndf=ndf,\n        test_pvalue=sts.chi2.sf(test_stat, ndf),\n        parameterized_entropy=parameterized_entropy,\n    )\n    return results\n</code></pre>"},{"location":"min_distance_utils/","title":"<code>min_distance_utils</code> module","text":"<p>Utility programs used in <code>min_distance.py</code>.</p>"},{"location":"min_distance_utils/#cupid_matching.min_distance_utils.MDEResults","title":"<code>MDEResults</code>  <code>dataclass</code>","text":"<p>The results from minimum-distance estimation and testing.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>int</code> <p>int</p> required <code>Y</code> <code>int</code> <p>int</p> required <code>K</code> <code>int</code> <p>int</p> required <code>number_households</code> <code>int</code> <p>int</p> required <code>estimated_coefficients</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>varcov_coefficients</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>stderrs_coefficients</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>estimated_Phi</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>test_statistic</code> <code>float</code> <p>float</p> required <code>test_pvalue</code> <code>float</code> <p>float</p> required <code>ndf</code> <code>int</code> <p>int</p> required <code>parameterized_entropy</code> <code>Optional[bool]</code> <p>Optional[bool] = False</p> <code>False</code> Source code in <code>cupid_matching/min_distance_utils.py</code> <pre><code>@dataclass\nclass MDEResults:\n\"\"\"\n    The results from minimum-distance estimation and testing.\n\n    Args:\n        X: int\n        Y: int\n        K: int\n        number_households: int\n        estimated_coefficients: np.ndarray\n        varcov_coefficients: np.ndarray\n        stderrs_coefficients: np.ndarray\n        estimated_Phi: np.ndarray\n        test_statistic: float\n        test_pvalue: float\n        ndf: int\n        parameterized_entropy: Optional[bool] = False\n    \"\"\"\n\n    X: int\n    Y: int\n    K: int\n    number_households: int\n    estimated_coefficients: np.ndarray\n    varcov_coefficients: np.ndarray\n    stderrs_coefficients: np.ndarray\n    estimated_Phi: np.ndarray\n    test_statistic: float\n    test_pvalue: float\n    ndf: int\n    parameterized_entropy: Optional[bool] = False\n\n    def __str__(self):\n        line_stars = \"*\" * 80 + \"\\n\"\n        if self.parameterized_entropy:\n            n_alpha = self.estimated_coefficients.size - self.K\n            entropy_str = f\"     The entropy has {n_alpha} parameters.\"\n        else:\n            entropy_str = \"     The entropy is parameter-free.\"\n            n_alpha = 0\n        model_str = f\"The data has {self.number_households} households\\n\\n\"\n        model_str += (\n            f\"The model has {self.X}x{self.Y} margins\\n {entropy_str} \\n\"\n        )\n        model_str += f\"We use {self.K} basis functions.\\n\\n\"\n        repr_str = line_stars + model_str\n        repr_str += (\n            \"The estimated coefficients (and their standard errors) are\\n\\n\"\n        )\n        if self.parameterized_entropy:\n            for i, coeff in enumerate(self.estimated_coefficients[:n_alpha]):\n                repr_str += (\n                    f\"   alpha({i + 1}): {coeff: &gt; 10.3f}  \"\n                    + f\"({self.stderrs_coefficients[i]: .3f})\\n\"\n                )\n            repr_str += \"\\n\"\n        for i, coeff in enumerate(self.estimated_coefficients[n_alpha:]):\n            repr_str += (\n                f\"   base {i + 1}: {coeff: &gt; 10.3f} \"\n                + f\"({self.stderrs_coefficients[n_alpha + i]: .3f})\\n\"\n            )\n        repr_str += \"\\nSpecification test:\\n\"\n        repr_str += f\"   the value of the test statistic is {self.test_statistic: &gt; 10.3f}\\n\"\n        repr_str += f\"     for a chi2({self.ndf}), the p-value is {self.test_pvalue: &gt; 10.3f}\\n\"\n        return repr_str + line_stars\n\n    def print_results(\n        self, true_coeffs: Optional[np.ndarray] = None, n_alpha: int = 0\n    ) -&gt; None | float:\n        estimates = self.estimated_coefficients\n        stderrs = self.stderrs_coefficients\n\n        if true_coeffs is not None:\n            repr_str = (\n                \"The true and estimated coefficients \"\n                + \"(and their standard errors) are\\n\\n\"\n            )\n            for i, coeff in enumerate(estimates[:n_alpha]):\n                repr_str += f\"   alpha({i + 1}): {true_coeffs[i]: &gt; 10.3f}\"\n                repr_str += f\"{coeff: &gt; 10.3f}  ({stderrs[i]: &gt; 10.3f})\\n\"\n                repr_str += \"\\n\"\n            for i, coeff in enumerate(estimates[n_alpha:]):\n                j = n_alpha + i\n                repr_str += (\n                    f\"   base {i + 1}: {true_coeffs[j]: &gt; 10.3f}  \"\n                    + f\"{coeff: &gt; 10.3f}  ({stderrs[j]: &gt; 10.3f})\\n\"\n                )\n            print_stars(repr_str)\n            discrepancy = npmaxabs(true_coeffs - estimates)\n            print_stars(f\"The largest difference between true and estimated coefficients is {discrepancy: .2e}\")\n        else:\n            repr_str = (\n                \"The estimated coefficients \"\n                + \"(and their standard errors) are\\n\\n\"\n            )\n            for i, coeff in enumerate(estimates[:n_alpha]):\n                repr_str + f\"{coeff: &gt; 10.3f}  ({stderrs[i]: &gt; 10.3f})\\n\"\n                repr_str += \"\\n\"\n            for i, coeff in enumerate(estimates[n_alpha:]):\n                j = n_alpha + i\n                repr_str += f\"{coeff: &gt; 10.3f}  ({stderrs[j]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n\n        repr_str = \"\\nSpecification test:\\n\"\n        repr_str += (\n            \"   the value of the test statistic is \"\n            + f\"{self.test_statistic: &gt; 10.3f}\\n\"\n        )\n        repr_str += (\n            f\"     for a chi2({self.ndf}), \"\n            + f\"the p-value is {self.test_pvalue: &gt; 10.3f}\\n\"\n        )\n        print_stars(repr_str)\n        if true_coeffs is not None:\n            return discrepancy\n        return None\n</code></pre>"},{"location":"model_classes/","title":"<code>model_classes</code> module","text":""},{"location":"model_classes/#cupid_matching.model_classes.NestedLogitPrimitives","title":"<code>NestedLogitPrimitives</code>  <code>dataclass</code>","text":"Source code in <code>cupid_matching/model_classes.py</code> <pre><code>@dataclass\nclass NestedLogitPrimitives:\n    Phi: np.ndarray\n    n: np.ndarray\n    m: np.ndarray\n    nests_for_each_x: NestsList  # given by user, e.g. [[1, 3], [2,4]] has y=1 and y=3 in first nest\n    nests_for_each_y: NestsList\n    nests_over_Y: NestsList  # rebased to zero: the above example becomes [[0, 2], [1,3]]\n    nests_over_X: NestsList\n    i_nest_of_x: Nest  # mapping x -&gt; n'\n    i_nest_of_y: Nest  # mapping y -&gt; n\n    n_alphas: int\n    mus: Optional[Matching] = None\n    true_alphas: Optional[np.ndarray] = None\n\n    def __init__(\n        self,\n        Phi: np.ndarray,\n        n: np.ndarray,\n        m: np.ndarray,\n        nests_for_each_x: NestsList,\n        nests_for_each_y: NestsList,\n        true_alphas: Optional[np.ndarray] = None,\n    ):\n\"\"\"\n        We only model two-level nested logit, with {0} as the first nest,\n        and nests and nests parameters that do not depend on the type.\n\n        Args:\n            Phi: the (X,Y) joint surplus matrix\n            n: the X-vector of men margins\n            m: the X-vector of women margins\n            nests_for_each_x: the composition of the nests over 1...Y, a list of r lists\n            nests_for_each_y: the composition of the nests over 1...X, a list of d lists\n            true_alphas: the true nest parameters, if any; should be an (r+d)-vector\n        \"\"\"\n        X, Y = test_matrix(Phi)\n        Xn = test_vector(n)\n        Ym = test_vector(m)\n\n        # we need to rebase the indices to zero\n        self.nests_over_X = _change_indices(nests_for_each_y)\n        self.nests_over_Y = _change_indices(nests_for_each_x)\n\n        self.n_alphas = len(nests_for_each_y) + len(nests_for_each_x)\n\n        if Xn != X:\n            bs_error_abort(\n                f\"Phi is a ({X}, {Y}) matrix but n has {Xn} elements.\"\n            )\n        if Ym != Y:\n            bs_error_abort(\n                f\"Phi is a ({X}, {Y}) matrix but m has {Ym} elements.\"\n            )\n\n        if true_alphas is not None:\n            alpha_size = test_vector(true_alphas)\n            if alpha_size != self.n_alphas:\n                bs_error_abort(\n                    f\"true_alphas shoud have {self.n_alphas} elements, not {alpha_size}\"\n                )\n\n        self.Phi = Phi\n        self.n = n\n        self.m = m\n        self.true_alphas = true_alphas\n        self.nests_for_each_x = nests_for_each_x\n        self.nests_for_each_y = nests_for_each_y\n\n        # check that every x is in a nest, and just once\n        nests_check = []\n        i_nest_of_x = np.zeros(X, int)\n        for x in range(X):\n            i_nest_of_x[x] = _find_nest_of(self.nests_over_X, x)\n            nests_check.append(i_nest_of_x[x])\n        if -1 in nests_check or len(set(nests_check)) != len(nests_for_each_y):\n            bs_error_abort(\"Check your nests_for_each_y\")\n        # check that every y is in a nest, and just once\n        nests_check = []\n        i_nest_of_y = np.zeros(Y, int)\n        for y in range(Y):\n            i_nest_of_y[y] = _find_nest_of(self.nests_over_Y, y)\n            nests_check.append(i_nest_of_y[y])\n        if -1 in nests_check or len(set(nests_check)) != len(nests_for_each_x):\n            bs_error_abort(\"Check your nests_for_each_x\")\n\n        self.i_nest_of_x = i_nest_of_x.tolist()\n        self.i_nest_of_y = i_nest_of_y.tolist()\n\n    def __str__(self):\n        X, Y = self.Phi.shape\n        nmen, nwomen = np.sum(self.n), np.sum(self.m)\n        repr_str = (\n            f\"This is a 2-level nested logit with {nmen} men of {X} types\"\n            + f\" and {nwomen} women of {Y} types.\\n\"\n        )\n        repr_str += (\n            f\" We have {self.n_nests_over_Y} nests over 1...Y \"\n            + f\" and {self.n_nests_over_X} nests over 1...X,\\n\"\n        )\n        if self.true_alphas is None:\n            repr_str += \"     with unspecified nests parameters.\"\n        else:\n            alpha_vals = self.true_alphas\n            repr_str += \"     with respective nests parameters:\\n\"\n            repr_str += f\"    {alpha_vals[:self.n_nests_over_Y]}\\n\"\n            repr_str += f\" and {alpha_vals[self.n_nests_over_Y:]}\\n\"\n        print_stars(repr_str)\n\n    def ipfp_nested_logit_solver(\n        self, tol: float = 1e-9, verbose: bool = False, maxiter: int = 1000\n    ) -&gt; tuple[Matching, np.ndarray, np.ndarray]:\n\"\"\"Solves for equilibrium in a two-level nested logit market\n        given systematic surplus and margins and nests parameters;\n        does not compute the gradient of the matching patterns\n\n        Args:\n            tol: tolerance on change in solution\n            verbose: if `True`, prints information\n            maxiter: maximum number of iterations\n\n        Returns:\n             the matching patterns\n             marg_err_x, marg_err_y: the errors on the margins\n        \"\"\"\n        alphas = self.true_alphas\n        if alphas is None:\n            bs_error_abort(\"cannot solve without nest parameters\")\n        else:\n            alphas = cast(np.ndarray, alphas)\n            n_rhos = len(self.nests_over_Y)\n            n_deltas = len(self.nests_over_X)\n            rhos = alphas[:n_rhos]\n            deltas = alphas[n_rhos:]\n\n        #############################################################################\n        # we solve the equilibrium equations\n        #   starting with a reasonable initial point  muxy, mux0, mu0y = bigc\n        #   it is important that it fit the number of individuals\n        #############################################################################\n\n        n, m = self.n, self.m\n        X, Y = n.size, m.size\n\n        nests_over_X, nests_over_Y = self.nests_over_X, self.nests_over_Y\n        i_nest_of_x, i_nest_of_y = self.i_nest_of_x, self.i_nest_of_y\n\n        rho_vals = rhos[i_nest_of_y]  # rho(n) for y in n in the paper\n        delta_vals = deltas[i_nest_of_x]  # delta(n') for x in n' in the paper\n\n        ephi = npexp(self.Phi / np.add.outer(delta_vals, rho_vals))\n\n        # initial values\n        nindivs = np.sum(n) + np.sum(m)\n        bigc = nindivs / (X + Y + 2.0 * np.sum(ephi))\n\n        mux0, mu0y, muxy = (\n            np.full(X, bigc),\n            np.full(Y, bigc),\n            np.full((X, Y), bigc),\n        )\n        muxn = np.zeros((X, n_rhos))\n        for i_nest_y, nest_y in enumerate(nests_over_Y):\n            muxn[:, i_nest_y] = np.sum(muxy[:, nest_y], 1)\n        muny = np.zeros((n_deltas, Y))\n        for i_nest_x, nest_x in enumerate(nests_over_X):\n            muny[i_nest_x, :] = np.sum(muxy[nest_x, :], 0)\n\n        err_diff = bigc\n        tol_diff = tol * bigc\n        tol_newton = tol\n        max_newton = 2000\n        MIN_REST = (\n            1e-4 * bigc\n        )  # used to bound mus below in the Newton iterations\n\n        niter = 0\n        while (err_diff &gt; tol_diff) and (niter &lt; maxiter):  # IPFP main loop\n            # Newton iterates for men\n            err_newton = bigc\n            i_newton = 0\n            while err_newton &gt; tol_newton:\n                gbar = np.zeros(\n                    (X, n_rhos)\n                )  # this will be the $\\bar{G}^x_n$ of the note\n                gbar_pow = np.zeros((X, n_rhos))\n                biga = np.zeros(X)  # this will be the $A_x$ of the note\n                for i_nest_x, nest_x in enumerate(nests_over_X):\n                    # i_nest_x is n' in the paper\n                    delta_x = deltas[i_nest_x]\n                    muny_x = muny[i_nest_x, :]  # mu(n', :)\n                    for x in nest_x:\n                        ephi_x = ephi[x, :]\n                        for i_nest_y, nest_y in enumerate(nests_over_Y):\n                            # i_nest_y is n in the paper\n                            mu_n = muny_x[nest_y]\n                            mu0_n = mu0y[nest_y]\n                            evec_n = ephi_x[nest_y]\n                            rho_n = rhos[i_nest_y]\n                            sum_rd = rho_n + delta_x\n                            mun_term = nppow(mu_n, (delta_x - 1.0) / sum_rd)\n                            mu0_term = nppow(mu0_n, 1.0 / sum_rd)\n                            gbar[x, i_nest_y] = np.sum(\n                                mun_term * mu0_term * evec_n\n                            )\n                            gbar_pow[x, i_nest_y] = nppow(\n                                gbar[x, i_nest_y], sum_rd / (delta_x + 1.0)\n                            )\n                            biga[x] += gbar_pow[x, i_nest_y]\n\n                # now we take one Newton step for all types of men\n                delta_vals1 = 1.0 + delta_vals\n                mux0_term = nppow(mux0, 1.0 / delta_vals1)\n                bigb = mux0_term * biga  # this is the $B_x$ of the note\n                numer = n * delta_vals1 - delta_vals * bigb\n                lower_bound = np.full(X, MIN_REST)\n                mux0_new = mux0 * np.maximum(\n                    numer / (delta_vals1 * mux0 + bigb), lower_bound\n                )\n                muxn_new = gbar_pow * mux0_term.reshape((-1, 1))\n\n                mux0 = mux0_new\n                muxn = muxn_new\n                errxi = mux0 + np.sum(muxn, 1) - n\n                err_newton = npmaxabs(errxi)\n                i_newton += 1\n                if i_newton &gt; max_newton:\n                    bs_error_abort(\n                        f\"Newton solver failed for men after {max_newton} iterations\"\n                    )\n\n            if verbose:\n                print(\n                    f\"Newton error on men is {err_newton} after {i_newton} iterations\"\n                )\n\n            # Newton iterates for women\n            err_newton = bigc\n            i_newton = 0\n            while err_newton &gt; tol_newton:\n                gbar = np.zeros((Y, n_deltas))\n                gbar_pow = np.zeros((Y, n_deltas))\n                biga = np.zeros(Y)\n                for i_nest_y, nest_y in enumerate(nests_over_Y):\n                    # i_nest_y is n in the paper\n                    rho_y = rhos[i_nest_y]\n                    muxn_y = muxn[:, i_nest_y]  # mu(:, n)\n                    for y in nest_y:\n                        ephi_y = ephi[:, y]\n                        for i_nest_x, nest_x in enumerate(nests_over_X):\n                            mu_n = muxn_y[nest_x]\n                            mu0_n = mux0[nest_x]\n                            evec_n = ephi_y[nest_x]\n                            delta_n = deltas[i_nest_x]\n                            sum_rd = rho_y + delta_n\n                            mun_term = nppow(mu_n, (rho_n - 1.0) / sum_rd)\n                            mu0_term = nppow(mu0_n, 1.0 / sum_rd)\n                            gbar[y, i_nest_x] = np.sum(\n                                mun_term * mu0_term * evec_n\n                            )\n                            gbar_pow[y, i_nest_x] = nppow(\n                                gbar[y, i_nest_x], sum_rd / (1.0 + rho_y)\n                            )\n                            biga[y] += gbar_pow[y, i_nest_x]\n\n                # now we take one Newton step for all types of women\n                rho_vals1 = 1.0 + rho_vals\n                mu0y_term = nppow(mu0y, 1.0 / rho_vals1)\n                bigb = mu0y_term * biga\n                numer = m * rho_vals1 - rho_vals * bigb\n                lower_bound = np.full(Y, MIN_REST)\n                mu0y_new = mu0y * np.maximum(\n                    numer / (rho_vals1 * mu0y + bigb), lower_bound\n                )\n                muny_new = gbar_pow.T * mu0y_term\n\n                mu0y = mu0y_new\n                muny = muny_new\n                erryi = mu0y + np.sum(muny, 0) - m\n                err_newton = npmaxabs(erryi)\n                i_newton += 1\n                if i_newton &gt; max_newton:\n                    bs_error_abort(\n                        f\"Newton solver failed for women after {max_newton} iterations\"\n                    )\n\n            if verbose:\n                print(\n                    f\"Newton error on women is {err_newton} after {i_newton} iterations\"\n                )\n\n            muxy = np.zeros((X, Y))\n            for x in range(X):\n                i_nest_x = i_nest_of_x[x]  # n'\n                ephi_x = ephi[x, :]\n                mux0_x = mux0[x]\n                muxn_x = muxn[x, :]\n                delta_x = delta_vals[x]\n                muny_x = muny[i_nest_x, :]\n                for y in range(Y):\n                    i_nest_y = i_nest_of_y[y]  # n\n                    mu0y_y = mu0y[y]\n                    rho_y = rho_vals[y]\n                    muxn_xy = muxn_x[i_nest_y]\n                    muny_xy = muny_x[y]\n                    mu_term = (\n                        mux0_x\n                        * mu0y_y\n                        * (muxn_xy ** (rho_y - 1.0))\n                        * (muny_xy ** (delta_x - 1.0))\n                    )\n                    muxy[x, y] = ephi_x[y] * (\n                        mu_term ** (1.0 / (delta_x + rho_y))\n                    )\n\n            n_sim, m_sim = _compute_margins(muxy, mux0, mu0y)\n            marg_err_x, marg_err_y = n_sim - n, m_sim - m\n\n            if verbose:\n                print(\n                    f\"Margin error on men is {marg_err_x} \"\n                    f\" after {niter} IPFP iterations\"\n                )\n                print(\n                    f\"Margin error on women is {marg_err_y} \"\n                    f\" after {niter} IPFP iterations\"\n                )\n            err_diff = npmaxabs(marg_err_x) + npmaxabs(marg_err_y)\n            niter += 1\n\n        n_sim, m_sim = _compute_margins(muxy, mux0, mu0y)\n        marg_err_x = n_sim - n\n        marg_err_y = m_sim - m\n\n        if verbose:\n            print(\n                f\"Margin error on men is {npmaxabs(marg_err_x)} after {niter} IPFP iterations\"\n            )\n            print(\n                f\"Margin error on women is {npmaxabs(marg_err_y)} after {niter} IPFP iterations\"\n            )\n\n        return Matching(muxy, n, m), marg_err_x, marg_err_y\n\n    def ipfp_solve(self) -&gt; Matching:\n        if self.true_alphas is None:\n            bs_error_abort(\n                \"true_alphas must be specified to solve the nested logit by IPFP.\"\n            )\n        self.mus, err_x, err_y = self.ipfp_nested_logit_solver(verbose=False)\n        return self.mus\n\n    def simulate(\n        self, n_households: int, seed: Optional[int] = None\n    ) -&gt; Matching:\n        self.mus = self.ipfp_solve()\n        mus_sim = _simulate_sample_from_mus(self.mus, n_households, seed)\n        return mus_sim\n</code></pre>"},{"location":"model_classes/#cupid_matching.model_classes.NestedLogitPrimitives.__init__","title":"<code>__init__(Phi, n, m, nests_for_each_x, nests_for_each_y, true_alphas=None)</code>","text":"<p>We only model two-level nested logit, with {0} as the first nest, and nests and nests parameters that do not depend on the type.</p> <p>Parameters:</p> Name Type Description Default <code>Phi</code> <code>np.ndarray</code> <p>the (X,Y) joint surplus matrix</p> required <code>n</code> <code>np.ndarray</code> <p>the X-vector of men margins</p> required <code>m</code> <code>np.ndarray</code> <p>the X-vector of women margins</p> required <code>nests_for_each_x</code> <code>NestsList</code> <p>the composition of the nests over 1...Y, a list of r lists</p> required <code>nests_for_each_y</code> <code>NestsList</code> <p>the composition of the nests over 1...X, a list of d lists</p> required <code>true_alphas</code> <code>Optional[np.ndarray]</code> <p>the true nest parameters, if any; should be an (r+d)-vector</p> <code>None</code> Source code in <code>cupid_matching/model_classes.py</code> <pre><code>def __init__(\n    self,\n    Phi: np.ndarray,\n    n: np.ndarray,\n    m: np.ndarray,\n    nests_for_each_x: NestsList,\n    nests_for_each_y: NestsList,\n    true_alphas: Optional[np.ndarray] = None,\n):\n\"\"\"\n    We only model two-level nested logit, with {0} as the first nest,\n    and nests and nests parameters that do not depend on the type.\n\n    Args:\n        Phi: the (X,Y) joint surplus matrix\n        n: the X-vector of men margins\n        m: the X-vector of women margins\n        nests_for_each_x: the composition of the nests over 1...Y, a list of r lists\n        nests_for_each_y: the composition of the nests over 1...X, a list of d lists\n        true_alphas: the true nest parameters, if any; should be an (r+d)-vector\n    \"\"\"\n    X, Y = test_matrix(Phi)\n    Xn = test_vector(n)\n    Ym = test_vector(m)\n\n    # we need to rebase the indices to zero\n    self.nests_over_X = _change_indices(nests_for_each_y)\n    self.nests_over_Y = _change_indices(nests_for_each_x)\n\n    self.n_alphas = len(nests_for_each_y) + len(nests_for_each_x)\n\n    if Xn != X:\n        bs_error_abort(\n            f\"Phi is a ({X}, {Y}) matrix but n has {Xn} elements.\"\n        )\n    if Ym != Y:\n        bs_error_abort(\n            f\"Phi is a ({X}, {Y}) matrix but m has {Ym} elements.\"\n        )\n\n    if true_alphas is not None:\n        alpha_size = test_vector(true_alphas)\n        if alpha_size != self.n_alphas:\n            bs_error_abort(\n                f\"true_alphas shoud have {self.n_alphas} elements, not {alpha_size}\"\n            )\n\n    self.Phi = Phi\n    self.n = n\n    self.m = m\n    self.true_alphas = true_alphas\n    self.nests_for_each_x = nests_for_each_x\n    self.nests_for_each_y = nests_for_each_y\n\n    # check that every x is in a nest, and just once\n    nests_check = []\n    i_nest_of_x = np.zeros(X, int)\n    for x in range(X):\n        i_nest_of_x[x] = _find_nest_of(self.nests_over_X, x)\n        nests_check.append(i_nest_of_x[x])\n    if -1 in nests_check or len(set(nests_check)) != len(nests_for_each_y):\n        bs_error_abort(\"Check your nests_for_each_y\")\n    # check that every y is in a nest, and just once\n    nests_check = []\n    i_nest_of_y = np.zeros(Y, int)\n    for y in range(Y):\n        i_nest_of_y[y] = _find_nest_of(self.nests_over_Y, y)\n        nests_check.append(i_nest_of_y[y])\n    if -1 in nests_check or len(set(nests_check)) != len(nests_for_each_x):\n        bs_error_abort(\"Check your nests_for_each_x\")\n\n    self.i_nest_of_x = i_nest_of_x.tolist()\n    self.i_nest_of_y = i_nest_of_y.tolist()\n</code></pre>"},{"location":"model_classes/#cupid_matching.model_classes.NestedLogitPrimitives.ipfp_nested_logit_solver","title":"<code>ipfp_nested_logit_solver(tol=1e-09, verbose=False, maxiter=1000)</code>","text":"<p>Solves for equilibrium in a two-level nested logit market given systematic surplus and margins and nests parameters; does not compute the gradient of the matching patterns</p> <p>Parameters:</p> Name Type Description Default <code>tol</code> <code>float</code> <p>tolerance on change in solution</p> <code>1e-09</code> <code>verbose</code> <code>bool</code> <p>if <code>True</code>, prints information</p> <code>False</code> <code>maxiter</code> <code>int</code> <p>maximum number of iterations</p> <code>1000</code> <p>Returns:</p> Type Description <code>Matching</code> <p>the matching patterns</p> <code>np.ndarray</code> <p>marg_err_x, marg_err_y: the errors on the margins</p> Source code in <code>cupid_matching/model_classes.py</code> <pre><code>def ipfp_nested_logit_solver(\n    self, tol: float = 1e-9, verbose: bool = False, maxiter: int = 1000\n) -&gt; tuple[Matching, np.ndarray, np.ndarray]:\n\"\"\"Solves for equilibrium in a two-level nested logit market\n    given systematic surplus and margins and nests parameters;\n    does not compute the gradient of the matching patterns\n\n    Args:\n        tol: tolerance on change in solution\n        verbose: if `True`, prints information\n        maxiter: maximum number of iterations\n\n    Returns:\n         the matching patterns\n         marg_err_x, marg_err_y: the errors on the margins\n    \"\"\"\n    alphas = self.true_alphas\n    if alphas is None:\n        bs_error_abort(\"cannot solve without nest parameters\")\n    else:\n        alphas = cast(np.ndarray, alphas)\n        n_rhos = len(self.nests_over_Y)\n        n_deltas = len(self.nests_over_X)\n        rhos = alphas[:n_rhos]\n        deltas = alphas[n_rhos:]\n\n    #############################################################################\n    # we solve the equilibrium equations\n    #   starting with a reasonable initial point  muxy, mux0, mu0y = bigc\n    #   it is important that it fit the number of individuals\n    #############################################################################\n\n    n, m = self.n, self.m\n    X, Y = n.size, m.size\n\n    nests_over_X, nests_over_Y = self.nests_over_X, self.nests_over_Y\n    i_nest_of_x, i_nest_of_y = self.i_nest_of_x, self.i_nest_of_y\n\n    rho_vals = rhos[i_nest_of_y]  # rho(n) for y in n in the paper\n    delta_vals = deltas[i_nest_of_x]  # delta(n') for x in n' in the paper\n\n    ephi = npexp(self.Phi / np.add.outer(delta_vals, rho_vals))\n\n    # initial values\n    nindivs = np.sum(n) + np.sum(m)\n    bigc = nindivs / (X + Y + 2.0 * np.sum(ephi))\n\n    mux0, mu0y, muxy = (\n        np.full(X, bigc),\n        np.full(Y, bigc),\n        np.full((X, Y), bigc),\n    )\n    muxn = np.zeros((X, n_rhos))\n    for i_nest_y, nest_y in enumerate(nests_over_Y):\n        muxn[:, i_nest_y] = np.sum(muxy[:, nest_y], 1)\n    muny = np.zeros((n_deltas, Y))\n    for i_nest_x, nest_x in enumerate(nests_over_X):\n        muny[i_nest_x, :] = np.sum(muxy[nest_x, :], 0)\n\n    err_diff = bigc\n    tol_diff = tol * bigc\n    tol_newton = tol\n    max_newton = 2000\n    MIN_REST = (\n        1e-4 * bigc\n    )  # used to bound mus below in the Newton iterations\n\n    niter = 0\n    while (err_diff &gt; tol_diff) and (niter &lt; maxiter):  # IPFP main loop\n        # Newton iterates for men\n        err_newton = bigc\n        i_newton = 0\n        while err_newton &gt; tol_newton:\n            gbar = np.zeros(\n                (X, n_rhos)\n            )  # this will be the $\\bar{G}^x_n$ of the note\n            gbar_pow = np.zeros((X, n_rhos))\n            biga = np.zeros(X)  # this will be the $A_x$ of the note\n            for i_nest_x, nest_x in enumerate(nests_over_X):\n                # i_nest_x is n' in the paper\n                delta_x = deltas[i_nest_x]\n                muny_x = muny[i_nest_x, :]  # mu(n', :)\n                for x in nest_x:\n                    ephi_x = ephi[x, :]\n                    for i_nest_y, nest_y in enumerate(nests_over_Y):\n                        # i_nest_y is n in the paper\n                        mu_n = muny_x[nest_y]\n                        mu0_n = mu0y[nest_y]\n                        evec_n = ephi_x[nest_y]\n                        rho_n = rhos[i_nest_y]\n                        sum_rd = rho_n + delta_x\n                        mun_term = nppow(mu_n, (delta_x - 1.0) / sum_rd)\n                        mu0_term = nppow(mu0_n, 1.0 / sum_rd)\n                        gbar[x, i_nest_y] = np.sum(\n                            mun_term * mu0_term * evec_n\n                        )\n                        gbar_pow[x, i_nest_y] = nppow(\n                            gbar[x, i_nest_y], sum_rd / (delta_x + 1.0)\n                        )\n                        biga[x] += gbar_pow[x, i_nest_y]\n\n            # now we take one Newton step for all types of men\n            delta_vals1 = 1.0 + delta_vals\n            mux0_term = nppow(mux0, 1.0 / delta_vals1)\n            bigb = mux0_term * biga  # this is the $B_x$ of the note\n            numer = n * delta_vals1 - delta_vals * bigb\n            lower_bound = np.full(X, MIN_REST)\n            mux0_new = mux0 * np.maximum(\n                numer / (delta_vals1 * mux0 + bigb), lower_bound\n            )\n            muxn_new = gbar_pow * mux0_term.reshape((-1, 1))\n\n            mux0 = mux0_new\n            muxn = muxn_new\n            errxi = mux0 + np.sum(muxn, 1) - n\n            err_newton = npmaxabs(errxi)\n            i_newton += 1\n            if i_newton &gt; max_newton:\n                bs_error_abort(\n                    f\"Newton solver failed for men after {max_newton} iterations\"\n                )\n\n        if verbose:\n            print(\n                f\"Newton error on men is {err_newton} after {i_newton} iterations\"\n            )\n\n        # Newton iterates for women\n        err_newton = bigc\n        i_newton = 0\n        while err_newton &gt; tol_newton:\n            gbar = np.zeros((Y, n_deltas))\n            gbar_pow = np.zeros((Y, n_deltas))\n            biga = np.zeros(Y)\n            for i_nest_y, nest_y in enumerate(nests_over_Y):\n                # i_nest_y is n in the paper\n                rho_y = rhos[i_nest_y]\n                muxn_y = muxn[:, i_nest_y]  # mu(:, n)\n                for y in nest_y:\n                    ephi_y = ephi[:, y]\n                    for i_nest_x, nest_x in enumerate(nests_over_X):\n                        mu_n = muxn_y[nest_x]\n                        mu0_n = mux0[nest_x]\n                        evec_n = ephi_y[nest_x]\n                        delta_n = deltas[i_nest_x]\n                        sum_rd = rho_y + delta_n\n                        mun_term = nppow(mu_n, (rho_n - 1.0) / sum_rd)\n                        mu0_term = nppow(mu0_n, 1.0 / sum_rd)\n                        gbar[y, i_nest_x] = np.sum(\n                            mun_term * mu0_term * evec_n\n                        )\n                        gbar_pow[y, i_nest_x] = nppow(\n                            gbar[y, i_nest_x], sum_rd / (1.0 + rho_y)\n                        )\n                        biga[y] += gbar_pow[y, i_nest_x]\n\n            # now we take one Newton step for all types of women\n            rho_vals1 = 1.0 + rho_vals\n            mu0y_term = nppow(mu0y, 1.0 / rho_vals1)\n            bigb = mu0y_term * biga\n            numer = m * rho_vals1 - rho_vals * bigb\n            lower_bound = np.full(Y, MIN_REST)\n            mu0y_new = mu0y * np.maximum(\n                numer / (rho_vals1 * mu0y + bigb), lower_bound\n            )\n            muny_new = gbar_pow.T * mu0y_term\n\n            mu0y = mu0y_new\n            muny = muny_new\n            erryi = mu0y + np.sum(muny, 0) - m\n            err_newton = npmaxabs(erryi)\n            i_newton += 1\n            if i_newton &gt; max_newton:\n                bs_error_abort(\n                    f\"Newton solver failed for women after {max_newton} iterations\"\n                )\n\n        if verbose:\n            print(\n                f\"Newton error on women is {err_newton} after {i_newton} iterations\"\n            )\n\n        muxy = np.zeros((X, Y))\n        for x in range(X):\n            i_nest_x = i_nest_of_x[x]  # n'\n            ephi_x = ephi[x, :]\n            mux0_x = mux0[x]\n            muxn_x = muxn[x, :]\n            delta_x = delta_vals[x]\n            muny_x = muny[i_nest_x, :]\n            for y in range(Y):\n                i_nest_y = i_nest_of_y[y]  # n\n                mu0y_y = mu0y[y]\n                rho_y = rho_vals[y]\n                muxn_xy = muxn_x[i_nest_y]\n                muny_xy = muny_x[y]\n                mu_term = (\n                    mux0_x\n                    * mu0y_y\n                    * (muxn_xy ** (rho_y - 1.0))\n                    * (muny_xy ** (delta_x - 1.0))\n                )\n                muxy[x, y] = ephi_x[y] * (\n                    mu_term ** (1.0 / (delta_x + rho_y))\n                )\n\n        n_sim, m_sim = _compute_margins(muxy, mux0, mu0y)\n        marg_err_x, marg_err_y = n_sim - n, m_sim - m\n\n        if verbose:\n            print(\n                f\"Margin error on men is {marg_err_x} \"\n                f\" after {niter} IPFP iterations\"\n            )\n            print(\n                f\"Margin error on women is {marg_err_y} \"\n                f\" after {niter} IPFP iterations\"\n            )\n        err_diff = npmaxabs(marg_err_x) + npmaxabs(marg_err_y)\n        niter += 1\n\n    n_sim, m_sim = _compute_margins(muxy, mux0, mu0y)\n    marg_err_x = n_sim - n\n    marg_err_y = m_sim - m\n\n    if verbose:\n        print(\n            f\"Margin error on men is {npmaxabs(marg_err_x)} after {niter} IPFP iterations\"\n        )\n        print(\n            f\"Margin error on women is {npmaxabs(marg_err_y)} after {niter} IPFP iterations\"\n        )\n\n    return Matching(muxy, n, m), marg_err_x, marg_err_y\n</code></pre>"},{"location":"nested_logit/","title":"Nested Logit","text":""},{"location":"nested_logit/#nested_logit-module","title":"<code>nested_logit</code> module","text":"<p>The components of the derivative of the entropy for a two-layer nested logit model. One nest on each side must consist of the 0 option. The other nests are specified as nested lists. E.g. [[1, 3], [2,4]] describes two nests, one with types 1 and 3, and the other with types 2 and 4. On each side, the nests are the same for each type, with the same parameters.</p>"},{"location":"nested_logit/#cupid_matching.nested_logit.e0_derivative_mu_nested_logit","title":"<code>e0_derivative_mu_nested_logit(muhat, additional_parameters)</code>","text":"<p>Returns the derivatives of the parameter-independent part e_0 wrt \\mu for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list[Any]</code> <p>a list with the nest structure</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the parameter-independent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt (\\mu,\\mu).</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e0_derivative_mu_nested_logit(\n    muhat: Matching, additional_parameters: list[Any]\n) -&gt; ThreeArrays:\n\"\"\"Returns the derivatives of the parameter-independent part $e_0$\n    wrt $\\\\mu$ for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu,\\\\mu)$.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = additional_parameters\n    nests_x = _change_indices(nests_for_each_x)\n    nests_y = _change_indices(nests_for_each_y)\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    hess_x = np.zeros((X, Y, Y))\n    hess_y = np.zeros((X, Y, X))\n    hess_xy = np.zeros((X, Y))\n    der_logx0 = 1.0 / mux0\n    der_log0y = 1.0 / mu0y\n\n    for x in range(X):\n        dlogx0 = der_logx0[x]\n        for nest in nests_x:\n            mu_xn = np.sum(muxy[x, nest])\n            der_logxn = 1.0 / mu_xn\n            for y in nest:\n                hess_x[x, y, :] = -dlogx0\n                hess_x[x, y, nest] -= der_logxn\n    for y in range(Y):\n        dlog0y = der_log0y[y]\n        for nest in nests_y:\n            mu_ny = np.sum(muxy[nest, y])\n            der_logny = 1.0 / mu_ny\n            for x in nest:\n                hess_y[x, y, :] = -dlog0y\n                hess_y[x, y, nest] -= der_logny\n    for x in range(X):\n        for y in range(Y):\n            hess_xy[x, y] = hess_x[x, y, y] + hess_y[x, y, x]\n\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"nested_logit/#cupid_matching.nested_logit.e0_derivative_r_nested_logit","title":"<code>e0_derivative_r_nested_logit(muhat, additional_parameters)</code>","text":"<p>Returns the derivatives of the parameter-independent part e_0 wrt r for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list[Any]</code> <p>a list with the nest structure</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-independent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt (\\mu,r).</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e0_derivative_r_nested_logit(\n    muhat: Matching, additional_parameters: list[Any]\n) -&gt; TwoArrays:\n\"\"\"Returns the derivatives of the parameter-independent part $e_0$\n    wrt $r$ for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the parameter-independent part of the hessian of the entropy\n        wrt $(\\\\mu,r)$.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = additional_parameters\n    nests_x = _change_indices(nests_for_each_x)\n    nests_y = _change_indices(nests_for_each_y)\n    muxy, mux0, mu0y, n, m = muhat.unpack()\n    X, Y = muxy.shape\n\n    hess_n = np.zeros((X, Y))\n    hess_m = np.zeros((X, Y))\n    der_logx0 = 1.0 / mux0\n    der_log0y = 1.0 / mu0y\n\n    for x in range(X):\n        dlogx0 = der_logx0[x]\n        for nest in nests_x:\n            for y in nest:\n                hess_n[x, y] = dlogx0\n    for y in range(Y):\n        dlog0y = der_log0y[y]\n        for nest in nests_y:\n            for x in nest:\n                hess_m[x, y] = dlog0y\n\n    return hess_n, hess_m\n</code></pre>"},{"location":"nested_logit/#cupid_matching.nested_logit.e0_nested_logit","title":"<code>e0_nested_logit(muhat, additional_parameters)</code>","text":"<p>Returns the values of the parameter-independent part e_0 for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list[Any]</code> <p>a list with the nest structure</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>the (X,Y) matrix of the parameter-independent part</p> <code>np.ndarray</code> <p>of the first derivative of the entropy.</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e0_nested_logit(\n    muhat: Matching, additional_parameters: list[Any]\n) -&gt; np.ndarray:\n\"\"\"Returns the values of the parameter-independent part $e_0$\n    for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the (X,Y) matrix of the parameter-independent part\n        of the first derivative of the entropy.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = additional_parameters\n    nests_x = _change_indices(nests_for_each_x)\n    nests_y = _change_indices(nests_for_each_y)\n    muxy, mux0, mu0y, *_ = muhat.unpack()\n    X, Y = muxy.shape\n    e0_vals = np.zeros((X, Y))\n\n    for x in range(X):\n        mux0_x = mux0[x]\n        for nest in nests_x:\n            mu_xn = np.sum(muxy[x, nest])\n            e0_vals[x, nest] = -log(mu_xn / mux0_x)\n    for y in range(Y):\n        mu0y_y = mu0y[y]\n        for nest in nests_y:\n            mu_ny = np.sum(muxy[nest, y])\n            e0_vals[nest, y] -= log(mu_ny / mu0y_y)\n    return e0_vals\n</code></pre>"},{"location":"nested_logit/#cupid_matching.nested_logit.e_derivative_mu_nested_logit","title":"<code>e_derivative_mu_nested_logit(muhat, additional_parameters)</code>","text":"<p>Returns the derivatives of the parameter-dependent part e  wrt \\mu for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list[Any]</code> <p>a list with the nest structure</p> required <p>Returns:</p> Type Description <code>ThreeArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>ThreeArrays</code> <p>wrt (\\mu,\\mu).</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e_derivative_mu_nested_logit(\n    muhat: Matching, additional_parameters: list[Any]\n) -&gt; ThreeArrays:\n\"\"\"Returns the derivatives of the parameter-dependent part $e$\n     wrt $\\\\mu$ for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $(\\\\mu,\\\\mu)$.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = additional_parameters\n    nests_x = _change_indices(nests_for_each_x)\n    nests_y = _change_indices(nests_for_each_y)\n    n_rhos = len(nests_for_each_x)\n    n_deltas = len(nests_for_each_y)\n    n_alpha = n_rhos + n_deltas\n\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    hess_x = np.zeros((X, Y, Y, n_alpha))\n    hess_y = np.zeros((X, Y, X, n_alpha))\n    hess_xy = np.zeros((X, Y, n_alpha))\n    der_logxy = 1.0 / muxy\n\n    for x in range(X):\n        for i_n, nest in enumerate(nests_x):\n            mux_nest_n = muxy[x, nest]\n            mu_xn = np.sum(mux_nest_n)\n            der_logxn = 1.0 / mu_xn\n            for t in nest:\n                hess_x[x, nest, t, i_n] = der_logxn\n            hess_xy[x, nest, i_n] = der_logxn - der_logxy[x, nest]\n\n    for y in range(Y):\n        for i_n, nest in enumerate(nests_y):\n            muy_nest_n = muxy[nest, y]\n            mu_ny = np.sum(muy_nest_n)\n            der_logny = 1.0 / mu_ny\n            i_n2 = i_n + n_rhos\n            for z in nest:\n                hess_y[nest, y, z, i_n2] = der_logny\n            hess_xy[nest, y, i_n2] = der_logny - der_logxy[nest, y]\n\n    return hess_x, hess_y, hess_xy\n</code></pre>"},{"location":"nested_logit/#cupid_matching.nested_logit.e_derivative_r_nested_logit","title":"<code>e_derivative_r_nested_logit(muhat, additional_parameters)</code>","text":"<p>Returns the derivatives of the parameter-dependent part e  wrt r for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list[Any]</code> <p>a list with the nest structure</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>the parameter-dependent part of the hessian of the entropy</p> <code>TwoArrays</code> <p>wrt (\\mu,r).</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e_derivative_r_nested_logit(\n    muhat: Matching, additional_parameters: list[Any]\n) -&gt; TwoArrays:\n\"\"\"Returns the derivatives of the parameter-dependent part $e$\n     wrt $r$ for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the parameter-dependent part of the hessian of the entropy\n        wrt $(\\\\mu,r)$.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = additional_parameters\n    n_rhos = len(nests_for_each_x)\n    n_deltas = len(nests_for_each_y)\n    n_alpha = n_rhos + n_deltas\n\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    hess_n = np.zeros((X, Y, n_alpha))\n    hess_m = np.zeros((X, Y, n_alpha))\n\n    return hess_n, hess_m\n</code></pre>"},{"location":"nested_logit/#cupid_matching.nested_logit.e_nested_logit","title":"<code>e_nested_logit(muhat, additional_parameters)</code>","text":"<p>Returns the values of the parameter-dependent part  e for the nested logit.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>a Matching</p> required <code>additional_parameters</code> <code>list[Any]</code> <p>a list with the nest structure</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>the (X,Y,n_alpha) array of the parameter-dependent part</p> <code>np.ndarray</code> <p>of the first derivative of the entropy.</p> Source code in <code>cupid_matching/nested_logit.py</code> <pre><code>def e_nested_logit(\n    muhat: Matching, additional_parameters: list[Any]\n) -&gt; np.ndarray:\n\"\"\"Returns the values of the parameter-dependent part  $e$\n    for the nested logit.\n\n    Args:\n        muhat: a Matching\n        additional_parameters: a list with the nest structure\n\n    Returns:\n        the (X,Y,n_alpha) array of the parameter-dependent part\n        of the first derivative of the entropy.\n    \"\"\"\n    nests_for_each_x, nests_for_each_y = additional_parameters\n    nests_x = _change_indices(nests_for_each_x)\n    nests_y = _change_indices(nests_for_each_y)\n    n_rhos = len(nests_for_each_x)\n    n_deltas = len(nests_for_each_y)\n    n_alpha = n_rhos + n_deltas\n\n    muxy, *_ = muhat.unpack()\n    X, Y = muxy.shape\n\n    e_vals = np.zeros((X, Y, n_alpha))\n\n    for x in range(X):\n        for i_n, nest in enumerate(nests_x):\n            mux_nest_n = muxy[x, nest]\n            mu_xn = np.sum(mux_nest_n)\n            e_vals[x, nest, i_n] = -np.log(mux_nest_n / mu_xn)\n\n    for y in range(Y):\n        for i_n, nest in enumerate(nests_y):\n            muy_nest_n = muxy[nest, y]\n            mu_ny = np.sum(muy_nest_n)\n            e_vals[nest, y, (i_n + n_rhos)] -= np.log(muy_nest_n / mu_ny)\n\n    return e_vals\n</code></pre>"},{"location":"poisson_glm/","title":"<code>poisson_glm</code> module","text":"<p>Estimates the semilinear Choo and Siow homoskedastic (2006) model using Poisson GLM.</p>"},{"location":"poisson_glm/#cupid_matching.poisson_glm.choo_siow_poisson_glm","title":"<code>choo_siow_poisson_glm(muhat, phi_bases, tol=1e-12, max_iter=10000, verbose=1)</code>","text":"<p>Estimates the semilinear Choo and Siow homoskedastic (2006) model     using Poisson GLM.</p> <p>Parameters:</p> Name Type Description Default <code>muhat</code> <code>Matching</code> <p>the observed Matching</p> required <code>phi_bases</code> <code>np.ndarray</code> <p>an (X, Y, K) array of bases</p> required <code>tol</code> <code>Optional[float]</code> <p>tolerance level for <code>linear_model.PoissonRegressor.fit</code></p> <code>1e-12</code> <code>max_iter</code> <code>Optional[int]</code> <p>maximum number of iterations for <code>linear_model.PoissonRegressor.fit</code></p> <code>10000</code> <code>verbose</code> <code>Optional[int]</code> <p>defines how much output we want (0 = least)</p> <code>1</code> <p>Returns:</p> Type Description <code>PoissonGLMResults</code> <p>a <code>PoissonGLMResults</code> instance</p> Example <pre><code>n_households = 1e6\nX, Y, K = 4, 3, 6\n# we setup a quadratic set of basis functions\nphi_bases = np.zeros((X, Y, K))\nphi_bases[:, :, 0] = 1\nfor x in range(X):\n    phi_bases[x, :, 1] = x\n    phi_bases[x, :, 3] = x * x\n    for y in range(Y):\n        phi_bases[x, y, 4] = x * y\nfor y in range(Y):\n    phi_bases[:, y, 2] = y\n    phi_bases[:, y, 5] = y * y\n\nlambda_true = np.random.randn(K)\nphi_bases = np.random.randn(X, Y, K)\nPhi = phi_bases @ lambda_true\n\n# we simulate a Choo and Siow sample from a population\n#  with equal numbers of men and women of each type\nn = np.ones(X)\nm = np.ones(Y)\nchoo_siow_instance = ChooSiowPrimitives(Phi, n, m)\nmus_sim = choo_siow_instance.simulate(n_households)\nmuxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack()\n\nresults = choo_siow_poisson_glm(mus_sim, phi_bases)\n\n# compare true and estimated parameters\nresults.print_results(\n    lambda_true,\n    u_true=-np.log(mux0_sim / n_sim),\n    v_true=-np.log(mu0y_sim / m_sim)\n)\n</code></pre> Source code in <code>cupid_matching/poisson_glm.py</code> <pre><code>def choo_siow_poisson_glm(\n    muhat: Matching,\n    phi_bases: np.ndarray,\n    tol: Optional[float] = 1e-12,\n    max_iter: Optional[int] = 10000,\n    verbose: Optional[int] = 1,\n) -&gt; PoissonGLMResults:\n\"\"\"Estimates the semilinear Choo and Siow homoskedastic (2006) model\n        using Poisson GLM.\n\n    Args:\n        muhat: the observed Matching\n        phi_bases: an (X, Y, K) array of bases\n        tol: tolerance level for `linear_model.PoissonRegressor.fit`\n        max_iter: maximum number of iterations\n            for `linear_model.PoissonRegressor.fit`\n        verbose: defines how much output we want (0 = least)\n\n    Returns:\n        a `PoissonGLMResults` instance\n\n    Example:\n        ```py\n        n_households = 1e6\n        X, Y, K = 4, 3, 6\n        # we setup a quadratic set of basis functions\n        phi_bases = np.zeros((X, Y, K))\n        phi_bases[:, :, 0] = 1\n        for x in range(X):\n            phi_bases[x, :, 1] = x\n            phi_bases[x, :, 3] = x * x\n            for y in range(Y):\n                phi_bases[x, y, 4] = x * y\n        for y in range(Y):\n            phi_bases[:, y, 2] = y\n            phi_bases[:, y, 5] = y * y\n\n        lambda_true = np.random.randn(K)\n        phi_bases = np.random.randn(X, Y, K)\n        Phi = phi_bases @ lambda_true\n\n        # we simulate a Choo and Siow sample from a population\n        #  with equal numbers of men and women of each type\n        n = np.ones(X)\n        m = np.ones(Y)\n        choo_siow_instance = ChooSiowPrimitives(Phi, n, m)\n        mus_sim = choo_siow_instance.simulate(n_households)\n        muxy_sim, mux0_sim, mu0y_sim, n_sim, m_sim = mus_sim.unpack()\n\n        results = choo_siow_poisson_glm(mus_sim, phi_bases)\n\n        # compare true and estimated parameters\n        results.print_results(\n            lambda_true,\n            u_true=-np.log(mux0_sim / n_sim),\n            v_true=-np.log(mu0y_sim / m_sim)\n        )\n        ```\n\n    \"\"\"\n    try_sparse = False\n    X, Y, K = phi_bases.shape\n    XY = X * Y\n    n_rows = XY + X + Y\n    n_cols = X + Y + K\n\n    # the vector of weights for the Poisson regression\n    w = np.concatenate((2 * np.ones(XY), np.ones(X + Y)))\n    # reshape the bases\n    phi_mat = _make_XY_K_mat(phi_bases)\n\n    if try_sparse:\n        w_mat = spr.csr_matrix(\n            np.concatenate(\n                (2 * np.ones((XY, n_cols)), np.ones((X + Y, n_cols)))\n            )\n        )\n\n        # construct the Z matrix\n        ones_X = spr.csr_matrix(np.ones((X, 1)))\n        ones_Y = spr.csr_matrix(np.ones((Y, 1)))\n        zeros_XK = spr.csr_matrix(np.zeros((X, K)))\n        zeros_YK = spr.csr_matrix(np.zeros((Y, K)))\n        zeros_XY = spr.csr_matrix(np.zeros((X, Y)))\n        zeros_YX = spr.csr_matrix(np.zeros((Y, X)))\n        id_X = spr.csr_matrix(np.eye(X))\n        id_Y = spr.csr_matrix(np.eye(Y))\n        Z_unweighted = spr.vstack(\n            [\n                spr.hstack(\n                    [\n                        -spr.kron(id_X, ones_Y),\n                        -spr.kron(ones_X, id_Y),\n                        phi_mat,\n                    ]\n                ),\n                spr.hstack([-id_X, zeros_XY, zeros_XK]),\n                spr.hstack([zeros_YX, -id_Y, zeros_YK]),\n            ]\n        )\n        Z = Z_unweighted / w_mat\n    else:\n        ones_X = np.ones((X, 1))\n        ones_Y = np.ones((Y, 1))\n        zeros_XK = np.zeros((X, K))\n        zeros_YK = np.zeros((Y, K))\n        zeros_XY = np.zeros((X, Y))\n        zeros_YX = np.zeros((Y, X))\n        id_X = np.eye(X)\n        id_Y = np.eye(Y)\n        Z_unweighted = np.vstack(\n            [\n                np.hstack(\n                    [-np.kron(id_X, ones_Y), -np.kron(ones_X, id_Y), phi_mat]\n                ),\n                np.hstack([-id_X, zeros_XY, zeros_XK]),\n                np.hstack([zeros_YX, -id_Y, zeros_YK]),\n            ]\n        )\n        Z = Z_unweighted / w.reshape((-1, 1))\n\n    _, _, _, n, m = muhat.unpack()\n    var_muhat, var_munm = _variance_muhat(muhat)\n    (\n        muxyhat_norm,\n        var_muhat_norm,\n        var_munm_norm,\n        n_households,\n        n_individuals,\n    ) = _prepare_data(muhat, var_muhat, var_munm)\n\n    clf = linear_model.PoissonRegressor(\n        fit_intercept=False,\n        tol=tol,\n        verbose=verbose,\n        alpha=0,\n        max_iter=max_iter,\n    )\n    clf.fit(Z, muxyhat_norm, sample_weight=w)\n    gamma_est = clf.coef_\n\n    # we compute the variance-covariance of the estimator\n    nr, nc = Z.shape\n    exp_Zg = np.exp(Z @ gamma_est).reshape(n_rows)\n    A_hat = np.zeros((nc, nc))\n    B_hat = np.zeros((nc, nc))\n    for i in range(nr):\n        Zi = Z[i, :]\n        wi = w[i]\n        A_hat += wi * exp_Zg[i] * np.outer(Zi, Zi)\n        for j in range(nr):\n            Zj = Z[j, :]\n            B_hat += wi * w[j] * var_muhat_norm[i, j] * np.outer(Zi, Zj)\n\n    A_inv = spla.inv(A_hat)\n    varcov_gamma = A_inv @ B_hat @ A_inv\n    stderrs_gamma = np.sqrt(np.diag(varcov_gamma))\n\n    beta_est = gamma_est[-K:]\n    varcov_beta = varcov_gamma[-K:, -K:]\n    beta_std = stderrs_gamma[-K:]\n    Phi_est = phi_bases @ beta_est\n\n    # we correct for the effect of the normalization\n    n_norm = n / n_individuals\n    m_norm = m / n_individuals\n    u_est = gamma_est[:X] + np.log(n_norm)\n    v_est = gamma_est[X:-K] + np.log(m_norm)\n\n    # since u = a + log(n_norm) we also need to adjust the estimated variance\n    z_unweighted_T = Z_unweighted.T\n    u_std = np.zeros(X)\n    ix = XY\n    for x in range(X):\n        n_norm_x = n_norm[x]\n        A_inv_x = A_inv[x, :]\n        var_log_nx = var_munm_norm[ix, ix] / n_norm_x / n_norm_x\n        slice_x = slice(x * Y, (x + 1) * Y)\n        covar_term = var_muhat_norm[:, ix] + np.sum(\n            var_muhat_norm[:, slice_x], 1\n        )\n        cov_a_lognx = (A_inv_x @ z_unweighted_T @ covar_term) / n_norm_x\n        ux_var = varcov_gamma[x, x] + var_log_nx + 2.0 * cov_a_lognx\n        u_std[x] = sqrt(ux_var)\n        ix += 1\n\n    v_std = stderrs_gamma[X:-K]\n    iy, jy = X, XY + X\n    for y in range(Y):\n        m_norm_y = m_norm[y]\n        A_inv_y = A_inv[iy, :]\n        var_log_my = var_munm_norm[jy, jy] / m_norm_y / m_norm_y\n        slice_y = slice(y, XY, Y)\n        covar_term = var_muhat_norm[:, jy] + np.sum(\n            var_muhat_norm[:, slice_y], 1\n        )\n        cov_b_logmy = (A_inv_y @ z_unweighted_T @ covar_term) / m_norm_y\n        vy_var = varcov_gamma[iy, iy] + var_log_my + 2.0 * cov_b_logmy\n        v_std[y] = sqrt(vy_var)\n        iy += 1\n        jy += 1\n\n    results = PoissonGLMResults(\n        X=X,\n        Y=Y,\n        K=K,\n        number_households=n_households,\n        number_individuals=n_individuals,\n        estimated_gamma=gamma_est,\n        estimated_Phi=Phi_est,\n        estimated_beta=beta_est,\n        estimated_u=u_est,\n        estimated_v=v_est,\n        varcov_gamma=varcov_gamma,\n        varcov_beta=varcov_beta,\n        stderrs_gamma=stderrs_gamma,\n        stderrs_beta=beta_std,\n        stderrs_u=u_std,\n        stderrs_v=v_std,\n    )\n\n    return results\n</code></pre>"},{"location":"poisson_glm_utils/","title":"<code>poisson_glm_utils</code> module","text":"<p>Utilities for Poisson GLM.</p>"},{"location":"poisson_glm_utils/#cupid_matching.poisson_glm_utils.PoissonGLMResults","title":"<code>PoissonGLMResults</code>  <code>dataclass</code>","text":"<p>Stores and formats the estimation results.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>int</code> <p>int</p> required <code>Y</code> <code>int</code> <p>int</p> required <code>K</code> <code>int</code> <p>int</p> required <code>number_households</code> <code>int</code> <p>int</p> required <code>number_individuals</code> <code>int</code> <p>int</p> required <code>estimated_gamma</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>varcov_gamma</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>stderrs_gamma</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>estimated_beta</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>estimated_u</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>estimated_v</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>varcov_beta</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>stderrs_beta</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>stderrs_u</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>stderrs_v</code> <code>np.ndarray</code> <p>np.ndarray</p> required <code>estimated_Phi</code> <code>np.ndarray</code> <p>np.ndarray</p> required Source code in <code>cupid_matching/poisson_glm_utils.py</code> <pre><code>@dataclass\nclass PoissonGLMResults:\n\"\"\"Stores and formats the estimation results.\n\n    Args:\n        X: int\n        Y: int\n        K: int\n        number_households: int\n        number_individuals: int\n        estimated_gamma: np.ndarray\n        varcov_gamma: np.ndarray\n        stderrs_gamma: np.ndarray\n        estimated_beta: np.ndarray\n        estimated_u: np.ndarray\n        estimated_v: np.ndarray\n        varcov_beta: np.ndarray\n        stderrs_beta: np.ndarray\n        stderrs_u: np.ndarray\n        stderrs_v: np.ndarray\n        estimated_Phi: np.ndarray\n    \"\"\"\n\n    X: int\n    Y: int\n    K: int\n    number_households: int\n    number_individuals: int\n    estimated_gamma: np.ndarray\n    varcov_gamma: np.ndarray\n    stderrs_gamma: np.ndarray\n    estimated_beta: np.ndarray\n    varcov_beta: np.ndarray\n    estimated_u: np.ndarray\n    estimated_v: np.ndarray\n    stderrs_beta: np.ndarray\n    stderrs_u: np.ndarray\n    stderrs_v: np.ndarray\n    estimated_Phi: np.ndarray\n\n    def __str__(self):\n        line_stars = \"*\" * 80 + \"\\n\"\n        print_stars(\"Estimating a Choo and Siow model by Poisson GLM.\")\n        model_str = f\"The data has {self.number_households} households\\n\\n\"\n        model_str += f\"We use {self.K} basis functions.\\n\\n\"\n        repr_str = line_stars + model_str\n        repr_str += \"The estimated basis coefficients (and their standard errors) are\\n\\n\"\n        for i in range(self.K):\n            repr_str += (\n                f\"   base_{i + 1}: {self.estimated_beta[i]: &gt; 10.3f}  \"\n                + f\"({self.stderrs_beta[i]: .3f})\\n\"\n            )\n        repr_str += (\n            \"The estimated utilities of men (and their standard errors) are\\n\\n\"\n        )\n        for i in range(self.X):\n            repr_str += (\n                f\"   u_{i + 1}: {self.estimated_u[i]: &gt; 10.3f}  \"\n                + f\"({self.stderrs_u[i]: .3f})\\n\"\n            )\n        repr_str += \"The estimated utilities of women (and their standard errors) are\\n\\n\"\n        for i in range(self.Y):\n            repr_str += (\n                f\"   v {i + 1}: {self.estimated_v[i]: &gt; 10.3f}  \"\n                + f\"({self.stderrs_v[i]: .3f})\\n\"\n            )\n        return repr_str + line_stars\n\n    def print_results(\n        self,\n        lambda_true: Optional[np.ndarray] = None,\n        u_true: Optional[np.ndarray] = None,\n        v_true: Optional[np.ndarray] = None,\n    ) -&gt; float | None:\n        estimates_beta = self.estimated_beta\n        stderrs_beta = self.stderrs_beta\n\n        if lambda_true is None:\n            repr_str = \"The  estimated coefficients \"\n            repr_str += \"(and their standard errors) are\\n\\n\"\n            for i, coeff in enumerate(estimates_beta):\n                repr_str += f\" {coeff: &gt; 10.3f}  ({stderrs_beta[i]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n        else:\n            repr_str = \"The  true and estimated coefficients \"\n            repr_str += \"(and their standard errors) are\\n\\n\"\n            for i, coeff in enumerate(estimates_beta):\n                repr_str += f\"   base {i + 1}: {lambda_true[i]: &gt; 10.3f} \"\n                repr_str += f\" {coeff: &gt; 10.3f}  ({stderrs_beta[i]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n\n        estimates_u = self.estimated_u\n        stderrs_u = self.stderrs_u\n\n        if u_true is None:\n            repr_str = \"The estimated utilities for men  \"\n            repr_str += \"(and their standard errors) are:\\n\\n\"\n            for i, coeff in enumerate(estimates_u):\n                repr_str += f\" {coeff: &gt; 10.3f}  ({stderrs_u[i]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n        else:\n            repr_str = \"The true and estimated utilities for men \"\n            repr_str += \"(and their standard errors) are:\\n\\n\"\n            for i, coeff in enumerate(estimates_u):\n                repr_str += f\"   u_{i + 1}: {u_true[i]: &gt; 10.3f} \"\n                repr_str += f\" {coeff: &gt; 10.3f}  ({stderrs_u[i]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n\n        estimates_v = self.estimated_v\n        stderrs_v = self.stderrs_v\n        if v_true is None:\n            repr_str = \"The estimated utilities for women \"\n            repr_str += \"(and their standard errors) are:\\n\\n\"\n            for i, coeff in enumerate(estimates_v):\n                repr_str += f\" {coeff: &gt; 10.3f}  ({stderrs_v[i]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n        else:\n            repr_str = \"The true and estimated utilities for women \"\n            repr_str += \"(and their standard errors) are:\\n\\n\"\n            for i, coeff in enumerate(estimates_v):\n                repr_str += f\"   v_{i + 1}: {v_true[i]: &gt; 10.3f} \"\n                repr_str += f\" {coeff: &gt; 10.3f}  ({stderrs_v[i]: &gt; 10.3f})\\n\"\n            print_stars(repr_str)\n\n        if lambda_true is None:\n            return None\n        else:\n            discrepancy = npmaxabs(lambda_true - estimates_beta)\n            print_stars(f\"The largest difference between true and estimated coefficients is {discrepancy: .2e}\")\n            return discrepancy\n</code></pre>"},{"location":"utils/","title":"<code>utils</code> module","text":"<p>This module contains some utility programs used by the package.</p>"},{"location":"utils/#cupid_matching.utils.ScalarFunctionAndGradient","title":"<code>ScalarFunctionAndGradient: TypeAlias = Callable[[np.ndarray, list, Optional[bool]], float | tuple[float, np.ndarray]]</code>  <code>module-attribute</code>","text":"<p>Type of f(v, args, gr) that returns a scalar value and also a gradient if gr is True</p>"},{"location":"utils/#cupid_matching.utils.bs_error_abort","title":"<code>bs_error_abort(msg='error, aborting')</code>","text":"<p>Report error and exits with code 1</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>specifies the error message</p> <code>'error, aborting'</code> <p>Returns:</p> Type Description <code>None</code> <p>nothing</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def bs_error_abort(msg: str = \"error, aborting\") -&gt; None:\n\"\"\"Report error and exits with code 1\n\n    Args:\n        msg: specifies the error message\n\n    Returns:\n        nothing\n    \"\"\"\n    print_stars(f\"{bs_name_func(3)}: {msg}\")\n    sys.exit(1)\n</code></pre>"},{"location":"utils/#cupid_matching.utils.bs_name_func","title":"<code>bs_name_func(back=2)</code>","text":"<p>Get the name of the current function, or further back in the stack</p> <p>Parameters:</p> Name Type Description Default <code>back</code> <code>int</code> <p>2 for the current function, 3 for the function that called it, etc</p> <code>2</code> <p>Returns:</p> Type Description <code>str</code> <p>the name of the function requested</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def bs_name_func(back: int = 2) -&gt; str:\n\"\"\"Get the name of the current function, or further back in the stack\n\n    Args:\n        back: 2 for the current function, 3 for the function that called it, etc\n\n    Returns:\n        the name of the function requested\n    \"\"\"\n    stack = extract_stack()\n    func_name: str = stack[-back][2]\n    return func_name\n</code></pre>"},{"location":"utils/#cupid_matching.utils.check_gradient_scalar_function","title":"<code>check_gradient_scalar_function(fg, p, args, mode='central', EPS=1e-06)</code>","text":"<p>Checks the gradient of a scalar function.</p> <p>Parameters:</p> Name Type Description Default <code>fg</code> <code>Any</code> <p>should return the scalar value, and the gradient if its <code>gr</code> argument is <code>True</code></p> required <code>p</code> <code>np.ndarray</code> <p>where we are checking the gradient</p> required <code>args</code> <code>list[Any]</code> <p>other arguments passed to <code>fg</code></p> required <code>mode</code> <code>str</code> <p>\"central\" or \"forward\" derivatives</p> <code>'central'</code> <code>EPS</code> <code>float</code> <p>the step for forward or central derivatives</p> <code>1e-06</code> <p>Returns:</p> Type Description <code>tuple[np.ndarray, np.ndarray]</code> <p>the analytic and numeric gradients</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def check_gradient_scalar_function(\n    fg: Any,\n    p: np.ndarray,\n    args: list[Any],\n    mode: str = \"central\",\n    EPS: float = 1e-6,\n) -&gt; tuple[np.ndarray, np.ndarray]:\n\"\"\"Checks the gradient of a scalar function.\n\n    Args:\n        fg: should return the scalar value, and the gradient if its `gr` argument is `True`\n        p: where we are checking the gradient\n        args: other arguments passed to `fg`\n        mode: \"central\" or \"forward\" derivatives\n        EPS: the step for forward or central derivatives\n\n    Returns:\n        the analytic and numeric gradients\n    \"\"\"\n    # if not isinstance(fg, ScalarFunctionAndGradient):\n    #     bs_error_abort(\"wrong type for fg\")\n    f0, f_grad = fg(p, args, True)\n\n    print_stars(\"checking the gradient: analytic, numeric\")\n\n    g = np.zeros_like(p)\n    sp: int = p.size\n    if mode == \"central\":\n        for i in range(sp):\n            x = p[i]\n            p1 = p.copy()\n            p1[i] = x + EPS\n            f_plus = fg(p1, args, False)\n            p1[i] -= 2.0 * EPS\n            f_minus = fg(p1, args, False)\n            g[i] = (f_plus - f_minus) / (2.0 * EPS)\n            print(f\"{i}: {f_grad[i]}, {g[i]}\")\n    elif mode == \"forward\":\n        for i in range(sp):\n            x = p[i]\n            p1 = p.copy()\n            p1[i] = x + EPS\n            f_plus = fg(p1, args, False)\n            g[i] = (f_plus - f0) / EPS\n            print(f\"{i}: {f_grad[i]}, {g[i]}\")\n    else:\n        bs_error_abort(\"mode must be 'central' or 'forward'\")\n\n    return f_grad, g\n</code></pre>"},{"location":"utils/#cupid_matching.utils.der_nppow","title":"<code>der_nppow(a, b)</code>","text":"<p>evaluates the derivatives in a and b of element-by-element a^b</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>np.ndarray</code> <p>input Numpy arrays</p> required <code>b</code> <code>int | float | np.ndarray</code> <p>a Numpy array of the same shape, or a scalar</p> required <p>Returns:</p> Type Description <code>TwoArrays</code> <p>a pair of two arrays of the same shape as <code>a</code></p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def der_nppow(a: np.ndarray, b: int | float | np.ndarray) -&gt; TwoArrays:\n\"\"\"\n    evaluates the derivatives in a and b of element-by-element $a^b$\n\n    Args:\n        a: input Numpy arrays\n        b: a Numpy array of the same shape, or a scalar\n\n    Returns:\n        a pair of two arrays of the same shape as `a`\n    \"\"\"\n    mina: float = np.min(a)\n    if mina &lt;= 0:\n        print_stars(\"All elements of a must be positive in der_nppow!\")\n        sys.exit(1)\n\n    if isinstance(b, (int, float)):\n        a_pow_b = np.power(a, b)\n        return (b * a_pow_b / a, a_pow_b * log(a))\n    else:\n        if a.shape != b.shape:\n            print_stars(\n                \"nppow: b is not a number or an array of the same shape as a!\"\n            )\n            sys.exit(1)\n        avec = a.ravel()\n        bvec = b.ravel()\n        a_pow_b = avec**bvec\n        der_wrt_a = a_pow_b * bvec / avec\n        der_wrt_b = a_pow_b * nplog(avec)\n        return der_wrt_a.reshape(a.shape), der_wrt_b.reshape(a.shape)\n</code></pre>"},{"location":"utils/#cupid_matching.utils.describe_array","title":"<code>describe_array(v, name='The array')</code>","text":"<p>Descriptive statistics on an array interpreted as a vector</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>np.ndarray</code> <p>the array</p> required <code>name</code> <code>str</code> <p>its name</p> <code>'The array'</code> <p>Returns:</p> Type Description <code>NamedTuple</code> <p>a <code>DescribeResult</code> namedtuple</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def describe_array(v: np.ndarray, name: str = \"The array\") -&gt; NamedTuple:\n\"\"\"Descriptive statistics on an array interpreted as a vector\n\n    Args:\n        v: the array\n        name: its name\n\n    Returns:\n        a `DescribeResult` namedtuple\n    \"\"\"\n    print_stars(f\"{name} has:\")\n    d = sts.describe(v, None)\n    print(f\"Number of elements: {d.nobs}\")\n    print(f\"Minimum: {d.minmax[0]}\")\n    print(f\"Maximum: {d.minmax[1]}\")\n    print(f\"Mean: {d.mean}\")\n    print(f\"Stderr: {sqrt(d.variance)}\")\n    return d\n</code></pre>"},{"location":"utils/#cupid_matching.utils.npexp","title":"<code>npexp(a, deriv=False, bigx=30.0, verbose=False)</code>","text":"<p>C^2 extension of  \\exp(a) above <code>bigx</code></p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>np.ndarray</code> <p>a Numpy array</p> required <code>deriv</code> <code>bool</code> <p>if <code>True</code>, the first derivative is also returned</p> <code>False</code> <code>bigx</code> <code>float</code> <p>an upper bound</p> <code>30.0</code> <code>verbose</code> <code>bool</code> <p>whether diagnoses are printed</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bigx</code> <code>np.ndarray | TwoArrays</code> <p>upper bound \\exp(a) C^2-extended above <code>bigx</code>,</p> <code>np.ndarray | TwoArrays</code> <p>with its derivative if <code>deriv</code> is <code>True</code></p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def npexp(\n    a: np.ndarray,\n    deriv: bool = False,\n    bigx: float = 30.0,\n    verbose: bool = False,\n) -&gt; np.ndarray | TwoArrays:\n\"\"\"\n    $C^2$ extension of  $\\\\exp(a)$ above `bigx`\n\n    Args:\n        a: a Numpy array\n        deriv: if `True`, the first derivative is also returned\n        bigx: an upper bound\n        verbose: whether diagnoses are printed\n\n    Returns:\n        bigx: upper bound $\\\\exp(a)$  $C^2$-extended above `bigx`,\n        with its derivative if `deriv` is `True`\n    \"\"\"\n    if np.max(a) &lt; bigx:\n        expa = np.exp(a)\n        return (expa, expa) if deriv else expa\n    else:\n        exparr = np.exp(np.minimum(a, bigx))\n        ebigx = exp(bigx)\n        darr = a - bigx\n        exparr_larger = ebigx * (1.0 + darr * (1.0 + 0.5 * darr))\n        if verbose:\n            n_large_args = np.sum(a &gt; bigx)\n            if n_large_args &gt; 0:\n                finals = \"s\" if n_large_args &gt; 1 else \"\"\n                print(\n                    f\"npexp: {n_large_args} argument{finals} larger than {bigx}: maxi = {np.max(a)}\"\n                )\n        expa = np.where(a &lt; bigx, exparr, exparr_larger)\n        if deriv:\n            der_exparr = np.exp(np.minimum(a, bigx))\n            der_exparr_larger = ebigx * (1.0 + darr)\n            der_expa = np.where(a &lt; bigx, der_exparr, der_exparr_larger)\n            return expa, der_expa\n        else:\n            return expa\n</code></pre>"},{"location":"utils/#cupid_matching.utils.nplog","title":"<code>nplog(a, deriv=False, eps=1e-30, verbose=False)</code>","text":"<p>C^2 extension of  \\ln(a) below <code>eps</code></p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>np.ndarray</code> <p>a Numpy array</p> required <code>deriv</code> <code>bool</code> <p>if <code>True</code>, the first derivative is also returned</p> <code>False</code> <code>eps</code> <code>float</code> <p>a lower bound</p> <code>1e-30</code> <code>verbose</code> <code>bool</code> <p>whether diagnoses are printed</p> <code>False</code> <p>Returns:</p> Type Description <code>np.ndarray | tuple[np.ndarray, np.ndarray]</code> <p>\\ln(a) C^2-extended below <code>eps</code>,</p> <code>np.ndarray | tuple[np.ndarray, np.ndarray]</code> <p>with its derivative if <code>deriv</code> is <code>True</code></p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def nplog(\n    a: np.ndarray,\n    deriv: bool = False,\n    eps: float = 1e-30,\n    verbose: bool = False,\n) -&gt; np.ndarray | tuple[np.ndarray, np.ndarray]:\n\"\"\"$C^2$ extension of  $\\\\ln(a)$ below `eps`\n\n    Args:\n        a: a Numpy array\n        deriv: if `True`, the first derivative is also returned\n        eps: a lower bound\n        verbose: whether diagnoses are printed\n\n    Returns:\n        $\\\\ln(a)$ $C^2$-extended below `eps`,\n        with its derivative if `deriv` is `True`\n    \"\"\"\n    if np.min(a) &gt; eps:\n        loga = np.log(a)\n        return (loga, 1.0 / a) if deriv else loga\n    else:\n        logarreps = np.log(np.maximum(a, eps))\n        logarr_smaller = log(eps) - (eps - a) * (3.0 * eps - a) / (\n            2.0 * eps * eps\n        )\n        if verbose:\n            n_small_args = np.sum(a &lt; eps)\n            if n_small_args &gt; 0:\n                finals = \"s\" if n_small_args &gt; 1 else \"\"\n                print(\n                    f\"nplog: {n_small_args} argument{finals} smaller than {eps}: mini = {np.min(a)}\"\n                )\n        loga = np.where(a &gt; eps, logarreps, logarr_smaller)\n        if deriv:\n            der_logarreps = 1.0 / np.maximum(a, eps)\n            der_logarr_smaller = (2.0 * eps - a) / (eps * eps)\n            der_loga = np.where(a &gt; eps, der_logarreps, der_logarr_smaller)\n            return loga, der_loga\n        else:\n            return loga\n</code></pre>"},{"location":"utils/#cupid_matching.utils.npmaxabs","title":"<code>npmaxabs(a)</code>","text":"<p>The maximum absolute value in an array</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>np.ndarray</code> <p>the array</p> required <p>Returns:</p> Type Description <code>float</code> <p>\\max{\\vert a \\vert}</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def npmaxabs(a: np.ndarray) -&gt; float:\n\"\"\"The maximum absolute value in an array\n\n    Args:\n        a: the array\n\n    Returns:\n        $\\\\max{\\\\vert a \\\\vert}$\n    \"\"\"\n    maxi: float = np.max(np.abs(a))\n    return maxi\n</code></pre>"},{"location":"utils/#cupid_matching.utils.nppow","title":"<code>nppow(a, b, deriv=False)</code>","text":"<p>Evaluates a^b element-by-element</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>np.ndarray</code> <p>a Numpy array</p> required <code>b</code> <code>int | float | np.ndarray</code> <p>if an array, it should have the same shape as <code>a</code></p> required <code>deriv</code> <code>bool</code> <p>if <code>True</code>, the first derivatives wrt <code>a</code> and <code>b</code> are also returned</p> <code>False</code> <p>Returns:</p> Type Description <code>np.ndarray | ThreeArrays</code> <p>an array of the same shape as <code>a</code>, and if <code>deriv</code> is <code>True</code>,</p> <code>np.ndarray | ThreeArrays</code> <p>the derivatives wrt <code>a</code> and <code>b</code></p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def nppow(\n    a: np.ndarray, b: int | float | np.ndarray, deriv: bool = False\n) -&gt; np.ndarray | ThreeArrays:\n\"\"\"Evaluates $a^b$ element-by-element\n\n    Args:\n        a: a Numpy array\n        b: if an array, it should have the same shape as `a`\n        deriv: if `True`, the first derivatives wrt `a` and `b`\n            are also returned\n\n    Returns:\n        an array of the same shape as `a`, and if `deriv` is `True`,\n        the derivatives wrt `a` and `b`\n    \"\"\"\n    mina = np.min(a)\n    if mina &lt;= 0:\n        bs_error_abort(\"All elements of a must be positive!\")\n\n    if isinstance(b, (int, float)):\n        a_pow_b = a**b\n        if deriv:\n            return (a**b, b * a_pow_b / a, a_pow_b * log(a))\n        else:\n            return a_pow_b\n    else:\n        if a.shape != b.shape:\n            bs_error_abort(f\"a has shape {a.shape} and b has shape {b.shape}\")\n        avec = a.ravel()\n        bvec = b.ravel()\n        a_pow_b = avec**bvec\n        if deriv:\n            der_wrt_a = a_pow_b * bvec / avec\n            der_wrt_b = a_pow_b * nplog(avec)\n            return (\n                a_pow_b.reshape(a.shape),\n                der_wrt_a.reshape(a.shape),\n                der_wrt_b.reshape(a.shape),\n            )\n        else:\n            return a_pow_b.reshape(a.shape)\n</code></pre>"},{"location":"utils/#cupid_matching.utils.nprepeat_col","title":"<code>nprepeat_col(v, n)</code>","text":"<p>Creates a matrix with <code>n</code> columns, all equal to <code>v</code></p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>np.ndarray</code> <p>a vector of size <code>m</code></p> required <code>n</code> <code>int</code> <p>the number of columns requested</p> required <p>:return: a matrix of shape <code>(m, n)</code></p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def nprepeat_col(v: np.ndarray, n: int) -&gt; np.ndarray:\n\"\"\"Creates a matrix with `n` columns, all equal to `v`\n\n    Args:\n        v: a vector of size `m`\n        n: the number of columns requested\n\n    :return: a matrix of shape `(m, n)`\n    \"\"\"\n    _ = test_vector(v, \"nprepeat_col\")\n    w: np.ndarray = v[:, np.newaxis]\n    return np.repeat(w, n, axis=1)\n</code></pre>"},{"location":"utils/#cupid_matching.utils.nprepeat_row","title":"<code>nprepeat_row(v, m)</code>","text":"<p>Creates a matrix with <code>m</code> rows, all equal to <code>v</code></p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>np.ndarray</code> <p>a vector of size <code>n</code></p> required <code>m</code> <code>int</code> <p>the number of rows requested</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>a matrix of shape <code>(m, n)</code></p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def nprepeat_row(v: np.ndarray, m: int) -&gt; np.ndarray:\n\"\"\"\n    Creates a matrix with `m` rows, all equal to `v`\n\n    Args:\n        v: a vector of size `n`\n        m: the number of rows requested\n\n    Returns:\n        a matrix of shape `(m, n)`\n    \"\"\"\n    _ = test_vector(v, \"nprepeat_row\")\n    return np.repeat(v[np.newaxis, :], m, axis=0)\n</code></pre>"},{"location":"utils/#cupid_matching.utils.print_stars","title":"<code>print_stars(title=None, n=70)</code>","text":"<p>Prints a starred line, or two around the title</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>Optional[str]</code> <p>an optional title</p> <code>None</code> <code>n</code> <code>int</code> <p>the number of stars on the line</p> <code>70</code> <p>Returns:</p> Type Description <code>None</code> <p>nothing</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def print_stars(title: Optional[str] = None, n: int = 70) -&gt; None:\n\"\"\"Prints a starred line, or two around the title\n\n    Args:\n        title:  an optional title\n        n: the number of stars on the line\n\n    Returns:\n        nothing\n    \"\"\"\n    line_stars = \"*\" * n\n    print()\n    print(line_stars)\n    if title:\n        print(title.center(n))\n        print(line_stars)\n    print()\n</code></pre>"},{"location":"utils/#cupid_matching.utils.test_matrix","title":"<code>test_matrix(x, fun_name=None)</code>","text":"<p>Tests that <code>x</code> is a matrix; aborts otherwise</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Any</code> <p>a potential matrix</p> required <code>fun_name</code> <code>Optional[str]</code> <p>the name of the calling function</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>the shape of <code>x</code> if it is a matrix</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def test_matrix(x: Any, fun_name: Optional[str] = None) -&gt; tuple[int, int]:\n\"\"\"Tests that `x` is a matrix; aborts otherwise\n\n    Args:\n        x: a potential matrix\n        fun_name: the name of the calling function\n\n    Returns:\n        the shape of `x` if it is a matrix\n    \"\"\"\n    fun_str: str = \"\" if fun_name is None else fun_name + \":\"\n    if not isinstance(x, np.ndarray):\n        bs_error_abort(f\"x in {fun_str} should be a Numpy array\")\n    ndims_x = x.ndim\n    if ndims_x != 2:\n        bs_error_abort(\n            f\"x in {fun_str} should have two dimensions, not {ndims_x}\"\n        )\n    shx: tuple[int, int] = x.shape\n    return shx\n</code></pre>"},{"location":"utils/#cupid_matching.utils.test_vector","title":"<code>test_vector(x, fun_name=None)</code>","text":"<p>Tests that <code>x</code> is a vector; aborts otherwise</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Any</code> <p>a potential vector</p> required <code>fun_name</code> <code>Optional[str]</code> <p>the name of the calling function</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>the size of <code>x</code> if it is a vector</p> Source code in <code>cupid_matching/utils.py</code> <pre><code>def test_vector(x: Any, fun_name: Optional[str] = None) -&gt; int:\n\"\"\"Tests that `x` is a vector; aborts otherwise\n\n    Args:\n        x: a potential vector\n        fun_name: the name of the calling function\n\n    Returns:\n        the size of `x` if it is a vector\n    \"\"\"\n    fun_str = [\"\" if fun_name is None else fun_name + \":\"]\n    if not isinstance(x, np.ndarray):\n        bs_error_abort(f\"{fun_str} x should be a Numpy array\")\n    ndims_x = x.ndim\n    if ndims_x != 1:\n        bs_error_abort(f\"{fun_str} x should have one dimension, not {ndims_x}\")\n    sx: int = x.size\n    return sx\n</code></pre>"}]}